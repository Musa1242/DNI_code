{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis for temporal predictability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Necessary packages ###\n",
    "import mne\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from autoreject import Ransac\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib qt\n",
    "import matplotlib.ticker as ticker \n",
    "from IPython.display import display\n",
    "# DATA ANALYSIS PART\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "import pingouin as pg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for data from 2023 ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking triggers and data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from C:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\Data4\\BB\\AR_BB_01.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 170759  =      0.000 ...   170.759 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\2738457531.py:39: RuntimeWarning: No coordinate information found for channels ['VEOG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\2738457531.py:39: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\2738457531.py:39: RuntimeWarning: Not setting position of 1 misc channel found in montage:\n",
      "['VEOG']\n",
      "Consider setting the channel types to be of EEG/sEEG/ECoG/DBS/fNIRS using inst.set_channel_types before calling inst.set_montage, or omit these channels when creating your montage.\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<details open>\n",
       "    <summary><strong>General</strong></summary>\n",
       "    <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "        <tr>\n",
       "            <th>Measurement date</th>\n",
       "            \n",
       "            <td>July 19, 2023  16:08:19 GMT</td>\n",
       "            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Experimenter</th>\n",
       "            \n",
       "            <td>Unknown</td>\n",
       "            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Participant</th>\n",
       "            \n",
       "            <td>Unknown</td>\n",
       "            \n",
       "        </tr>\n",
       "    </table>\n",
       "    </details>\n",
       "    <details open>\n",
       "        <summary><strong>Channels</strong></summary>\n",
       "        <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "            <tr>\n",
       "                <th>Digitized points</th>\n",
       "                \n",
       "                <td>34 points</td>\n",
       "                \n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Good channels</th>\n",
       "                <td>31 EEG</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Bad channels</th>\n",
       "                <td>None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>EOG channels</th>\n",
       "                <td>Not available</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>ECG channels</th>\n",
       "                <td>Not available</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "        </details>\n",
       "        <details open>\n",
       "            <summary><strong>Data</strong></summary>\n",
       "            <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "                \n",
       "                <tr>\n",
       "                    <th>Sampling frequency</th>\n",
       "                    <td>1000.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Highpass</th>\n",
       "                    <td>0.01 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Lowpass</th>\n",
       "                    <td>120.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Filenames</th>\n",
       "                    <td>AR_BB_01.eeg</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Duration</th>\n",
       "                    <td>00:02:51 (HH:MM:SS)</td>\n",
       "                </tr>\n",
       "                \n",
       "            </table>\n",
       "            </details>"
      ],
      "text/plain": [
       "<RawBrainVision | AR_BB_01.eeg, 31 x 170760 (170.8 s), ~40.4 MB, data loaded>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib as 2D backend.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.03\n",
      "- Lower transition bandwidth: 0.03 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 110001 samples (110.001 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Response/R  7', 'Response/R 13', 'Response/R 15', 'Stimulus/S  2', 'Stimulus/S  4', 'Stimulus/S  6']\n",
      "Trigger 2 count: 114\n",
      "Trigger 4 count: 114\n",
      "Trigger 6 count: 76\n",
      "Trigger 8 count: 0\n",
      "Trigger 10 count: 0\n",
      "Extracting parameters from C:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\Data4\\BB\\AR_BB_02.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 164459  =      0.000 ...   164.459 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\2738457531.py:39: RuntimeWarning: No coordinate information found for channels ['VEOG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\2738457531.py:39: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\2738457531.py:39: RuntimeWarning: Not setting position of 1 misc channel found in montage:\n",
      "['VEOG']\n",
      "Consider setting the channel types to be of EEG/sEEG/ECoG/DBS/fNIRS using inst.set_channel_types before calling inst.set_montage, or omit these channels when creating your montage.\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<details open>\n",
       "    <summary><strong>General</strong></summary>\n",
       "    <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "        <tr>\n",
       "            <th>Measurement date</th>\n",
       "            \n",
       "            <td>July 19, 2023  16:28:55 GMT</td>\n",
       "            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Experimenter</th>\n",
       "            \n",
       "            <td>Unknown</td>\n",
       "            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Participant</th>\n",
       "            \n",
       "            <td>Unknown</td>\n",
       "            \n",
       "        </tr>\n",
       "    </table>\n",
       "    </details>\n",
       "    <details open>\n",
       "        <summary><strong>Channels</strong></summary>\n",
       "        <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "            <tr>\n",
       "                <th>Digitized points</th>\n",
       "                \n",
       "                <td>34 points</td>\n",
       "                \n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Good channels</th>\n",
       "                <td>31 EEG</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Bad channels</th>\n",
       "                <td>None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>EOG channels</th>\n",
       "                <td>Not available</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>ECG channels</th>\n",
       "                <td>Not available</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "        </details>\n",
       "        <details open>\n",
       "            <summary><strong>Data</strong></summary>\n",
       "            <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "                \n",
       "                <tr>\n",
       "                    <th>Sampling frequency</th>\n",
       "                    <td>1000.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Highpass</th>\n",
       "                    <td>0.01 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Lowpass</th>\n",
       "                    <td>120.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Filenames</th>\n",
       "                    <td>AR_BB_02.eeg</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Duration</th>\n",
       "                    <td>00:02:45 (HH:MM:SS)</td>\n",
       "                </tr>\n",
       "                \n",
       "            </table>\n",
       "            </details>"
      ],
      "text/plain": [
       "<RawBrainVision | AR_BB_02.eeg, 31 x 164460 (164.5 s), ~38.9 MB, data loaded>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.03\n",
      "- Lower transition bandwidth: 0.03 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 110001 samples (110.001 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Response/R  7', 'Response/R 13', 'Response/R 15', 'Stimulus/S  2', 'Stimulus/S  4', 'Stimulus/S  6']\n",
      "Trigger 2 count: 114\n",
      "Trigger 4 count: 114\n",
      "Trigger 6 count: 76\n",
      "Trigger 8 count: 0\n",
      "Trigger 10 count: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data4\\\\BB\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"AR\"]\n",
    "conds_of_interest2 = [\"US\",\"AS\",\"UR\",\"AR\"]\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "counter = 0\n",
    "\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_BB_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID\n",
    "    block_number = file_parts[2]  # Block number\n",
    "\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        display(raw)\n",
    "        \n",
    "        raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        \n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        def check_event_triggers(events):\n",
    "            ignore_codes = set(range(1000, 1101))\n",
    "            trigger_counts = {2: 0, 4: 0, 6: 0, 8: 0, 10: 0}\n",
    "            \n",
    "            # Process each event\n",
    "            for i, event in enumerate(events):\n",
    "                # Skip ignored codes and the code 99999\n",
    "                if event[2] in ignore_codes or event[2] == 99999:\n",
    "                    continue\n",
    "\n",
    "                # Count valid triggers\n",
    "                if event[2] in trigger_counts:\n",
    "                    trigger_counts[event[2]] += 1\n",
    "\n",
    "            return trigger_counts\n",
    "\n",
    "\n",
    "        # Now let's call the function and print the results\n",
    "        trigger_counts = check_event_triggers(events)\n",
    "        for trigger, count in trigger_counts.items():\n",
    "            print(f\"Trigger {trigger} count: {count}\")\n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing for BA;BC;BD --> BB is excluded"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Participant BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from C:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\Data4\\BC\\AR_BC_01.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 165339  =      0.000 ...   165.339 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.03\n",
      "- Lower transition bandwidth: 0.03 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 110001 samples (110.001 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:128: RuntimeWarning: No coordinate information found for channels ['VEOG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:128: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:128: RuntimeWarning: Not setting position of 1 misc channel found in montage:\n",
      "['VEOG']\n",
      "Consider setting the channel types to be of EEG/sEEG/ECoG/DBS/fNIRS using inst.set_channel_types before calling inst.set_montage, or omit these channels when creating your montage.\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Response/R  7', 'Response/R 15', 'Stimulus/S  2', 'Stimulus/S  4', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 304 events and 601 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    2.5s remaining:   23.2s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    2.5s remaining:    7.7s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    2.6s remaining:    3.9s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    2.6s remaining:    2.1s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    2.7s remaining:    1.1s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    2.7s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.9s remaining:    8.5s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.9s remaining:    3.0s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    0.9s remaining:    1.5s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    1.0s remaining:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    1.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    1.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done]\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "Interpolating bad channels.\n",
      "    Automatic origin fit: head of radius 96.0 mm\n",
      "Computing interpolation matrix from 28 sensor positions\n",
      "Interpolating 1 sensors\n",
      "Oz\n",
      "Fitting ICA to data using 29 channels (please be patient, this may take a while)\n",
      "Selecting by number: 28 components\n",
      "Fitting ICA took 4.5s.\n",
      "Using EOG channels: Fp1, Fp2\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (28 components)\n",
      "    Zeroing out 1 ICA component\n",
      "    Projecting back using 29 PCA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "Applying baseline correction (mode: mean)\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "142 bad epochs dropped\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "Extracting parameters from C:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\Data4\\BC\\AR_BC_02.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 166359  =      0.000 ...   166.359 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.03\n",
      "- Lower transition bandwidth: 0.03 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 110001 samples (110.001 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:128: RuntimeWarning: No coordinate information found for channels ['VEOG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:128: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:128: RuntimeWarning: Not setting position of 1 misc channel found in montage:\n",
      "['VEOG']\n",
      "Consider setting the channel types to be of EEG/sEEG/ECoG/DBS/fNIRS using inst.set_channel_types before calling inst.set_montage, or omit these channels when creating your montage.\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Response/R  7', 'Response/R 13', 'Response/R 15', 'Stimulus/S  2', 'Stimulus/S  4', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 304 events and 601 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Batch computation too fast (0.0405430793762207s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.9s remaining:    9.3s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    1.0s remaining:    3.1s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    1.0s remaining:    1.5s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    1.0s remaining:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    1.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    1.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done]\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "Interpolating bad channels.\n",
      "    Automatic origin fit: head of radius 96.0 mm\n",
      "Computing interpolation matrix from 28 sensor positions\n",
      "Interpolating 1 sensors\n",
      "FC6\n",
      "Fitting ICA to data using 29 channels (please be patient, this may take a while)\n",
      "Selecting by number: 28 components\n",
      "Fitting ICA took 3.1s.\n",
      "Using EOG channels: Fp1, Fp2\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (28 components)\n",
      "    Zeroing out 1 ICA component\n",
      "    Projecting back using 29 PCA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "Applying baseline correction (mode: mean)\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F3', 'F7', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['F3', 'FT9', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'CP1', 'P3', 'CP2', 'Cz', 'FT10', 'FC2', 'F4', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "5 bad epochs dropped\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "Extracting parameters from C:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\Data4\\BC\\AS_BC_01.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 166219  =      0.000 ...   166.219 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:38: RuntimeWarning: No coordinate information found for channels ['VEOG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:38: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:38: RuntimeWarning: Not setting position of 1 misc channel found in montage:\n",
      "['VEOG']\n",
      "Consider setting the channel types to be of EEG/sEEG/ECoG/DBS/fNIRS using inst.set_channel_types before calling inst.set_montage, or omit these channels when creating your montage.\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.03\n",
      "- Lower transition bandwidth: 0.03 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 110001 samples (110.001 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Response/R  7', 'Response/R 15', 'Stimulus/S  2', 'Stimulus/S  4', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 304 events and 601 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Batch computation too fast (0.045070648193359375s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done]\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "Interpolating bad channels.\n",
      "    Automatic origin fit: head of radius 96.0 mm\n",
      "Computing interpolation matrix from 28 sensor positions\n",
      "Interpolating 1 sensors\n",
      "FC6\n",
      "Fitting ICA to data using 29 channels (please be patient, this may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.9s remaining:    9.2s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.9s remaining:    3.0s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    0.9s remaining:    1.5s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    1.0s remaining:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    1.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    1.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by number: 28 components\n",
      "Fitting ICA took 2.1s.\n",
      "Using EOG channels: Fp1, Fp2\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (28 components)\n",
      "    Zeroing out 1 ICA component\n",
      "    Projecting back using 29 PCA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "Applying baseline correction (mode: mean)\n",
      "    Rejecting  epoch based on EEG : ['F3', 'O1', 'Oz', 'CP2', 'Cz', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['F3', 'CP1', 'Pz', 'O2', 'CP2', 'Cz', 'FC2', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['O2', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['O1', 'O2']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F3', 'FC6', 'F8']\n",
      "8 bad epochs dropped\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "Extracting parameters from C:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\Data4\\BC\\AS_BC_02.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 160319  =      0.000 ...   160.319 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:38: RuntimeWarning: No coordinate information found for channels ['VEOG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:38: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:38: RuntimeWarning: Not setting position of 1 misc channel found in montage:\n",
      "['VEOG']\n",
      "Consider setting the channel types to be of EEG/sEEG/ECoG/DBS/fNIRS using inst.set_channel_types before calling inst.set_montage, or omit these channels when creating your montage.\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.03\n",
      "- Lower transition bandwidth: 0.03 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 110001 samples (110.001 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Response/R  7', 'Response/R 15', 'Stimulus/S  2', 'Stimulus/S  4', 'Stimulus/S  6']\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 304 events and 601 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Batch computation too fast (0.04331636428833008s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.9s remaining:    8.5s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.9s remaining:    3.0s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    1.0s remaining:    1.5s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    1.0s remaining:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    1.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    1.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done]\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "Interpolating bad channels.\n",
      "    Automatic origin fit: head of radius 96.0 mm\n",
      "Computing interpolation matrix from 28 sensor positions\n",
      "Interpolating 1 sensors\n",
      "FC6\n",
      "Fitting ICA to data using 29 channels (please be patient, this may take a while)\n",
      "Selecting by number: 28 components\n",
      "Fitting ICA took 6.7s.\n",
      "Using EOG channels: Fp1, Fp2\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (28 components)\n",
      "    Zeroing out 1 ICA component\n",
      "    Projecting back using 29 PCA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "Applying baseline correction (mode: mean)\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F3', 'F4', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'FC6', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'FC6', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['F3', 'FT9', 'FC5', 'FC1', 'C3', 'CP1', 'Pz', 'P3', 'O1', 'Oz', 'O2', 'CP2', 'Cz', 'FT10', 'FC6', 'FC2', 'F4', 'F8']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'F4', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'FT9', 'CP1', 'Pz', 'P3', 'O1', 'Oz', 'O2', 'FT10', 'FC6', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "237 bad epochs dropped\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "Extracting parameters from C:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\Data4\\BC\\UR_BC_01.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 162879  =      0.000 ...   162.879 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:38: RuntimeWarning: No coordinate information found for channels ['VEOG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:38: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:38: RuntimeWarning: Not setting position of 1 misc channel found in montage:\n",
      "['VEOG']\n",
      "Consider setting the channel types to be of EEG/sEEG/ECoG/DBS/fNIRS using inst.set_channel_types before calling inst.set_montage, or omit these channels when creating your montage.\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.03\n",
      "- Lower transition bandwidth: 0.03 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 110001 samples (110.001 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Response/R  7', 'Response/R 13', 'Response/R 15', 'Stimulus/S  2', 'Stimulus/S  4', 'Stimulus/S  8', 'Stimulus/S 10']\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 304 events and 601 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Batch computation too fast (0.05074048042297363s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.9s remaining:    8.9s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    1.0s remaining:    3.1s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    1.0s remaining:    1.6s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    1.0s remaining:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    1.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    1.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done]\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "Interpolating bad channels.\n",
      "    Automatic origin fit: head of radius 96.0 mm\n",
      "Computing interpolation matrix from 28 sensor positions\n",
      "Interpolating 1 sensors\n",
      "FC6\n",
      "Fitting ICA to data using 29 channels (please be patient, this may take a while)\n",
      "Selecting by number: 28 components\n",
      "Fitting ICA took 2.9s.\n",
      "Using EOG channels: Fp1, Fp2\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (28 components)\n",
      "    Zeroing out 1 ICA component\n",
      "    Projecting back using 29 PCA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "Applying baseline correction (mode: mean)\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "    Rejecting  epoch based on EEG : ['F8']\n",
      "3 bad epochs dropped\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "Extracting parameters from C:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\Data4\\BC\\UR_BC_02.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 169259  =      0.000 ...   169.259 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:38: RuntimeWarning: No coordinate information found for channels ['VEOG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:38: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:38: RuntimeWarning: Not setting position of 1 misc channel found in montage:\n",
      "['VEOG']\n",
      "Consider setting the channel types to be of EEG/sEEG/ECoG/DBS/fNIRS using inst.set_channel_types before calling inst.set_montage, or omit these channels when creating your montage.\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.03\n",
      "- Lower transition bandwidth: 0.03 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 110001 samples (110.001 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Response/R  7', 'Response/R 13', 'Response/R 15', 'Stimulus/S  2', 'Stimulus/S  4', 'Stimulus/S  8', 'Stimulus/S 10']\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 304 events and 601 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Batch computation too fast (0.03998589515686035s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.9s remaining:    8.7s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.9s remaining:    2.9s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    0.9s remaining:    1.4s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    0.9s remaining:    0.7s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    1.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    1.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done]\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "Interpolating bad channels.\n",
      "    Automatic origin fit: head of radius 96.0 mm\n",
      "Computing interpolation matrix from 26 sensor positions\n",
      "Interpolating 3 sensors\n",
      "P8\n",
      "CP6\n",
      "F8\n",
      "Fitting ICA to data using 29 channels (please be patient, this may take a while)\n",
      "Selecting by number: 28 components\n",
      "Fitting ICA took 3.3s.\n",
      "Using EOG channels: Fp1, Fp2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:72: RuntimeWarning: Using n_components=28 (resulting in n_components_=28) may lead to an unstable mixing matrix estimation because the ratio between the largest (28) and smallest (9.6e-31) variances is too large (> 1e6); consider setting n_components=0.999999 or an integer <= 25\n",
      "  ica.fit(epochs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (28 components)\n",
      "    Zeroing out 1 ICA component\n",
      "    Projecting back using 29 PCA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "Applying baseline correction (mode: mean)\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'F8', 'Fp2']\n",
      "1 bad epochs dropped\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "Extracting parameters from C:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\Data4\\BC\\US_BC_01.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 162979  =      0.000 ...   162.979 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:38: RuntimeWarning: No coordinate information found for channels ['VEOG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:38: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:38: RuntimeWarning: Not setting position of 1 misc channel found in montage:\n",
      "['VEOG']\n",
      "Consider setting the channel types to be of EEG/sEEG/ECoG/DBS/fNIRS using inst.set_channel_types before calling inst.set_montage, or omit these channels when creating your montage.\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.03\n",
      "- Lower transition bandwidth: 0.03 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 110001 samples (110.001 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Response/R  5', 'Response/R  7', 'Response/R 13', 'Response/R 15', 'Stimulus/S  2', 'Stimulus/S  4', 'Stimulus/S  8', 'Stimulus/S 10']\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 304 events and 601 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Batch computation too fast (0.04157114028930664s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.9s remaining:    9.3s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    1.0s remaining:    3.2s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    1.0s remaining:    1.6s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    1.0s remaining:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    1.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    1.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done]\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "\n",
      "Fitting ICA to data using 29 channels (please be patient, this may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\autoreject\\ransac.py:244: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  epochs.interpolate_bads(reset_bads=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by number: 28 components\n",
      "Fitting ICA took 4.1s.\n",
      "Using EOG channels: Fp1, Fp2\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (28 components)\n",
      "    Zeroing out 1 ICA component\n",
      "    Projecting back using 29 PCA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "Applying baseline correction (mode: mean)\n",
      "0 bad epochs dropped\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "Extracting parameters from C:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\Data4\\BC\\US_BC_02.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 163659  =      0.000 ...   163.659 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:38: RuntimeWarning: No coordinate information found for channels ['VEOG']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:38: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\498812730.py:38: RuntimeWarning: Not setting position of 1 misc channel found in montage:\n",
      "['VEOG']\n",
      "Consider setting the channel types to be of EEG/sEEG/ECoG/DBS/fNIRS using inst.set_channel_types before calling inst.set_montage, or omit these channels when creating your montage.\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.03\n",
      "- Lower transition bandwidth: 0.03 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 110001 samples (110.001 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Response/R  7', 'Response/R 13', 'Response/R 15', 'Stimulus/S  2', 'Stimulus/S  4', 'Stimulus/S  8', 'Stimulus/S 10']\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 304 events and 601 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Batch computation too fast (0.04029107093811035s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.8s remaining:    8.4s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.9s remaining:    3.0s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    0.9s remaining:    1.4s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    1.0s remaining:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    1.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    1.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done]\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "Interpolating bad channels.\n",
      "    Automatic origin fit: head of radius 96.0 mm\n",
      "Computing interpolation matrix from 28 sensor positions\n",
      "Interpolating 1 sensors\n",
      "FC6\n",
      "Fitting ICA to data using 29 channels (please be patient, this may take a while)\n",
      "Selecting by number: 28 components\n",
      "Fitting ICA took 4.4s.\n",
      "Using EOG channels: Fp1, Fp2\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (28 components)\n",
      "    Zeroing out 1 ICA component\n",
      "    Projecting back using 29 PCA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "Applying baseline correction (mode: mean)\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F3', 'F7', 'FC5', 'FC1', 'C3', 'T7', 'CP5', 'Cz', 'FC2', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F3', 'F7', 'FC5', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'FC6', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F3', 'F7', 'FC1', 'FC2', 'F4', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F3', 'F7', 'FC5', 'T7', 'CP1', 'P7', 'O1', 'Oz', 'O2', 'FC6', 'F4', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'CP1', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F3', 'F7', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'F8', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "271 bad epochs dropped\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "none\n",
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data4\\\\BC\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"US\",\"AS\",\"UR\"]\n",
    "conds_of_interest2 = [\"AR\"]\n",
    "# tmin and tmax of epoch\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_BC_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID \n",
    "    block_number = file_parts[2]  # Block number\n",
    "\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        ## drop noisy channels\n",
    "        raw.drop_channels(['P4'])\n",
    "        raw.drop_channels(['C4'])\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs4')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events) \n",
    "    if file_cond in conds_of_interest2:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        \n",
    "        \n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        raw.drop_channels(['P4'])\n",
    "        raw.drop_channels(['C4'])\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs3')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)   \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant BA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data4\\\\BA\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"US\",\"AS\",\"UR\",\"AR\"]\n",
    "#conds_of_interest2 = [\"UR\"]\n",
    "# tmin and tmax of epoch\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_BA_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID \n",
    "    block_number = file_parts[2]  # Block number\n",
    "\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "    \n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.75)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs4')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events) \n",
    "    \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Participant BD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data4\\\\BD\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"US\",\"AS\",\"UR\",\"AR\"]\n",
    "#conds_of_interest2 = [\"AR\"]\n",
    "# tmin and tmax of epoch\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_BD_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID\n",
    "    block_number = file_parts[2]  # Block number\n",
    "\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.65)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs4')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events) \n",
    "    \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read epochs file and save it as evoked ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BA\\US_BA_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BA\\US_BA_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "300 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "604 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BA\\AS_BA_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\4233796953.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BA\\AS_BA_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "239 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "464 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BA\\UR_BA_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "201 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BA\\UR_BA_02-epo.fif ...\n",
      "    Found the data of interest:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\4233796953.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "505 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BA\\AR_BA_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\4233796953.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BA\\AR_BA_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "303 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "607 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BC\\US_BC_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\4233796953.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BC\\US_BC_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "33 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "337 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BC\\AS_BC_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "296 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BC\\AS_BC_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\4233796953.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "67 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "363 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BC\\UR_BC_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "301 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BC\\UR_BC_02-epo.fif ...\n",
      "    Found the data of interest:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\4233796953.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "303 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "604 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BC\\AR_BC_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BC\\AR_BC_02-epo.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\4233796953.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "608 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BD\\US_BD_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\4233796953.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BD\\US_BD_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "302 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "606 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BD\\AS_BD_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\4233796953.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BD\\AS_BD_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "608 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BD\\UR_BD_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\4233796953.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BD\\UR_BD_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "276 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "580 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BD\\AR_BD_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\4233796953.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs4\\BD\\AR_BD_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "287 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "591 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\4233796953.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    }
   ],
   "source": [
    "def load_and_combine_epochs_for_condition(part_directory, condition):\n",
    "    epochs_list = []\n",
    "    for block_file in part_directory.glob(f\"{condition}_{part_directory.stem}_*-epo.fif\"):\n",
    "        epochs = mne.read_epochs(block_file, preload=True)\n",
    "        # Check if this is participant and adjust channels\n",
    "        if part_directory.stem == \"BC\":\n",
    "            # Drop specific channels if they are presentV\n",
    "            channels_to_drop = [ch for ch in ['C4', 'P4'] if ch in epochs.ch_names]\n",
    "            epochs.drop_channels(channels_to_drop)\n",
    "        epochs_list.append(epochs)\n",
    "    combined_epochs = mne.concatenate_epochs(epochs_list)\n",
    "    return combined_epochs\n",
    "\n",
    "conds_of_interest = [\"US\",\"AS\",\"UR\",\"AR\"]\n",
    "\n",
    "# Main processing loop\n",
    "all_parts23 = {}\n",
    "for part in Path(\"saved_epochs4\").iterdir():\n",
    "    evokeds = []\n",
    "    for cond in conds_of_interest:\n",
    "        # Load and combine epochs for each condition across blocks\n",
    "        combined_epochs = load_and_combine_epochs_for_condition(part, cond)\n",
    "        \n",
    "        if \"A\" in cond:\n",
    "            lat_cond = [f\"{cond}/lat_am\"]\n",
    "        elif \"U\" in cond:\n",
    "            lat_cond = [f\"{cond}/lat_unam_r\", f\"{cond}/lat_unam_l\"]\n",
    "\n",
    "        evoked = combined_epochs[lat_cond].average()\n",
    "        evoked.comment = cond  # Simplify condition name directly here\n",
    "        evokeds.append(evoked)\n",
    "\n",
    "    all_parts23[part.stem] = evokeds\n",
    "    \n",
    "### delete additional info in conditions\n",
    "def simplify_condition(comment):\n",
    "    for cond in conds_of_interest:\n",
    "        if cond in comment:\n",
    "            return cond\n",
    "    return None\n",
    "\n",
    "def simplify_evoked_conditions(participant_evokeds):\n",
    "    simplified_evokeds = []\n",
    "    for evoked in participant_evokeds:\n",
    "        simplified_comment = simplify_condition(evoked.comment)\n",
    "        if simplified_comment:\n",
    "            evoked.comment = simplified_comment\n",
    "            simplified_evokeds.append(evoked)\n",
    "    return simplified_evokeds\n",
    "for participant in list(all_parts23):\n",
    "    all_parts23[participant] = simplify_evoked_conditions(all_parts23[participant])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing of dataset 2023 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BA': [<Evoked | 'US' (average, N=151), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=145), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=130), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'BC': [<Evoked | 'US' (average, N=89), -0.1  0.5 s, baseline -0.1  0 s, 29 ch, ~178 kB>,\n",
       "  <Evoked | 'AS' (average, N=96), -0.1  0.5 s, baseline -0.1  0 s, 29 ch, ~178 kB>,\n",
       "  <Evoked | 'UR' (average, N=150), -0.1  0.5 s, baseline -0.1  0 s, 29 ch, ~178 kB>,\n",
       "  <Evoked | 'AR' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 29 ch, ~178 kB>],\n",
       " 'BD': [<Evoked | 'US' (average, N=151), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=149), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_parts23"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot individual evoked data for participants in dataset 2023 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\519064909.py:20: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\519064909.py:20: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\519064909.py:20: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\519064909.py:20: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\519064909.py:20: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\519064909.py:20: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\519064909.py:20: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\519064909.py:20: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\519064909.py:20: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\519064909.py:20: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\519064909.py:20: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\519064909.py:20: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def plot_evokeds_for_participant(participant, evokeds, colors):\n",
    "    # Define styles for the lines\n",
    "    styles = {\n",
    "        'US': {'color': 'red', 'linestyle': '-'},   # Bold red for Unambiguous-Same\n",
    "        'UR': {'color': 'red', 'linestyle': '--'},  # Dashed red for Unambiguous-Random\n",
    "        'AS': {'color': 'blue', 'linestyle': '-'},  # Bold blue for Ambiguous-Same\n",
    "        'AR': {'color': 'blue', 'linestyle': '--'}  # Dashed blue for Ambiguous-Random\n",
    "    }\n",
    "    \n",
    "    # Determine the common channels among all evokeds for the participant\n",
    "    common_channels = set(evokeds[0].ch_names)\n",
    "    for evoked in evokeds[1:]:\n",
    "        common_channels.intersection_update(evoked.ch_names)\n",
    "    \n",
    "    # Pick only the common channels for plotting\n",
    "    evokeds_common_channels = []\n",
    "    for ev in evokeds:\n",
    "        ev.pick_channels(list(common_channels))\n",
    "        evokeds_common_channels.append(ev)\n",
    "\n",
    "    # Adjust colors and styles based on the evoked.comment\n",
    "    adjusted_styles = {ev.comment: styles[ev.comment] for ev in evokeds_common_channels if ev.comment in styles}\n",
    "    adjusted_colors = {ev.comment: colors[ev.comment] for ev in evokeds_common_channels if ev.comment in colors}\n",
    "\n",
    "    # Plotting using adjusted styles and colors\n",
    "    mne.viz.plot_compare_evokeds(\n",
    "        {ev.comment: ev for ev in evokeds_common_channels},\n",
    "        title=f\"Participant '{participant}' ERPs\",\n",
    "        picks=\"Cz\",\n",
    "        colors=adjusted_colors,\n",
    "        styles=adjusted_styles,\n",
    "        ci=True,\n",
    "        show=True,\n",
    "        truncate_yaxis=False,\n",
    "        truncate_xaxis=False\n",
    "    )\n",
    "colors = {'US': 'red', 'AS': 'blue', 'UR': 'red', 'AR': 'blue'}  \n",
    "\n",
    "for participant, evokeds in all_parts.items():\n",
    "    if evokeds:  # Only plot if there are evoked data present\n",
    "        plot_evokeds_for_participant(participant, evokeds, colors)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grand mean of dataset 2023 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\1319273522.py:17: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\1319273522.py:17: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\1319273522.py:17: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\1319273522.py:17: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\1319273522.py:17: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\1319273522.py:17: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\1319273522.py:17: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\1319273522.py:17: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\1319273522.py:17: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\1319273522.py:17: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\1319273522.py:17: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_14032\\1319273522.py:17: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "combined_evokeds_by_cond = {cond: [] for cond in conds_of_interest}\n",
    "participant_count_by_cond = {}  # Dictionary to hold participant counts for each condition\n",
    "\n",
    "for participant, evokeds in all_parts.items():\n",
    "    for evoked in evokeds:\n",
    "        cond = simplify_condition(evoked.comment)\n",
    "        if cond:\n",
    "            combined_evokeds_by_cond[cond].append(evoked)\n",
    "            if cond not in participant_count_by_cond:\n",
    "                participant_count_by_cond[cond] = set()\n",
    "            participant_count_by_cond[cond].add(participant)\n",
    "\n",
    "# Adjusting each evoked data to only include common channels\n",
    "all_channels = set.intersection(*(set(evoked.ch_names) for evokeds in combined_evokeds_by_cond.values() for evoked in evokeds))\n",
    "for cond, evokeds in combined_evokeds_by_cond.items():\n",
    "    for evoked in evokeds:\n",
    "        evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
    "\n",
    "grand_averages_all = []\n",
    "legend_info = {}\n",
    "for cond, evokeds in combined_evokeds_by_cond.items():\n",
    "    if evokeds:\n",
    "        grand_avg = mne.grand_average(evokeds)\n",
    "        grand_avg.comment = cond\n",
    "        grand_averages_all.append(grand_avg)\n",
    "        # Prepare legend info with participant count\n",
    "        legend_info[cond] = f\"{cond} (n={len(participant_count_by_cond[cond])})\"\n",
    "\n",
    "# Dictionary for plot styling\n",
    "colors = {\n",
    "    'US': 'red',\n",
    "    'UR': 'red',\n",
    "    'AS': 'blue',\n",
    "    'AR': 'blue'\n",
    "}\n",
    "styles = {\n",
    "    'UR': {'linestyle': '--'},\n",
    "    'AR': {'linestyle': '--'}\n",
    "}\n",
    "\n",
    "# Update styles and colors to use the legend_info keys\n",
    "updated_colors = {legend_info[cond]: colors[cond] for cond in colors if cond in legend_info}\n",
    "updated_styles = {legend_info[cond]: styles[cond] for cond in styles if cond in legend_info}\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "mne.viz.plot_compare_evokeds(\n",
    "    {legend_info[cond]: grand_averages_all[i] for i, cond in enumerate(conds_of_interest) if cond in legend_info},\n",
    "    picks=\"Cz\",\n",
    "    ci=0.95,\n",
    "    colors=updated_colors,\n",
    "    styles=updated_styles,\n",
    "    title=\"Grand Average Evoked Responses by Condition\",\n",
    "    axes=ax\n",
    ")\n",
    "\n",
    "# Customizing the legend manually\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "new_labels = [legend_info[label.split()[0]] for label in labels]  # Remapping labels to include participant counts\n",
    "ax.legend(handles, new_labels)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grand mean with confidence interval ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_evokeds_by_cond = {cond: [] for cond in conds_of_interest}\n",
    "participant_count_by_cond = {}  # Dictionary to hold participant counts for each condition\n",
    "\n",
    "for participant, evokeds in all_parts.items():\n",
    "    for evoked in evokeds:\n",
    "        cond = simplify_condition(evoked.comment)\n",
    "        if cond:\n",
    "            combined_evokeds_by_cond[cond].append(evoked)\n",
    "            if cond not in participant_count_by_cond:\n",
    "                participant_count_by_cond[cond] = set()\n",
    "            participant_count_by_cond[cond].add(participant)\n",
    "\n",
    "# Dictionary for plot styling\n",
    "colors = {\n",
    "    'US': 'red',\n",
    "    'UR': 'red',\n",
    "    'AS': 'blue',\n",
    "    'AR': 'blue'\n",
    "}\n",
    "styles = {\n",
    "    'UR': {'linestyle': '--'},\n",
    "    'AR': {'linestyle': '--'}\n",
    "}\n",
    "\n",
    "# Prepare the evoked data with participant counts for plotting\n",
    "plot_evokeds = {}\n",
    "for cond in combined_evokeds_by_cond:\n",
    "    if combined_evokeds_by_cond[cond]:\n",
    "        plot_evokeds[f\"{cond} (n={len(participant_count_by_cond[cond])})\"] = combined_evokeds_by_cond[cond]\n",
    "\n",
    "# Update colors and styles to use the condition names with participant counts\n",
    "updated_colors = {f\"{cond} (n={len(participant_count_by_cond[cond])})\": colors[cond] for cond in colors}\n",
    "updated_styles = {f\"{cond} (n={len(participant_count_by_cond[cond])})\": styles[cond] for cond in styles if cond in styles}\n",
    "\n",
    "# Plotting with CIs\n",
    "fig, ax = plt.subplots()\n",
    "mne.viz.plot_compare_evokeds(\n",
    "    plot_evokeds,\n",
    "    picks=\"Cz\",\n",
    "    ci=0.95,\n",
    "    colors=updated_colors,\n",
    "    styles=updated_styles,\n",
    "    title=\"Grand Average Evoked Responses by Condition\",\n",
    "    axes=ax\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of dataset 2022 ###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing ###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking triggers ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get data path to specific participant \n",
    "### AM is excluded\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data3\\\\AM\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"UR\"]\n",
    "conds_of_interest2 = [\"US\",\"AS\",\"UR\",\"AR\"]\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "counter = 0\n",
    "\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_AM_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID\n",
    "    block_number = file_parts[2]  # Block number\n",
    "\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        display(raw)\n",
    "        \n",
    "        raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        \n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        def check_event_triggers(events):\n",
    "            ignore_codes = set(range(1000, 1101))\n",
    "            trigger_counts = {2: 0, 4: 0, 6: 0, 8: 0, 10: 0}\n",
    "            \n",
    "            # Process each event\n",
    "            for i, event in enumerate(events):\n",
    "                # Skip ignored codes and the code 99999\n",
    "                if event[2] in ignore_codes or event[2] == 99999:\n",
    "                    continue\n",
    "\n",
    "                # Count valid triggers\n",
    "                if event[2] in trigger_counts:\n",
    "                    trigger_counts[event[2]] += 1\n",
    "\n",
    "            return trigger_counts\n",
    "\n",
    "\n",
    "        # Now let's call the function and print the results\n",
    "        trigger_counts = check_event_triggers(events)\n",
    "        for trigger, count in trigger_counts.items():\n",
    "            print(f\"Trigger {trigger} count: {count}\")\n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the dataset 2022"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Participant AT ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data3\\\\AT\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"US\"]\n",
    "conds_of_interest2 = [ \"AR\", \"UR\", \"AS\"]\n",
    "# tmin and tmax of epoch\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_AT_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID\n",
    "    block_number = file_parts[2]  # Block number\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        \n",
    "        # Drop noisy channels\n",
    "        raw.drop_channels(['FC6', 'CP2'])\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        \n",
    "        raw.pick_types(eeg=True)\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        # raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.6)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs3')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events) \n",
    "    if file_cond in conds_of_interest2:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        \n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.6)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs3')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)   \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant AJ ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data3\\\\AJ\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"AS\",\"UR\",\"AR\"]\n",
    "conds_of_interest2 = [\"US\"]\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_AJ_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID\n",
    "    block_number = file_parts[2]  # Block number\n",
    "\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        \n",
    "        \n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        # epochs.set_eeg_reference(ref_channels='average', projection=False) ###############\n",
    "        epochs.set_eeg_reference(['P7','P8'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs3')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)    \n",
    "    if file_cond in conds_of_interest2:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        \n",
    "        raw.drop_channels(['FC6'])\n",
    "        # raw.drop_channels(['CP2'])\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        ica.plot_components()\n",
    "        ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        # epochs.set_eeg_reference(ref_channels='average', projection=False) ###############\n",
    "        epochs.set_eeg_reference(['P7','P8'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs3')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)    \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant AK ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data3\\\\AK\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"US\",\"AS\",\"UR\",\"AR\"]\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_AK_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID\n",
    "    block_number = file_parts[2]  # Block number \n",
    "\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        \n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        # rereferenced because TP10 is noisy\n",
    "        epochs.set_eeg_reference(['P7','P8'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs3')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant AL ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data3\\\\AL\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"US\",\"AS\",\"UR\"]\n",
    "conds_of_interest2 = [\"AR\"]\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_AL_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID\n",
    "    block_number = file_parts[2]  # Block number\n",
    "\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        \n",
    "        \n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.8)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs3')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)    \n",
    "    if file_cond in conds_of_interest2 and block_number == '01': ## AR Block 2 is recorded wrongly.\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.8)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs3')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)    \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant AM ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"-> AM is excluded\"\"\"\n",
    "# # get data path to specific participant\n",
    "# participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data3\\\\AM\")\n",
    "\n",
    "# # conditions we are interested in as a list\n",
    "# conds_of_interest = [\"US\",\"AS\",\"UR\",\"AR\"]\n",
    "# # tmin and tmax of epochs\n",
    "# tmin = -0.1\n",
    "# tmax = 0.5\n",
    "\n",
    "# # Participant name\n",
    "# participant_id = participant_path.stem\n",
    "\n",
    "# for file in participant_path.glob(\"*_AM_*.vhdr\"):\n",
    "#     # Extract the condition and block from the file name \n",
    "#     file_parts = file.stem.split('_')\n",
    "#     file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "#     participant_id = file_parts[1]  # Participant ID\n",
    "#     block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "\n",
    "#     if file_cond in conds_of_interest:\n",
    "#         # event triggers as dict used file cond info\n",
    "#         event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "#                     f\"{file_cond}/checks_rev\": 4,\n",
    "#                     f\"{file_cond}/lat_am\": 6}\n",
    "#         event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "#                     f\"{file_cond}/checks_rev\": 4,\n",
    "#                     f\"{file_cond}/lat_unam_l\": 8,\n",
    "#                     f\"{file_cond}/lat_unam_r\": 10}\n",
    "#         # get event_id corresponding with condition\n",
    "#         if \"A\" in file_cond:\n",
    "#             event_id = event_id_am\n",
    "#         elif \"U\" in file_cond:\n",
    "#             event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "#        # load raw data\n",
    "#         raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "#         # only pick eeg channels\n",
    "#         raw.pick(\"eeg\")\n",
    "        \n",
    "#         # raw.plot()\n",
    "#         raw.set_montage('standard_1020')\n",
    "#         ####\n",
    "#         # orig_events, _ = mne.events_from_annotations(raw)\n",
    "#         # events = get_new_events_old_trigger_system(orig_events, raw.info[\"sfreq\"]) #####\n",
    "#         # print(events)\n",
    "        \n",
    "        \n",
    "#         # filter data\n",
    "#         raw.filter(0.03,25)\n",
    "#         # raw.plot_psd(fmax=40)\n",
    "#         raw.pick([\"eeg\"]).load_data()\n",
    "#         # raw.info\n",
    "#         # raw.plot_sensors(show_names=True)\n",
    "#         # fig = raw.plot_sensors(\"3d\")\n",
    "#         # fig\n",
    "        \n",
    "#         # get triggers\n",
    "#         orig_events, _ = mne.events_from_annotations(raw)\n",
    "#         events = orig_events\n",
    "#         events.shape\n",
    "#         epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "#         picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "#         stim=False, eog=False,\n",
    "#         include=[], exclude=[])\n",
    "#         ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "#         epochs = ransac.fit_transform(epochs)\n",
    "#         print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "#         # epochs.plot()\n",
    "#         # compute an ICA to remove eye blink components from signal\n",
    "#         ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "#         ica.fit(epochs)\n",
    "#         ica.exclude = []\n",
    "#         eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "#         ica.exclude = eog_idx\n",
    "#         # ica.plot_scores(scores)\n",
    "#         ica.plot_components()\n",
    "#         ica.plot_sources(epochs)\n",
    "#         epochs_new = epochs.copy()\n",
    "#         ica.apply(epochs_new)\n",
    "#         epochs = epochs_new\n",
    "#         # epochs.plot()\n",
    "        \n",
    "#         # set offline reference at mastoid electrodes\n",
    "#         epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "#         # apply baseline in ms\n",
    "#         epochs.apply_baseline((-0.1,0))\n",
    "#         # reject epochs that are above a certain threshold\n",
    "#         # value needs to be in volts\n",
    "#         epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "#         # epochs.plot()\n",
    "#         # epochs.plot_drop_log()\n",
    "#         # save epoch objects and events array\n",
    "#         epoch_path = Path('saved_epochs3')\n",
    "#         folder_path = Path(epoch_path,participant_id)\n",
    "#         # Check if saved_epochs folder already exists\n",
    "#         if not epoch_path.exists():\n",
    "#             # Create the folder\n",
    "#             epoch_path.mkdir(parents=True)\n",
    "#         # Check if participant folder already exists\n",
    "#         if not folder_path.exists():\n",
    "#             # Create the folder\n",
    "#             folder_path.mkdir(parents=True)\n",
    "#         # Construct the filename with condition, participant ID, and block number\n",
    "#         epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "#         annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "#         # Save the epochs and annotations\n",
    "#         epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "#         np.save(folder_path / annotations_filename, events)    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant AN ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"--> AN is excluded\"\"\"\n",
    "\n",
    "\n",
    "# # get data path to specific participant\n",
    "# participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data3\\\\AN\")\n",
    "\n",
    "# # conditions we are interested in as a list\n",
    "# conds_of_interest = [\"US\",\"AS\",\"UR\",\"AR\"]\n",
    "\n",
    "# # tmin and tmax of epochs\n",
    "# tmin = -0.1\n",
    "# tmax = 0.5\n",
    "\n",
    "# # Participant name\n",
    "# participant_id = participant_path.stem\n",
    "\n",
    "# for file in participant_path.glob(\"*_AN_*.vhdr\"):\n",
    "#     # Extract the condition and block from the file name \n",
    "#     file_parts = file.stem.split('_')\n",
    "#     file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "#     participant_id = file_parts[1]  # Participant ID (e.g., \"AB\")\n",
    "#     block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "\n",
    "#     if file_cond in conds_of_interest:\n",
    "#         # event triggers as dict used file cond info\n",
    "#         event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "#                     f\"{file_cond}/checks_rev\": 4,\n",
    "#                     f\"{file_cond}/lat_am\": 6}\n",
    "#         event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "#                     f\"{file_cond}/checks_rev\": 4,\n",
    "#                     f\"{file_cond}/lat_unam_l\": 8,\n",
    "#                     f\"{file_cond}/lat_unam_r\": 10}\n",
    "#         # get event_id corresponding with condition\n",
    "#         if \"A\" in file_cond:\n",
    "#             event_id = event_id_am\n",
    "#         elif \"U\" in file_cond:\n",
    "#             event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "#        # load raw data\n",
    "#         raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "#         # only pick eeg channels\n",
    "#         raw.pick(\"eeg\")\n",
    "        \n",
    "#         # raw.plot()\n",
    "#         raw.set_montage('standard_1020')\n",
    "#         ####\n",
    "#         # orig_events, _ = mne.events_from_annotations(raw)\n",
    "#         # events = get_new_events_old_trigger_system(orig_events, raw.info[\"sfreq\"]) #####\n",
    "#         # print(events)\n",
    "        \n",
    "        \n",
    "#         # filter data\n",
    "#         raw.filter(0.03,25)\n",
    "#         # raw.plot_psd(fmax=40)\n",
    "#         raw.pick([\"eeg\"]).load_data()\n",
    "#         # raw.info\n",
    "#         # raw.plot_sensors(show_names=True)\n",
    "#         # fig = raw.plot_sensors(\"3d\")\n",
    "#         # fig\n",
    "        \n",
    "#         # get triggers\n",
    "#         orig_events, _ = mne.events_from_annotations(raw)\n",
    "#         events = orig_events\n",
    "#         events.shape\n",
    "#         epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "#         picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "#         stim=False, eog=False,\n",
    "#         include=[], exclude=[])\n",
    "#         ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "#         epochs = ransac.fit_transform(epochs)\n",
    "#         print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "#         # epochs.plot()\n",
    "#         # compute an ICA to remove eye blink components from signal\n",
    "#         ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "#         ica.fit(epochs)\n",
    "#         ica.exclude = []\n",
    "#         eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.6)\n",
    "#         ica.exclude = eog_idx\n",
    "#         # ica.plot_scores(scores)\n",
    "#         # ica.plot_components()\n",
    "#         # ica.plot_sources(epochs)\n",
    "#         epochs_new = epochs.copy()\n",
    "#         ica.apply(epochs_new)\n",
    "#         epochs = epochs_new\n",
    "#         # epochs.plot()\n",
    "        \n",
    "#         # set offline reference at mastoid electrodes\n",
    "#         epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "#         # apply baseline in ms\n",
    "#         epochs.apply_baseline((-0.1,0))\n",
    "#         # reject epochs that are above a certain threshold\n",
    "#         # value needs to be in volts\n",
    "#         epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "#         # epochs.plot()\n",
    "#         # epochs.plot_drop_log()\n",
    "#         # save epoch objects and events array\n",
    "#         epoch_path = Path('saved_epochs3')\n",
    "#         folder_path = Path(epoch_path,participant_id)\n",
    "#         # Check if saved_epochs folder already exists\n",
    "#         if not epoch_path.exists():\n",
    "#             # Create the folder\n",
    "#             epoch_path.mkdir(parents=True)\n",
    "#         # Check if participant folder already exists\n",
    "#         if not folder_path.exists():\n",
    "#             # Create the folder\n",
    "#             folder_path.mkdir(parents=True)\n",
    "#         # Construct the filename with condition, participant ID, and block number\n",
    "#         epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "#         annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "#         # Save the epochs and annotations\n",
    "#         epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "#         np.save(folder_path / annotations_filename, events)    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant AO ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data3\\\\AO\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"US\",\"AS\",\"UR\",\"AR\"]\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_AO_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID\n",
    "    block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.75)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs3')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant AP ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data3\\\\AP\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"US\",\"UR\"]\n",
    "conds_of_interest2 = [\"AS\"]\n",
    "conds_of_interest3 = [\"AR\"]\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_AP_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID \n",
    "    block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "\n",
    "    \n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs3')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events) \n",
    "    if file_cond in conds_of_interest2:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "                     \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        # raw.drop_channels(['CP2'])\n",
    "        raw.drop_channels(['CP6'])\n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "     \n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs3')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events) \n",
    "    if file_cond in conds_of_interest3 and block_number == \"01\":\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels and \n",
    "        raw.pick(\"eeg\")\n",
    "        raw.drop_channels(['CP6'])\n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs3')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)     \n",
    "    if file_cond in conds_of_interest3 and block_number == \"02\":\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels and \n",
    "        raw.pick(\"eeg\")\n",
    "        # raw.drop_channels(['Oz'])\n",
    "        raw.drop_channels(['CP2']) ########################\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    " \n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs3')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant AQ ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data3\\\\AQ\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"US\",\"AS\",\"UR\",\"AR\"]\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_AQ_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID \n",
    "    block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        \n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        ica.plot_components()\n",
    "        ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs3')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant AR ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data3\\\\AR\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"US\",\"AS\",\"UR\",\"AR\"]\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_AR_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID\n",
    "    block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        ####\n",
    "        # orig_events, _ = mne.events_from_annotations(raw)\n",
    "        # events = get_new_events_old_trigger_system(orig_events, raw.info[\"sfreq\"]) #####\n",
    "        # print(events)\n",
    "        \n",
    "        \n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        ica.plot_components()\n",
    "        ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs3')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant AS ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data3\\\\AS\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"US\",\"AS\",\"AR\"]\n",
    "conds_of_interest2 = [\"UR\"]\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_AS_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID\n",
    "    block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs3')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events) \n",
    "    if file_cond in conds_of_interest2 and block_number == '01': ### block 2 was misrecorded\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "    \n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = orig_events\n",
    "        events.shape\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs3')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)   \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read evoked data of dataset 2022 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AJ\\US_AJ_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "215 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AJ\\US_AJ_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "190 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "405 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AJ\\AS_AJ_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "301 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AJ\\AS_AJ_02-epo.fif ...\n",
      "    Found the data of interest:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "254 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "555 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AJ\\UR_AJ_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AJ\\UR_AJ_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "559 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AJ\\AR_AJ_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AJ\\AR_AJ_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "544 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AK\\US_AK_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "301 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AK\\US_AK_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "285 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "586 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AK\\AS_AK_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "301 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AK\\AS_AK_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "301 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "602 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AK\\UR_AK_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AK\\UR_AK_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "302 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "606 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AK\\AR_AK_01-epo.fif ...\n",
      "    Found the data of interest:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "302 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AK\\AR_AK_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "301 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "603 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AL\\US_AL_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AL\\US_AL_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "245 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "480 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AL\\AS_AL_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AL\\AS_AL_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "153 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "412 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AL\\UR_AL_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AL\\UR_AL_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "250 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "500 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AL\\AR_AL_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "267 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "267 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AO\\US_AO_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "218 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AO\\US_AO_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "22 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "240 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AO\\AS_AO_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "155 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AO\\AS_AO_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "200 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "355 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AO\\UR_AO_01-epo.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "199 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AO\\UR_AO_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "190 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "389 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AO\\AR_AO_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "237 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AO\\AR_AO_02-epo.fif ...\n",
      "    Found the data of interest:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "189 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "426 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AP\\US_AP_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AP\\US_AP_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "601 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AP\\AS_AP_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "287 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AP\\UR_AP_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "254 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AP\\UR_AP_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "301 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "555 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AP\\AR_AP_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AP\\AR_AP_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "220 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "464 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AQ\\US_AQ_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "215 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AQ\\US_AQ_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "505 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AQ\\AS_AQ_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "219 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AQ\\AS_AQ_02-epo.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "303 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "522 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AQ\\UR_AQ_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "205 matching events found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AQ\\UR_AQ_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "244 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "449 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AQ\\AR_AQ_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AQ\\AR_AQ_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "546 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AR\\US_AR_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "280 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AR\\US_AR_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "300 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "580 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AR\\AS_AR_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AR\\AS_AR_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "300 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "604 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AR\\UR_AR_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "303 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AR\\UR_AR_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "607 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AR\\AR_AR_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AR\\AR_AR_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "608 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AS\\US_AS_01-epo.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "271 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AS\\US_AS_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "294 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "565 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AS\\AS_AS_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AS\\AS_AS_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "284 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "549 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AS\\UR_AS_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "296 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "296 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AS\\AR_AS_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "302 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AS\\AR_AS_02-epo.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "272 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "574 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AT\\US_AT_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AT\\US_AT_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "261 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "524 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AT\\AS_AT_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "286 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AT\\AS_AT_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "265 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "551 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AT\\UR_AT_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "300 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AT\\UR_AT_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "271 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "571 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AT\\AR_AT_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "281 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs3\\AT\\AR_AT_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "300 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "581 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2452503459.py:22: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    }
   ],
   "source": [
    "def load_and_combine_epochs_for_condition(part_directory, condition):\n",
    "    epochs_list = []\n",
    "    for block_file in part_directory.glob(f\"{condition}_{part_directory.stem}_*-epo.fif\"):\n",
    "        epochs = mne.read_epochs(block_file, preload=True)\n",
    "        # Check if this is participant \"AT\" and adjust channels\n",
    "        if part_directory.stem == \"AT\":\n",
    "            if condition == \"US\":\n",
    "                channels_to_drop = [ch for ch in ['FC6', 'CP2'] if ch in epochs.ch_names]\n",
    "                epochs.drop_channels(channels_to_drop)\n",
    "        if part_directory.stem == \"AJ\":\n",
    "            if condition == \"US\":\n",
    "                channels_to_drop = [ch for ch in ['FC6'] if ch in epochs.ch_names]\n",
    "                epochs.drop_channels(channels_to_drop)\n",
    "        if part_directory.stem == \"AP\":\n",
    "            if condition == \"AS\":\n",
    "                channels_to_drop = [ch for ch in ['CP6'] if ch in epochs.ch_names]\n",
    "                epochs.drop_channels(channels_to_drop)\n",
    "            if condition == \"AR\":\n",
    "                channels_to_drop = [ch for ch in ['CP6', 'CP2'] if ch in epochs.ch_names]\n",
    "                epochs.drop_channels(channels_to_drop)\n",
    "        epochs_list.append(epochs)\n",
    "    combined_epochs = mne.concatenate_epochs(epochs_list)\n",
    "    return combined_epochs\n",
    "\n",
    "conds_of_interest = [\"US\",\"AS\",\"UR\",\"AR\"]\n",
    "\n",
    "# Main processing loop\n",
    "all_parts22 = {}\n",
    "for part in Path(\"saved_epochs3\").iterdir():\n",
    "    evokeds = []\n",
    "    for cond in conds_of_interest:\n",
    "        # Load and combine epochs for each condition across blocks\n",
    "        combined_epochs = load_and_combine_epochs_for_condition(part, cond)\n",
    "        \n",
    "        if \"A\" in cond:\n",
    "            lat_cond = [f\"{cond}/lat_am\"]\n",
    "        elif \"U\" in cond:\n",
    "            lat_cond = [f\"{cond}/lat_unam_r\", f\"{cond}/lat_unam_l\"]\n",
    "\n",
    "        evoked = combined_epochs[lat_cond].average()\n",
    "        evoked.comment = cond  # Simplify condition name directly here\n",
    "        evokeds.append(evoked)\n",
    "\n",
    "    all_parts22[part.stem] = evokeds\n",
    "\n",
    "def simplify_condition(comment):\n",
    "    for cond in conds_of_interest:\n",
    "        if cond in comment:\n",
    "            return cond\n",
    "    return None\n",
    "\n",
    "def simplify_evoked_conditions(participant_evokeds):\n",
    "    simplified_evokeds = []\n",
    "    for evoked in participant_evokeds:\n",
    "        simplified_comment = simplify_condition(evoked.comment)\n",
    "        if simplified_comment:\n",
    "            evoked.comment = simplified_comment\n",
    "            simplified_evokeds.append(evoked)\n",
    "    return simplified_evokeds\n",
    "for participant in list(all_parts22):\n",
    "    all_parts22[participant] = simplify_evoked_conditions(all_parts22[participant])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 2021 #"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing ##"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger control ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Convert old trigger system to new one\"\"\"\n",
    "\n",
    "def get_new_events_old_trigger_system(orig_events, sfreq):\n",
    "    events = orig_events.copy()\n",
    "    samples = 1000 / sfreq\n",
    "    small_check_normal = 300 / samples\n",
    "    small_check_rev = 250 / samples\n",
    "    amb_lat = 200 / samples\n",
    "    unamb_left_lat = 100 / samples\n",
    "    unamb_right_lat = 150 / samples\n",
    "\n",
    "    # Define a dictionary to map old triggers to new ones\n",
    "    trigger_map = {\n",
    "        small_check_normal: 2,\n",
    "        small_check_rev: 4,\n",
    "        amb_lat: 6,\n",
    "        unamb_left_lat: 8,\n",
    "        unamb_right_lat: 10\n",
    "        \n",
    "    }\n",
    "\n",
    "    # Ignore initial values of 99999 and anything between 1000-1100\n",
    "    valid_start = np.argwhere((events[:, 2] == 13) & (events[:, 2] < 1000) | (events[:, 2] > 1100))\n",
    "    if valid_start.size == 0:\n",
    "        return events  # No valid start found, return original events\n",
    "\n",
    "    start_index = valid_start[0][0]\n",
    "\n",
    "    # Find all 13 triggers starting from the first valid start index\n",
    "    trig_13_indices = np.where(events[start_index:, 2] == 13)[0] + start_index\n",
    "    # Find all 12 triggers starting from the first valid start index\n",
    "    trig_12_indices = np.where(events[start_index:, 2] == 12)[0] + start_index\n",
    "\n",
    "    # Ensure there is a matching 12 for each 13\n",
    "    for idx_13 in trig_13_indices:\n",
    "        following_12 = trig_12_indices[trig_12_indices > idx_13]\n",
    "        if not following_12.size:\n",
    "            continue  # If there's no matching 12, skip this 13\n",
    "\n",
    "        idx_12 = following_12[0]\n",
    "        trigger_length = events[idx_12, 0] - events[idx_13, 0]\n",
    "        closest_trigger = min(trigger_map, key=lambda x: abs(x - trigger_length))\n",
    "        events[idx_13, 2] = trigger_map[closest_trigger]\n",
    "\n",
    "    return events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check triggers ###\n",
    "\"\"\"-> AI is excluded\"\"\"\n",
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data2\\\\AI\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"AS\"]\n",
    "\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "counter = 0\n",
    "all_event_codes = []\n",
    "all_event_codes2 = []\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_AI_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID\n",
    "    block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "\n",
    "    if file_cond in conds_of_interest and block_number == '02':\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        def check_event_pairs(orig_events):\n",
    "            paired_count = 0\n",
    "            unpaired_13 = []\n",
    "            unpaired_12 = []\n",
    "            ignore_codes = set(range(1000, 1101))\n",
    "            orig_events = np.array(orig_events)\n",
    "            # Look for 13 events and check if the next event is 12\n",
    "            for i, event in enumerate(orig_events):\n",
    "                if event[2] == 13:\n",
    "                    # Initialize a variable to keep track of the next relevant index\n",
    "                    next_relevant_index = i + 1\n",
    "                    \n",
    "                    # Skip any event codes between 1010 and 1100\n",
    "                    while next_relevant_index < len(orig_events) and orig_events[next_relevant_index][2] in ignore_codes:\n",
    "                        next_relevant_index += 1\n",
    "                        \n",
    "                    # If the next relevant event is 12, count as a pair\n",
    "                    if next_relevant_index < len(orig_events) and orig_events[next_relevant_index][2] == 12:\n",
    "                        paired_count += 1\n",
    "                    else:\n",
    "                        # Otherwise, the 13 event is unpaired\n",
    "                        unpaired_13.append(i)\n",
    "                        \n",
    "                elif event[2] == 12:\n",
    "                    # Check if the previous event is a 13 and not unpaired\n",
    "                    prev_relevant_index = i - 1\n",
    "                    \n",
    "                    # Skip any event codes between 1010 and 1100\n",
    "                    while prev_relevant_index >= 0 and orig_events[prev_relevant_index][2] in ignore_codes:\n",
    "                        prev_relevant_index -= 1\n",
    "                        \n",
    "                    # If the previous relevant event is not a 13, count this 12 as unpaired\n",
    "                    if prev_relevant_index < 0 or orig_events[prev_relevant_index][2] != 13:\n",
    "                        unpaired_12.append(i)\n",
    "\n",
    "            return paired_count, unpaired_13, unpaired_12\n",
    "\n",
    "\n",
    "\n",
    "        # Now let's call the function and print the results\n",
    "        paired_count, unpaired_13s, unpaired_12s = check_event_pairs(orig_events)\n",
    "        print(f\"Number of correctly paired '13' followed by '12': {paired_count}\")\n",
    "        print(f\"Unpaired '13' indices: {unpaired_13s}\")\n",
    "        print(f\"Unpaired '12' indices: {unpaired_12s}\")\n",
    "            \n",
    "        # Find indices of triggers 12 and 13\n",
    "        trig_12_indices = np.where(orig_events[:, 2] == 12)[0]\n",
    "        trig_13_indices = np.where(orig_events[:, 2] == 13)[0]\n",
    "            \n",
    "        # Iterate through the indices of triggers 13\n",
    "        for trig_12_index in trig_12_indices:\n",
    "            # Find the corresponding trigger 12 that comes before the current trigger 13\n",
    "            previous_trig_13_index = trig_13_indices[trig_13_indices < trig_12_index]\n",
    "            if previous_trig_13_index.size > 0:  # Check if a previous trigger 12 exists\n",
    "                previous_trig_13_index = previous_trig_13_index[-1]\n",
    "                # Calculate the difference in sample points\n",
    "                difference = orig_events[trig_12_index, 0] - orig_events[previous_trig_13_index, 0]\n",
    "                print(f\"Difference {counter + 1}: {difference}\")\n",
    "                # Add the difference to the list\n",
    "                # sample_differences.append(difference)\n",
    "                # Increment the counter\n",
    "                counter += 1\n",
    "                if counter == 20:  # Stop after printing 20 differences\n",
    "                    break\n",
    "            if counter == 20:  # Check if we need to break out of the outer loop as well\n",
    "                break\n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant AA ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data2\\\\AA\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"AS\",\"US\",\"UR\"]\n",
    "conds_of_interest2 = [\"AR\"]\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "\n",
    "all_event_codes = []\n",
    "all_event_codes2 = []\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_AA_*.vhdr\"):  ### has only one block\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID (e.g., \"AB\")\n",
    "    block_number = file_parts[2]  # Block number (e.D., \"01\")\n",
    "\n",
    "    if file_cond in conds_of_interest: \n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    " \n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        # raw.plot()\n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = get_new_events_old_trigger_system(orig_events, raw.info[\"sfreq\"]) #####\n",
    "        \n",
    "        events.shape\n",
    "        # Plot events\n",
    "        # mne.viz.plot_events(events, event_id=event_id, sfreq=raw.info['sfreq'])\n",
    "        \n",
    "        # so cut raw into epochs\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        \n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        ica.plot_components()\n",
    "        ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs2')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)\n",
    "    if file_cond in conds_of_interest2:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        raw.drop_channels(['FC6']) ## noisy channel\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    " \n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        # raw.plot()\n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = get_new_events_old_trigger_system(orig_events, raw.info[\"sfreq\"]) #####\n",
    "        \n",
    "        events.shape\n",
    "        # Plot events\n",
    "        # mne.viz.plot_events(events, event_id=event_id, sfreq=raw.info['sfreq'])\n",
    "        \n",
    "        # so cut raw into epochs\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        \n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        ica.plot_components()\n",
    "        ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        # epochs.plot()\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot()\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs2')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant AB ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data2\\\\AB\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"AS\",\"AR\",\"US\",\"UR\"]\n",
    "\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "\n",
    "all_event_codes = []\n",
    "all_event_codes2 = []\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_AB_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID (e.g., \"AB\")\n",
    "    block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = get_new_events_old_trigger_system(orig_events, raw.info[\"sfreq\"]) #####\n",
    "        \n",
    "        events.shape\n",
    "        # Plot events\n",
    "        # mne.viz.plot_events(events, event_id=event_id, sfreq=raw.info['sfreq'])\n",
    "        \n",
    "        # so cut raw into epochs\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        \n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs2')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant AC ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data2\\\\AC\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"AS\",\"AR\",\"US\",\"UR\"]\n",
    "\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "\n",
    "all_event_codes = []\n",
    "all_event_codes2 = []\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_AC_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID (e.g., \"AB\")\n",
    "    block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = get_new_events_old_trigger_system(orig_events, raw.info[\"sfreq\"]) #####\n",
    "        \n",
    "        events.shape\n",
    "        # Plot events\n",
    "        # mne.viz.plot_events(events, event_id=event_id, sfreq=raw.info['sfreq'])\n",
    "   \n",
    "        # so cut raw into epochs\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        \n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs2')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant AD ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from C:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\Data2\\AD\\AR_AD_01.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 157099  =      0.000 ...   157.099 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.03\n",
      "- Lower transition bandwidth: 0.03 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 110001 samples (110.001 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3396187499.py:38: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Response/R  7', 'Response/R 15', 'Stimulus/S 12', 'Stimulus/S 13']\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 304 events and 601 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    2.3s remaining:   21.7s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    2.4s remaining:    7.5s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    2.4s remaining:    3.7s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    2.5s remaining:    2.0s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    2.6s remaining:    1.0s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    2.7s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    2.7s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.9s remaining:    9.1s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    1.0s remaining:    3.1s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    1.0s remaining:    1.6s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    1.0s remaining:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    1.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    1.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done]\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "Interpolating bad channels.\n",
      "    Automatic origin fit: head of radius 96.0 mm\n",
      "Computing interpolation matrix from 30 sensor positions\n",
      "Interpolating 1 sensors\n",
      "Cz\n",
      "Fitting ICA to data using 31 channels (please be patient, this may take a while)\n",
      "Selecting by number: 30 components\n",
      "Fitting ICA took 6.8s.\n",
      "Using EOG channels: Fp1, Fp2\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (30 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 31 PCA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "Applying baseline correction (mode: mean)\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F3', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "55 bad epochs dropped\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "Extracting parameters from C:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\Data2\\AD\\AR_AD_02.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 155039  =      0.000 ...   155.039 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.03\n",
      "- Lower transition bandwidth: 0.03 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 110001 samples (110.001 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3396187499.py:38: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Response/R  7', 'Response/R 15', 'Stimulus/S 12', 'Stimulus/S 13']\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 304 events and 601 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Batch computation too fast (0.0470271110534668s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.8s remaining:    8.0s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.9s remaining:    3.0s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    1.0s remaining:    1.5s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    1.0s remaining:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    1.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    1.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done]\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "Interpolating bad channels.\n",
      "    Automatic origin fit: head of radius 96.0 mm\n",
      "Computing interpolation matrix from 30 sensor positions\n",
      "Interpolating 1 sensors\n",
      "Cz\n",
      "Fitting ICA to data using 31 channels (please be patient, this may take a while)\n",
      "Selecting by number: 30 components\n",
      "Fitting ICA took 2.4s.\n",
      "Using EOG channels: Fp1, Fp2\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (30 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 31 PCA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "Applying baseline correction (mode: mean)\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F3', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "43 bad epochs dropped\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "Extracting parameters from C:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\Data2\\AD\\AS_AD_01.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 160759  =      0.000 ...   160.759 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.03\n",
      "- Lower transition bandwidth: 0.03 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 110001 samples (110.001 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3396187499.py:38: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S 12', 'Stimulus/S 13']\n",
      "Not setting metadata\n",
      "303 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 303 events and 601 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Batch computation too fast (0.04590439796447754s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.9s remaining:    8.7s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.9s remaining:    2.9s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    1.0s remaining:    1.5s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    1.0s remaining:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    1.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    1.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done]\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "\n",
      "Fitting ICA to data using 31 channels (please be patient, this may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\autoreject\\ransac.py:244: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  epochs.interpolate_bads(reset_bads=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by number: 30 components\n",
      "Fitting ICA took 5.5s.\n",
      "Using EOG channels: Fp1, Fp2\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (30 components)\n",
      "    Zeroing out 1 ICA component\n",
      "    Projecting back using 31 PCA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "Applying baseline correction (mode: mean)\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F3', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['F3', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['F3', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "300 bad epochs dropped\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "Extracting parameters from C:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\Data2\\AD\\AS_AD_02.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 174999  =      0.000 ...   174.999 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.03\n",
      "- Lower transition bandwidth: 0.03 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 110001 samples (110.001 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3396187499.py:38: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Response/R  7', 'Response/R 15', 'Stimulus/S 12', 'Stimulus/S 13']\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 304 events and 601 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Batch computation too fast (0.058803558349609375s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.0s remaining:    0.5s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.9s remaining:    9.3s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    1.0s remaining:    3.1s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    1.0s remaining:    1.5s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    1.0s remaining:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    1.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    1.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done]\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "\n",
      "Fitting ICA to data using 31 channels (please be patient, this may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\autoreject\\ransac.py:244: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  epochs.interpolate_bads(reset_bads=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by number: 30 components\n",
      "Fitting ICA took 4.5s.\n",
      "Using EOG channels: Fp1, Fp2\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (30 components)\n",
      "    Zeroing out 1 ICA component\n",
      "    Projecting back using 31 PCA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "Applying baseline correction (mode: mean)\n",
      "0 bad epochs dropped\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "Extracting parameters from C:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\Data2\\AD\\AS_AD_03.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 156679  =      0.000 ...   156.679 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.03\n",
      "- Lower transition bandwidth: 0.03 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 110001 samples (110.001 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3396187499.py:38: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Response/R  7', 'Response/R 15', 'Stimulus/S 12', 'Stimulus/S 13']\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 304 events and 601 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Batch computation too fast (0.051062822341918945s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.9s remaining:    9.3s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    1.0s remaining:    3.2s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    1.0s remaining:    1.6s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    1.0s remaining:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    1.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    1.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done]\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "\n",
      "Fitting ICA to data using 31 channels (please be patient, this may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\autoreject\\ransac.py:244: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  epochs.interpolate_bads(reset_bads=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by number: 30 components\n",
      "Fitting ICA took 5.0s.\n",
      "Using EOG channels: Fp1, Fp2\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (30 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 31 PCA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "Applying baseline correction (mode: mean)\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F3', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F3', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "54 bad epochs dropped\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "Extracting parameters from C:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\Data2\\AD\\UR_AD_01.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 156759  =      0.000 ...   156.759 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.03\n",
      "- Lower transition bandwidth: 0.03 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 110001 samples (110.001 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3396187499.py:38: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Response/R  5', 'Response/R  7', 'Response/R 13', 'Response/R 15', 'Stimulus/S 12', 'Stimulus/S 13']\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 304 events and 601 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Batch computation too fast (0.052074432373046875s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.9s remaining:    9.2s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    1.0s remaining:    3.1s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    1.0s remaining:    1.6s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    1.1s remaining:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    1.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    1.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done]\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "\n",
      "Fitting ICA to data using 31 channels (please be patient, this may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\autoreject\\ransac.py:244: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  epochs.interpolate_bads(reset_bads=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by number: 30 components\n",
      "Fitting ICA took 7.1s.\n",
      "Using EOG channels: Fp1, Fp2\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (30 components)\n",
      "    Zeroing out 1 ICA component\n",
      "    Projecting back using 31 PCA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "Applying baseline correction (mode: mean)\n",
      "0 bad epochs dropped\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "Extracting parameters from C:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\Data2\\AD\\UR_AD_02.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 155039  =      0.000 ...   155.039 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.03\n",
      "- Lower transition bandwidth: 0.03 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 110001 samples (110.001 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3396187499.py:38: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Response/R  7', 'Response/R 13', 'Response/R 15', 'Stimulus/S 12', 'Stimulus/S 13']\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 304 events and 601 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Batch computation too fast (0.042584896087646484s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.0s remaining:    0.3s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.9s remaining:    9.2s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    1.0s remaining:    3.1s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    1.1s remaining:    1.7s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    1.1s remaining:    0.9s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    1.1s remaining:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done]\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "\n",
      "Fitting ICA to data using 31 channels (please be patient, this may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    1.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    1.2s finished\n",
      "c:\\Python311\\Lib\\site-packages\\autoreject\\ransac.py:244: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  epochs.interpolate_bads(reset_bads=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by number: 30 components\n",
      "Fitting ICA took 4.9s.\n",
      "Using EOG channels: Fp1, Fp2\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (30 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 31 PCA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "Applying baseline correction (mode: mean)\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F3', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F3', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "21 bad epochs dropped\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "Extracting parameters from C:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\Data2\\AD\\US_AD_01.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 157199  =      0.000 ...   157.199 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.03\n",
      "- Lower transition bandwidth: 0.03 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 110001 samples (110.001 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3396187499.py:38: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Response/R  7', 'Response/R 13', 'Response/R 15', 'Stimulus/S 12', 'Stimulus/S 13']\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 304 events and 601 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Batch computation too fast (0.048114776611328125s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.0s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    1.0s remaining:    9.6s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    1.0s remaining:    3.2s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    1.1s remaining:    1.6s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    1.1s remaining:    0.9s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    1.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    1.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done]\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "\n",
      "Fitting ICA to data using 31 channels (please be patient, this may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\autoreject\\ransac.py:244: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  epochs.interpolate_bads(reset_bads=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by number: 30 components\n",
      "Fitting ICA took 4.1s.\n",
      "Using EOG channels: Fp1, Fp2\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (30 components)\n",
      "    Zeroing out 1 ICA component\n",
      "    Projecting back using 31 PCA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "Applying baseline correction (mode: mean)\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'F7', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp2']\n",
      "303 bad epochs dropped\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n",
      "Extracting parameters from C:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\Data2\\AD\\US_AD_02.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 156999  =      0.000 ...   156.999 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.03 - 25 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.03\n",
      "- Lower transition bandwidth: 0.03 Hz (-6 dB cutoff frequency: 0.01 Hz)\n",
      "- Upper passband edge: 25.00 Hz\n",
      "- Upper transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 28.12 Hz)\n",
      "- Filter length: 110001 samples (110.001 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3396187499.py:38: RuntimeWarning: Online software filter detected. Using software filter settings and ignoring hardware values\n",
      "  raw = mne.io.read_raw_brainvision(file,preload=True)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Response/R  5', 'Response/R  7', 'Response/R 13', 'Response/R 15', 'Stimulus/S 12', 'Stimulus/S 13']\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 304 events and 601 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Batch computation too fast (0.07461881637573242s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.0s remaining:    0.6s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    0.0s remaining:    0.2s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done   2 out of  20 | elapsed:    0.9s remaining:    9.3s\n",
      "[Parallel(n_jobs=20)]: Done   5 out of  20 | elapsed:    1.0s remaining:    3.2s\n",
      "[Parallel(n_jobs=20)]: Done   8 out of  20 | elapsed:    1.0s remaining:    1.6s\n",
      "[Parallel(n_jobs=20)]: Done  11 out of  20 | elapsed:    1.0s remaining:    0.8s\n",
      "[Parallel(n_jobs=20)]: Done  14 out of  20 | elapsed:    1.1s remaining:    0.4s\n",
      "[Parallel(n_jobs=20)]: Done  17 out of  20 | elapsed:    1.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=20)]: Done  20 out of  20 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done]\n",
      "Setting channel interpolation method to {'eeg': 'spline'}.\n",
      "\n",
      "Fitting ICA to data using 31 channels (please be patient, this may take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\autoreject\\ransac.py:244: RuntimeWarning: No bad channels to interpolate. Doing nothing...\n",
      "  epochs.interpolate_bads(reset_bads=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting by number: 30 components\n",
      "Fitting ICA took 4.0s.\n",
      "Using EOG channels: Fp1, Fp2\n",
      "Applying ICA to Epochs instance\n",
      "    Transforming to ICA space (30 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 31 PCA components\n",
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n",
      "Applying baseline correction (mode: mean)\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "    Rejecting  epoch based on EEG : ['Fp1', 'Fp2']\n",
      "12 bad epochs dropped\n",
      "Overwriting existing file.\n",
      "Overwriting existing file.\n"
     ]
    }
   ],
   "source": [
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data2\\\\AD\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"AS\",\"AR\",\"US\",\"UR\"]\n",
    "\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_AD_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID (e.g., \"AB\")\n",
    "    block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "\n",
    "    if file_cond in conds_of_interest: ### block 01 was excluded, block 2 and 3 were analyzed\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = get_new_events_old_trigger_system(orig_events, raw.info[\"sfreq\"]) #####\n",
    "        \n",
    "        events.shape\n",
    "        # Plot events\n",
    "        # mne.viz.plot_events(events, event_id=event_id, sfreq=raw.info['sfreq'])\n",
    "        \n",
    "        # so cut raw into epochs\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        \n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.8)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs2')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant AE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"AE was excluded\"\"\"\n",
    "\n",
    "# # get data path to specific participant\n",
    "# participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data2\\\\AE\")\n",
    "\n",
    "# # conditions we are interested in as a list\n",
    "# conds_of_interest = [\"AS\",\"US\",\"UR\"]\n",
    "# conds_of_interest2 = [\"AR\"]\n",
    "# # tmin and tmax of epochs\n",
    "# tmin = -0.1\n",
    "# tmax = 0.5\n",
    "\n",
    "# all_event_codes = []\n",
    "# all_event_codes2 = []\n",
    "# # Participant name\n",
    "# participant_id = participant_path.stem\n",
    "\n",
    "# for file in participant_path.glob(\"*_AE_*.vhdr\"):\n",
    "#     # Extract the condition and block from the file name \n",
    "#     file_parts = file.stem.split('_')\n",
    "#     file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "#     participant_id = file_parts[1]  # Participant ID (e.g., \"AB\")\n",
    "#     block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "\n",
    "#     if file_cond in conds_of_interest:\n",
    "#         # event triggers as dict used file cond info\n",
    "#         event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "#                     f\"{file_cond}/checks_rev\": 4,\n",
    "#                     f\"{file_cond}/lat_am\": 6}\n",
    "#         event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "#                     f\"{file_cond}/checks_rev\": 4,\n",
    "#                     f\"{file_cond}/lat_unam_l\": 8,\n",
    "#                     f\"{file_cond}/lat_unam_r\": 10}\n",
    "#         # get event_id corresponding with condition\n",
    "#         if \"A\" in file_cond:\n",
    "#             event_id = event_id_am\n",
    "#         elif \"U\" in file_cond:\n",
    "#             event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "#        # load raw data\n",
    "#         raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "#         # only pick eeg channels\n",
    "#         raw.pick(\"eeg\")\n",
    "        \n",
    "#         # raw.plot()\n",
    "#         raw.set_montage('standard_1020')\n",
    "#         ####\n",
    "#         # orig_events, _ = mne.events_from_annotations(raw)\n",
    "#         # events = get_new_events_old_trigger_system(orig_events, raw.info[\"sfreq\"]) #####\n",
    "#         # print(events)\n",
    "        \n",
    "        \n",
    "#         # filter data\n",
    "#         raw.filter(0.03,25)\n",
    "#         # raw.plot_psd(fmax=40)\n",
    "#         raw.pick([\"eeg\"]).load_data()\n",
    "#         # raw.info\n",
    "#         # raw.plot_sensors(show_names=True)\n",
    "#         # fig = raw.plot_sensors(\"3d\")\n",
    "#         # fig\n",
    "        \n",
    "#         # get triggers\n",
    "#         orig_events, _ = mne.events_from_annotations(raw)\n",
    "#         events = get_new_events_old_trigger_system(orig_events, raw.info[\"sfreq\"]) #####\n",
    "        \n",
    "#         events.shape\n",
    "#         # Plot events\n",
    "#         # mne.viz.plot_events(events, event_id=event_id, sfreq=raw.info['sfreq'])\n",
    "        \n",
    "#         # find band channels and interpolate\n",
    "#         # code only works if data is in epochs\n",
    "#         # so cut raw into epochs\n",
    "#         epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "#         picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "#         stim=False, eog=False,\n",
    "#         include=[], exclude=[])\n",
    "#         ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "#         epochs = ransac.fit_transform(epochs)\n",
    "#         print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "#         # epochs.plot()\n",
    "        \n",
    "#         # compute an ICA to remove eye blink components from signal\n",
    "#         ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "#         ica.fit(epochs)\n",
    "#         ica.exclude = []\n",
    "#         eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "#         ica.exclude = eog_idx\n",
    "#         # ica.plot_scores(scores)\n",
    "#         # ica.plot_components()\n",
    "#         # ica.plot_sources(epochs)\n",
    "#         epochs_new = epochs.copy()\n",
    "#         ica.apply(epochs_new)\n",
    "#         epochs = epochs_new\n",
    "        \n",
    "#         # set offline reference at mastoid electrodes\n",
    "#         epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "#         # apply baseline in ms\n",
    "#         epochs.apply_baseline((-0.1,0))\n",
    "#         # reject epochs that are above a certain threshold\n",
    "#         # value needs to be in volts\n",
    "#         epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "#         # epochs.plot_drop_log()\n",
    "#         # save epoch objects and events array\n",
    "#         epoch_path = Path('saved_epochs2')\n",
    "#         folder_path = Path(epoch_path,participant_id)\n",
    "#         # Check if saved_epochs folder already exists\n",
    "#         if not epoch_path.exists():\n",
    "#             # Create the folder\n",
    "#             epoch_path.mkdir(parents=True)\n",
    "#         # Check if participant folder already exists\n",
    "#         if not folder_path.exists():\n",
    "#             # Create the folder\n",
    "#             folder_path.mkdir(parents=True)\n",
    "#         # Construct the filename with condition, participant ID, and block number\n",
    "#         epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "#         annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "#         # Save the epochs and annotations\n",
    "#         epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "#         np.save(folder_path / annotations_filename, events)\n",
    "#     if file_cond in conds_of_interest2 and block_number == \"01\":\n",
    "#         # event triggers as dict used file cond info\n",
    "#         event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "#                     f\"{file_cond}/checks_rev\": 4,\n",
    "#                     f\"{file_cond}/lat_am\": 6}\n",
    "#         event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "#                     f\"{file_cond}/checks_rev\": 4,\n",
    "#                     f\"{file_cond}/lat_unam_l\": 8,\n",
    "#                     f\"{file_cond}/lat_unam_r\": 10}\n",
    "#         # get event_id corresponding with condition\n",
    "#         if \"A\" in file_cond:\n",
    "#             event_id = event_id_am\n",
    "#         elif \"U\" in file_cond:\n",
    "#             event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "#        # load raw data\n",
    "#         raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "#         # only pick eeg channels\n",
    "#         raw.pick(\"eeg\")\n",
    "        \n",
    "#         # raw.plot()\n",
    "#         raw.set_montage('standard_1020')\n",
    "#         ####\n",
    "#         # orig_events, _ = mne.events_from_annotations(raw)\n",
    "#         # events = get_new_events_old_trigger_system(orig_events, raw.info[\"sfreq\"]) #####\n",
    "#         # print(events)\n",
    "        \n",
    "        \n",
    "#         # filter data\n",
    "#         raw.filter(0.03,25)\n",
    "#         # raw.plot_psd(fmax=40)\n",
    "#         raw.pick([\"eeg\"]).load_data()\n",
    "#         # raw.info\n",
    "#         # raw.plot_sensors(show_names=True)\n",
    "#         # fig = raw.plot_sensors(\"3d\")\n",
    "#         # fig\n",
    "        \n",
    "#         # get triggers\n",
    "#         orig_events, _ = mne.events_from_annotations(raw)\n",
    "#         events = get_new_events_old_trigger_system(orig_events, raw.info[\"sfreq\"]) #####\n",
    "        \n",
    "#         events.shape\n",
    "#         # Plot events\n",
    "#         # mne.viz.plot_events(events, event_id=event_id, sfreq=raw.info['sfreq'])\n",
    "        \n",
    "#         # find band channels and interpolate\n",
    "#         # code only works if data is in epochs\n",
    "#         # so cut raw into epochs\n",
    "#         epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "#         picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "#         stim=False, eog=False,\n",
    "#         include=[], exclude=[])\n",
    "#         ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "#         epochs = ransac.fit_transform(epochs)\n",
    "#         print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "#         # epochs.plot()\n",
    "        \n",
    "#         # compute an ICA to remove eye blink components from signal\n",
    "#         ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "#         ica.fit(epochs)\n",
    "#         ica.exclude = []\n",
    "#         eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "#         ica.exclude = eog_idx\n",
    "#         # ica.plot_scores(scores)\n",
    "#         # ica.plot_components()\n",
    "#         # ica.plot_sources(epochs)\n",
    "#         epochs_new = epochs.copy()\n",
    "#         ica.apply(epochs_new)\n",
    "#         epochs = epochs_new\n",
    "        \n",
    "#         # set offline reference at mastoid electrodes\n",
    "#         epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "#         # apply baseline in ms\n",
    "#         epochs.apply_baseline((-0.1,0))\n",
    "#         # reject epochs that are above a certain threshold\n",
    "#         # value needs to be in volts\n",
    "#         epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "#         # epochs.plot_drop_log()\n",
    "#         # save epoch objects and events array\n",
    "#         epoch_path = Path('saved_epochs2')\n",
    "#         folder_path = Path(epoch_path,participant_id)\n",
    "#         # Check if saved_epochs folder already exists\n",
    "#         if not epoch_path.exists():\n",
    "#             # Create the folder\n",
    "#             epoch_path.mkdir(parents=True)\n",
    "#         # Check if participant folder already exists\n",
    "#         if not folder_path.exists():\n",
    "#             # Create the folder\n",
    "#             folder_path.mkdir(parents=True)\n",
    "#         # Construct the filename with condition, participant ID, and block number\n",
    "#         epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "#         annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "#         # Save the epochs and annotations\n",
    "#         epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "#         np.save(folder_path / annotations_filename, events)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant AF ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data2\\\\AF\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"AS\",\"AR\",\"US\",\"UR\"]\n",
    "\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "\n",
    "\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_AF_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID (e.g., \"AB\")\n",
    "    block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "      \n",
    "        \n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = get_new_events_old_trigger_system(orig_events, raw.info[\"sfreq\"]) #####\n",
    "        \n",
    "        events.shape\n",
    "        # Plot events\n",
    "        # mne.viz.plot_events(events, event_id=event_id, sfreq=raw.info['sfreq'])\n",
    "        \n",
    "        # so cut raw into epochs\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        \n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs2')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant AH ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data2\\\\AH\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"AS\",\"AR\",\"US\",\"UR\"]\n",
    "\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_AH_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID (e.g., \"AB\")\n",
    "    block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "  \n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = get_new_events_old_trigger_system(orig_events, raw.info[\"sfreq\"]) #####\n",
    "        \n",
    "        events.shape\n",
    "        # Plot events\n",
    "        # mne.viz.plot_events(events, event_id=event_id, sfreq=raw.info['sfreq'])\n",
    "        \n",
    "      \n",
    "        # cut raw into epochs\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        \n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.75)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs2')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant AG ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data2\\\\AG\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"AS\",\"AR\",\"US\",\"UR\"]\n",
    "\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "\n",
    "\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_AG_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID (e.g., \"AB\")\n",
    "    block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = get_new_events_old_trigger_system(orig_events, raw.info[\"sfreq\"]) #####\n",
    "        \n",
    "        events.shape\n",
    "        # Plot events\n",
    "        # mne.viz.plot_events(events, event_id=event_id, sfreq=raw.info['sfreq'])\n",
    "        \n",
    "    \n",
    "        # cut raw into epochs\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        \n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.65)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs2')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant AI ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"--> AI was excluded\"\"\"\n",
    "# # get data path to specific participant\n",
    "# participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data2\\\\AI\")\n",
    "\n",
    "# # conditions we are interested in as a list\n",
    "# conds_of_interest = [\"AR\",\"US\",\"UR\"]\n",
    "# conds_of_interest2 = [\"AS\"] \n",
    "# # tmin and tmax of epochs\n",
    "# tmin = -0.1\n",
    "# tmax = 0.5\n",
    "\n",
    "# # Participant name\n",
    "# participant_id = participant_path.stem\n",
    "\n",
    "# for file in participant_path.glob(\"*_AI_*.vhdr\"):\n",
    "#     # Extract the condition and block from the file name \n",
    "#     file_parts = file.stem.split('_')\n",
    "#     file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "#     participant_id = file_parts[1]  # Participant ID (e.g., \"AB\")\n",
    "#     block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "\n",
    "#     if file_cond in conds_of_interest:\n",
    "#         # event triggers as dict used file cond info\n",
    "#         event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "#                     f\"{file_cond}/checks_rev\": 4,\n",
    "#                     f\"{file_cond}/lat_am\": 6}\n",
    "#         event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "#                     f\"{file_cond}/checks_rev\": 4,\n",
    "#                     f\"{file_cond}/lat_unam_l\": 8,\n",
    "#                     f\"{file_cond}/lat_unam_r\": 10}\n",
    "#         # get event_id corresponding with condition\n",
    "#         if \"A\" in file_cond:\n",
    "#             event_id = event_id_am\n",
    "#         elif \"U\" in file_cond:\n",
    "#             event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "#        # load raw data\n",
    "#         raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "#         # only pick eeg channels\n",
    "#         raw.pick(\"eeg\")\n",
    "        \n",
    "#         # raw.plot()\n",
    "#         raw.set_montage('standard_1020')\n",
    "#         ####\n",
    "#         # orig_events, _ = mne.events_from_annotations(raw)\n",
    "#         # events = get_new_events_old_trigger_system(orig_events, raw.info[\"sfreq\"]) #####\n",
    "#         # print(events)\n",
    "        \n",
    "        \n",
    "#         # filter data\n",
    "#         raw.filter(0.03,25)\n",
    "#         # raw.plot_psd(fmax=40)\n",
    "#         raw.pick([\"eeg\"]).load_data()\n",
    "#         # raw.info\n",
    "#         # raw.plot_sensors(show_names=True)\n",
    "#         # fig = raw.plot_sensors(\"3d\")\n",
    "#         # fig\n",
    "        \n",
    "#         # get triggers\n",
    "#         orig_events, _ = mne.events_from_annotations(raw)\n",
    "#         events = get_new_events_old_trigger_system(orig_events, raw.info[\"sfreq\"]) #####\n",
    "        \n",
    "#         events.shape\n",
    "#         # Plot events\n",
    "#         # mne.viz.plot_events(events, event_id=event_id, sfreq=raw.info['sfreq'])\n",
    "        \n",
    "#         # find band channels and interpolate\n",
    "#         # code only works if data is in epochs\n",
    "#         # so cut raw into epochs\n",
    "#         epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "#         picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "#         stim=False, eog=False,\n",
    "#         include=[], exclude=[])\n",
    "#         ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "#         epochs = ransac.fit_transform(epochs)\n",
    "#         print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "#         # epochs.plot()\n",
    "        \n",
    "#         # compute an ICA to remove eye blink components from signal\n",
    "#         ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "#         ica.fit(epochs)\n",
    "#         ica.exclude = []\n",
    "#         eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.65)\n",
    "#         ica.exclude = eog_idx\n",
    "#         # ica.plot_scores(scores)\n",
    "#         # ica.plot_components()\n",
    "#         # ica.plot_sources(epochs)\n",
    "#         epochs_new = epochs.copy()\n",
    "#         ica.apply(epochs_new)\n",
    "#         epochs = epochs_new\n",
    "        \n",
    "#         # set offline reference at mastoid electrodes\n",
    "#         epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "#         # apply baseline in ms\n",
    "#         epochs.apply_baseline((-0.1,0))\n",
    "#         # reject epochs that are above a certain threshold\n",
    "#         # value needs to be in volts\n",
    "#         epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "#         # epochs.plot_drop_log()\n",
    "#         # save epoch objects and events array\n",
    "#         epoch_path = Path('saved_epochs2')\n",
    "#         folder_path = Path(epoch_path,participant_id)\n",
    "#         # Check if saved_epochs folder already exists\n",
    "#         if not epoch_path.exists():\n",
    "#             # Create the folder\n",
    "#             epoch_path.mkdir(parents=True)\n",
    "#         # Check if participant folder already exists\n",
    "#         if not folder_path.exists():\n",
    "#             # Create the folder\n",
    "#             folder_path.mkdir(parents=True)\n",
    "#         # Construct the filename with condition, participant ID, and block number\n",
    "#         epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "#         annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "#         # Save the epochs and annotations\n",
    "#         epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "#         np.save(folder_path / annotations_filename, events)\n",
    "        \n",
    "#     if file_cond in conds_of_interest2 and block_number == \"01\":\n",
    "#         # event triggers as dict used file cond info\n",
    "#         event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "#                     f\"{file_cond}/checks_rev\": 4,\n",
    "#                     f\"{file_cond}/lat_am\": 6}\n",
    "#         event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "#                     f\"{file_cond}/checks_rev\": 4,\n",
    "#                     f\"{file_cond}/lat_unam_l\": 8,\n",
    "#                     f\"{file_cond}/lat_unam_r\": 10}\n",
    "#         # get event_id corresponding with condition\n",
    "#         if \"A\" in file_cond:\n",
    "#             event_id = event_id_am\n",
    "#         elif \"U\" in file_cond:\n",
    "#             event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "#        # load raw data\n",
    "#         raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "#         # only pick eeg channels\n",
    "#         raw.pick(\"eeg\")\n",
    "        \n",
    "#         # raw.plot()\n",
    "#         raw.set_montage('standard_1020')\n",
    "#         ####\n",
    "#         # orig_events, _ = mne.events_from_annotations(raw)\n",
    "#         # events = get_new_events_old_trigger_system(orig_events, raw.info[\"sfreq\"]) #####\n",
    "#         # print(events)\n",
    "        \n",
    "        \n",
    "#         # filter data\n",
    "#         raw.filter(0.03,25)\n",
    "#         # raw.plot_psd(fmax=40)\n",
    "#         raw.pick([\"eeg\"]).load_data()\n",
    "#         # raw.info\n",
    "#         # raw.plot_sensors(show_names=True)\n",
    "#         # fig = raw.plot_sensors(\"3d\")\n",
    "#         # fig\n",
    "        \n",
    "#         # get triggers\n",
    "#         orig_events, _ = mne.events_from_annotations(raw)\n",
    "#         events = get_new_events_old_trigger_system(orig_events, raw.info[\"sfreq\"]) #####\n",
    "        \n",
    "#         events.shape\n",
    "#         # Plot events\n",
    "#         # mne.viz.plot_events(events, event_id=event_id, sfreq=raw.info['sfreq'])\n",
    "        \n",
    "#         # find band channels and interpolate\n",
    "#         # code only works if data is in epochs\n",
    "#         # so cut raw into epochs\n",
    "#         epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None,tmin=tmin,tmax=tmax,proj=True,preload=True)\n",
    "\n",
    "#         picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "#         stim=False, eog=False,\n",
    "#         include=[], exclude=[])\n",
    "#         ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "#         epochs = ransac.fit_transform(epochs)\n",
    "#         print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "#         # epochs.plot()\n",
    "        \n",
    "#         # compute an ICA to remove eye blink components from signal\n",
    "#         ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "#         ica.fit(epochs)\n",
    "#         ica.exclude = []\n",
    "#         eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.65)\n",
    "#         ica.exclude = eog_idx\n",
    "#         # ica.plot_scores(scores)\n",
    "#         # ica.plot_components()\n",
    "#         # ica.plot_sources(epochs)\n",
    "#         epochs_new = epochs.copy()\n",
    "#         ica.apply(epochs_new)\n",
    "#         epochs = epochs_new\n",
    "        \n",
    "#         # set offline reference at mastoid electrodes\n",
    "#         epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "#         # apply baseline in ms\n",
    "#         epochs.apply_baseline((-0.1,0))\n",
    "#         # reject epochs that are above a certain threshold\n",
    "#         # value needs to be in volts\n",
    "#         epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "#         # epochs.plot_drop_log()\n",
    "#         # save epoch objects and events array\n",
    "#         epoch_path = Path('saved_epochs2')\n",
    "#         folder_path = Path(epoch_path,participant_id)\n",
    "#         # Check if saved_epochs folder already exists\n",
    "#         if not epoch_path.exists():\n",
    "#             # Create the folder\n",
    "#             epoch_path.mkdir(parents=True)\n",
    "#         # Check if participant folder already exists\n",
    "#         if not folder_path.exists():\n",
    "#             # Create the folder\n",
    "#             folder_path.mkdir(parents=True)\n",
    "#         # Construct the filename with condition, participant ID, and block number\n",
    "#         epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "#         annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "#         # Save the epochs and annotations\n",
    "#         epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "#         np.save(folder_path / annotations_filename, events)    \n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Evoked data 2021 ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AA\\US_AA_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "399 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "399 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AA\\AS_AA_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "400 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AA\\UR_AA_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "400 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AA\\AR_AA_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "400 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "400 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AB\\US_AB_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AB\\US_AB_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "608 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AB\\AS_AB_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AB\\AS_AB_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "605 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AB\\UR_AB_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "303 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AB\\UR_AB_02-epo.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "303 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "606 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AB\\AR_AB_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "303 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AB\\AR_AB_02-epo.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "303 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "606 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AC\\US_AC_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AC\\US_AC_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "607 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AC\\AS_AC_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AC\\AS_AC_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "276 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "580 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AC\\UR_AC_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AC\\UR_AC_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "608 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AC\\AR_AC_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "303 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AC\\AR_AC_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "607 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AD\\US_AD_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "1 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AD\\US_AD_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "293 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AD\\AS_AD_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AD\\AS_AD_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AD\\AS_AD_03-epo.fif ...\n",
      "    Found the data of interest:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "250 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "557 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AD\\UR_AD_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AD\\UR_AD_02-epo.fif ...\n",
      "    Found the data of interest:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "283 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "587 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AD\\AR_AD_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "249 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AD\\AR_AD_02-epo.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "261 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "510 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AF\\US_AF_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "302 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AF\\US_AF_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "606 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AF\\AS_AF_01-epo.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AF\\AS_AF_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "608 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AF\\UR_AF_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "301 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AF\\UR_AF_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "605 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AF\\AR_AF_01-epo.fif ...\n",
      "    Found the data of interest:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "302 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AF\\AR_AF_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "606 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AG\\US_AG_01-epo.fif ...\n",
      "    Found the data of interest:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "303 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AG\\US_AG_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "303 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "606 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AG\\AS_AG_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AG\\AS_AG_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "184 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AG\\AS_AG_03-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "271 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:4: RuntimeWarning: epochs._get_data() can't run because this Epochs-object is empty. You might want to check Epochs.drop_log or Epochs.plot_drop_log() to see why epochs were dropped.\n",
      "  epochs = mne.read_epochs(block_file, preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:4: RuntimeWarning: epochs._get_data() can't run because this Epochs-object is empty. You might want to check Epochs.drop_log or Epochs.plot_drop_log() to see why epochs were dropped.\n",
      "  epochs = mne.read_epochs(block_file, preload=True)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: epochs._get_data() can't run because this Epochs-object is empty. You might want to check Epochs.drop_log or Epochs.plot_drop_log() to see why epochs were dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AG\\UR_AG_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "3 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AG\\UR_AG_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "256 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "259 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AG\\AR_AG_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "261 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AG\\AR_AG_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "220 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AH\\US_AH_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "296 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AH\\US_AH_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "287 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "583 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AH\\AS_AH_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AH\\AS_AH_02-epo.fif ...\n",
      "    Found the data of interest:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "608 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AH\\UR_AH_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "292 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AH\\UR_AH_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "302 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "594 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AH\\AR_AH_01-epo.fif ...\n",
      "    Found the data of interest:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "303 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs2\\AH\\AR_AH_02-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "298 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Not setting metadata\n",
      "601 matching events found\n",
      "Applying baseline correction (mode: mean)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1301839981.py:11: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  combined_epochs = mne.concatenate_epochs(epochs_list)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_and_combine_epochs_for_condition(part_directory, condition):\n",
    "    epochs_list = []\n",
    "    for block_file in part_directory.glob(f\"{condition}_{part_directory.stem}_*-epo.fif\"):\n",
    "        epochs = mne.read_epochs(block_file, preload=True)\n",
    "        # Cadjust channels\n",
    "        if part_directory.stem == \"AA\":\n",
    "            # Drop specific channels if they are present\n",
    "            channels_to_drop = [ch for ch in ['FC6'] if ch in epochs.ch_names]\n",
    "            epochs.drop_channels(channels_to_drop)\n",
    "        epochs_list.append(epochs)\n",
    "    combined_epochs = mne.concatenate_epochs(epochs_list)\n",
    "    return combined_epochs\n",
    "\n",
    "conds_of_interest = [\"US\",\"AS\",\"UR\",\"AR\"]\n",
    "# Main processing loop\n",
    "all_parts21 = {}\n",
    "for part in Path(\"saved_epochs2\").iterdir():\n",
    "    evokeds = []\n",
    "    for cond in conds_of_interest:\n",
    "        # Load and combine epochs for each condition across blocks\n",
    "        combined_epochs = load_and_combine_epochs_for_condition(part, cond)\n",
    "        \n",
    "        if \"A\" in cond:\n",
    "            lat_cond = [f\"{cond}/lat_am\"]\n",
    "        elif \"U\" in cond:\n",
    "            lat_cond = [f\"{cond}/lat_unam_r\", f\"{cond}/lat_unam_l\"]\n",
    "\n",
    "        evoked = combined_epochs[lat_cond].average()\n",
    "        evoked.comment = cond  # Simplify condition name directly here\n",
    "        evokeds.append(evoked)\n",
    "\n",
    "    all_parts21[part.stem] = evokeds\n",
    "\n",
    "\n",
    "colors = {\n",
    "    'US': 'red',\n",
    "    'AS': 'orange',\n",
    "    'AR': 'blue',\n",
    "    'UR': 'green'\n",
    "}\n",
    "\n",
    "def simplify_condition(comment):\n",
    "    for cond in conds_of_interest:\n",
    "        if cond in comment:\n",
    "            return cond\n",
    "    return None\n",
    "\n",
    "def simplify_evoked_conditions(participant_evokeds):\n",
    "    simplified_evokeds = []\n",
    "    for evoked in participant_evokeds:\n",
    "        simplified_comment = simplify_condition(evoked.comment)\n",
    "        if simplified_comment:\n",
    "            evoked.comment = simplified_comment\n",
    "            simplified_evokeds.append(evoked)\n",
    "    return simplified_evokeds\n",
    "for participant in list(all_parts21):\n",
    "    all_parts21[participant] = simplify_evoked_conditions(all_parts21[participant])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AJ': [<Evoked | 'US' (average, N=136), -0.1  0.5 s, baseline -0.1  0 s, 30 ch, ~183 kB>,\n",
       "  <Evoked | 'AS' (average, N=151), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=142), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AK': [<Evoked | 'US' (average, N=146), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=150), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=151), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AL': [<Evoked | 'US' (average, N=150), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=124), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=142), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=73), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AO': [<Evoked | 'US' (average, N=72), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=110), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=92), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=99), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AP': [<Evoked | 'US' (average, N=150), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=74), -0.1  0.5 s, baseline -0.1  0 s, 30 ch, ~183 kB>,\n",
       "  <Evoked | 'UR' (average, N=141), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=123), -0.1  0.5 s, baseline -0.1  0 s, 29 ch, ~177 kB>],\n",
       " 'AQ': [<Evoked | 'US' (average, N=146), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=146), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=130), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=145), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AR': [<Evoked | 'US' (average, N=150), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=151), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AS': [<Evoked | 'US' (average, N=142), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=145), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=76), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=142), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AT': [<Evoked | 'US' (average, N=143), -0.1  0.5 s, baseline -0.1  0 s, 29 ch, ~177 kB>,\n",
       "  <Evoked | 'AS' (average, N=147), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=143), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=148), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_parts21"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 2020 #"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigger conversion ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_events_old_trigger_system2(orig_events, sfreq):\n",
    "    '''Change event triggers from duration to different trigger numbers depending on stimulus type.\n",
    "    Determined by sample points.\n",
    "    Parameters:\n",
    "    -----------------\n",
    "    events: numpy.ndarray, array from mne funtion events_from_annotations \n",
    "    sfreq: float, sample frequency\n",
    "    Output:\n",
    "    ----------------\n",
    "    events: numpy.ndarray, array with new trigger values\n",
    "    '''\n",
    "    events = orig_events.copy()\n",
    "    #find where stimulus trigger is 13 because those are stim onset\n",
    "    trig_13 = np.where(orig_events[:,-1]==13)[0]\n",
    "    # find where trigger is 12 because that is stim offset\n",
    "    trig_12 = np.where(orig_events[:,-1]==12)[0]\n",
    "    \n",
    "    #calculate number of samples in the case that the sample frequency is not 1000\n",
    "    #divide original sample frequency by new sample frequency\n",
    "    samples = 1000/sfreq\n",
    "    #divide original number of samples for stim by samples calculated above\n",
    "    small_check_normal=300/samples\n",
    "    small_check_rev=250/samples\n",
    "    amb_lat=200/samples\n",
    "    unamb_left_lat=100/samples\n",
    "    unamb_right_lat=150/samples\n",
    "    # all trigger lengths as list\n",
    "    all_trig_lens = [small_check_normal, small_check_rev, amb_lat, unamb_left_lat, unamb_right_lat]\n",
    "    \n",
    "    ## change trigger numbers\n",
    "    #loop through trigger indices\n",
    "    for i in range(len(trig_12)):\n",
    "        # find trigger duration\n",
    "        trig_len = orig_events[trig_12[i],0]-orig_events[trig_13[i],0]\n",
    "        \n",
    "        # compare all computed trigger lengths with actual trigger lengths\n",
    "        # put differences of actual trigger and computer trigger lengths into list\n",
    "        abs_trig_len = []\n",
    "        for t in all_trig_lens:\n",
    "            abs_trig_len.append(abs(t-trig_len))\n",
    "        \n",
    "        # find the trigger length with smallest difference between computed and actual trigger length\n",
    "        diff_min = np.argmin(abs_trig_len)\n",
    "        # get real trigger value\n",
    "        real_trigger_len = all_trig_lens[diff_min]\n",
    "        # get different trig values for diff stimuli\n",
    "        if real_trigger_len == small_check_normal:\n",
    "            new_trig = 2\n",
    "        elif real_trigger_len == small_check_rev:\n",
    "            new_trig = 4\n",
    "        elif real_trigger_len == amb_lat:\n",
    "            new_trig = 6\n",
    "        elif real_trigger_len == unamb_left_lat:\n",
    "            new_trig = 8\n",
    "        elif real_trigger_len == unamb_right_lat:\n",
    "            new_trig = 10\n",
    "            \n",
    "        # replace trigger 13 with values\n",
    "        events[trig_13[i],2] = new_trig    \n",
    "            \n",
    "    return events"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger checking ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data\\\\KM\")\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"AR\"]\n",
    "\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "counter = 0\n",
    "all_event_codes = []\n",
    "all_event_codes2 = []\n",
    "# Participant name\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "for file in participant_path.glob(\"*_KM_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID (e.g., \"AB\")\n",
    "    block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        \n",
    "                    \n",
    "       # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        \n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        def check_event_pairs(orig_events):\n",
    "            paired_count = 0\n",
    "            unpaired_13 = []\n",
    "            unpaired_12 = []\n",
    "            ignore_codes = set(range(1000, 1101))\n",
    "            orig_events = np.array(orig_events)\n",
    "            # Look for 13 events and check if the next event is 12\n",
    "            for i, event in enumerate(orig_events):\n",
    "                if event[2] == 13:\n",
    "                    # Initialize a variable to keep track of the next relevant index\n",
    "                    next_relevant_index = i + 1\n",
    "                    \n",
    "                    # Skip any event codes between 1010 and 1100\n",
    "                    while next_relevant_index < len(orig_events) and orig_events[next_relevant_index][2] in ignore_codes:\n",
    "                        next_relevant_index += 1\n",
    "                        \n",
    "                    # If the next relevant event is 12, count as a pair\n",
    "                    if next_relevant_index < len(orig_events) and orig_events[next_relevant_index][2] == 12:\n",
    "                        paired_count += 1\n",
    "                    else:\n",
    "                        # Otherwise, the 13 event is unpaired\n",
    "                        unpaired_13.append(i)\n",
    "                        \n",
    "                elif event[2] == 12:\n",
    "                    # Check if the previous event is a 13 and not unpaired\n",
    "                    prev_relevant_index = i - 1\n",
    "                    \n",
    "                    # Skip any event codes between 1010 and 1100\n",
    "                    while prev_relevant_index >= 0 and orig_events[prev_relevant_index][2] in ignore_codes:\n",
    "                        prev_relevant_index -= 1\n",
    "                        \n",
    "                    # If the previous relevant event is not a 13, count this 12 as unpaired\n",
    "                    if prev_relevant_index < 0 or orig_events[prev_relevant_index][2] != 13:\n",
    "                        unpaired_12.append(i)\n",
    "\n",
    "            return paired_count, unpaired_13, unpaired_12\n",
    "\n",
    "\n",
    "\n",
    "        # Now let's call the function and print the results\n",
    "        paired_count, unpaired_13s, unpaired_12s = check_event_pairs(orig_events)\n",
    "        print(f\"Number of correctly paired '13' followed by '12': {paired_count}\")\n",
    "        print(f\"Unpaired '13' indices: {unpaired_13s}\")\n",
    "        print(f\"Unpaired '12' indices: {unpaired_12s}\")\n",
    "            \n",
    "        # Find indices of triggers 12 and 13\n",
    "        trig_12_indices = np.where(orig_events[:, 2] == 12)[0]\n",
    "        trig_13_indices = np.where(orig_events[:, 2] == 13)[0]\n",
    "            \n",
    "        # Iterate through the indices of triggers 13\n",
    "        for trig_12_index in trig_12_indices:\n",
    "            # Find the corresponding trigger 12 that comes before the current trigger 13\n",
    "            previous_trig_13_index = trig_13_indices[trig_13_indices < trig_12_index]\n",
    "            if previous_trig_13_index.size > 0:  # Check if a previous trigger 12 exists\n",
    "                previous_trig_13_index = previous_trig_13_index[-1]\n",
    "                # Calculate the difference in sample points\n",
    "                difference = orig_events[trig_12_index, 0] - orig_events[previous_trig_13_index, 0]\n",
    "                print(f\"Difference {counter + 1}: {difference}\")\n",
    "                # Add the difference to the list\n",
    "                # sample_differences.append(difference)\n",
    "                # Increment the counter\n",
    "                counter += 1\n",
    "                if counter == 20:  # Stop after printing 20 differences\n",
    "                    break\n",
    "            if counter == 20:  # Check if we need to break out of the outer loop as well\n",
    "                break\n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter repetitive Necker lattices ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_event_sequences(events): ### Detect repetitive necker lattices (no checkerboards in between)\n",
    "    filtered_event_codes = []\n",
    "    filtered_event_indices = []\n",
    "    ignore_codes = {12, 1007, 1011, 1013, 1015}\n",
    "    sequence_start_codes = {6, 8, 10}\n",
    "    valid_terminators = {2, 4}\n",
    "    \n",
    "    skip_until_valid = False\n",
    "    last_sequence_code = None\n",
    "\n",
    "    for i, event in enumerate(events):\n",
    "        code = event[2]\n",
    "        if code in ignore_codes:\n",
    "            continue\n",
    "        elif skip_until_valid and code in sequence_start_codes and last_sequence_code == code:\n",
    "            continue\n",
    "        elif skip_until_valid and code in valid_terminators:\n",
    "            skip_until_valid = False\n",
    "            filtered_event_codes.append(code)\n",
    "            filtered_event_indices.append(i)\n",
    "        elif code in sequence_start_codes:\n",
    "            if not skip_until_valid:\n",
    "                filtered_event_codes.append(code)\n",
    "                filtered_event_indices.append(i)\n",
    "            skip_until_valid = True\n",
    "            last_sequence_code = code\n",
    "        else:\n",
    "            filtered_event_codes.append(code)\n",
    "            filtered_event_indices.append(i)\n",
    "\n",
    "    # Return both the filtered event codes and their indices\n",
    "    return filtered_event_codes, filtered_event_indices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant KM ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data\\\\KM\")\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"AR\",\"UR\",\"US\"]\n",
    "conds_of_interest2 = [\"AS\"]\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "participant_id = participant_path.stem\n",
    "all_event_codes_KM = []\n",
    "for file in participant_path.glob(\"*_KM_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID (e.g., \"AB\")\n",
    "    block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "            \n",
    "        # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        #raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        #raw.plot_psd(fmax=40)\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = get_new_events_old_trigger_system2(orig_events, raw.info[\"sfreq\"])\n",
    "        filtered_event_codes, filtered_event_indices = filter_event_sequences(events)\n",
    "        filtered_events = events[filtered_event_indices]\n",
    "\n",
    "        # You can now create epochs with the filtered events\n",
    "        epochs = mne.Epochs(raw, events=filtered_events, event_id=event_id, baseline=None, reject=None, tmin=tmin, tmax=tmax, proj=True, preload=True)\n",
    "                    \n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        \n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    " \n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)    \n",
    "        \n",
    "        \n",
    "        \n",
    "    if file_cond in conds_of_interest2:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        # raw.plot()\n",
    "        raw.drop_channels(['T8']) ## drop noisy channel\n",
    "        raw.set_montage('standard_1020')\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        #raw.plot_psd(fmax=40)\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = get_new_events_old_trigger_system2(orig_events, raw.info[\"sfreq\"])\n",
    "\n",
    "\n",
    "        # You can now create epochs with the filtered events\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None, tmin=tmin, tmax=tmax, proj=True, preload=True)\n",
    "                    \n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        \n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "            \n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant KN ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data\\\\KN\")\n",
    "participant_id = participant_path.stem\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "\n",
    "conds_of_interest = [\"AR\"]\n",
    "conds_of_interest2 = [\"UR\"]\n",
    "conds_of_interest3 = [\"AS\", \"US\"]\n",
    "all_event_codes_KN = []\n",
    "for file in participant_path.glob(\"*_KN_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID \n",
    "    block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        #raw.plot_psd(fmax=40)\n",
    "        raw.drop_channels(['Fp2']) ## drop noisy channel\n",
    "        ## get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = get_new_events_old_trigger_system2(orig_events, raw.info[\"sfreq\"])\n",
    "        filtered_event_codes, filtered_event_indices = filter_event_sequences(events)\n",
    "        filtered_events = events[filtered_event_indices]\n",
    "\n",
    "        # You can now create epochs with the filtered events\n",
    "        epochs = mne.Epochs(raw, events=filtered_events, event_id=event_id, baseline=None, reject=None, tmin=tmin, tmax=tmax, proj=True, preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        \n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1'],measure='correlation',threshold=0.55) ## fp2 noisy\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "            \n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)    \n",
    "    if file_cond in conds_of_interest3:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        #raw.plot_psd(fmax=40)\n",
    "    \n",
    "        ## get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = get_new_events_old_trigger_system2(orig_events, raw.info[\"sfreq\"])\n",
    "        filtered_event_codes, filtered_event_indices = filter_event_sequences(events)\n",
    "        filtered_events = events[filtered_event_indices]\n",
    "\n",
    "        # You can now create epochs with the filtered events\n",
    "        epochs = mne.Epochs(raw, events=filtered_events, event_id=event_id, baseline=None, reject=None, tmin=tmin, tmax=tmax, proj=True, preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        \n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "            \n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)    \n",
    "        \n",
    "    if file_cond in conds_of_interest2:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        #raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        raw.drop_channels(['T8']) ## drop noisy channel\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        #raw.plot_psd(fmax=40)\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = get_new_events_old_trigger_system2(orig_events, raw.info[\"sfreq\"])\n",
    "        filtered_event_codes, filtered_event_indices = filter_event_sequences(events)\n",
    "        filtered_events = events[filtered_event_indices]\n",
    "\n",
    "        # You can now create epochs with the filtered events\n",
    "        epochs = mne.Epochs(raw, events=filtered_events, event_id=event_id, baseline=None, reject=None, tmin=tmin, tmax=tmax, proj=True, preload=True)\n",
    "                    \n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        \n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        ica.plot_components()\n",
    "        ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "            \n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant KO ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data\\\\KO\")\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"AR\",\"UR\"]\n",
    "conds_of_interest2 = [\"AS\",\"US\"]\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "all_event_codes_KO = []\n",
    "for file in participant_path.glob(\"*_KO_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID \n",
    "    block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "    \n",
    "        # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        #raw.plot_psd(fmax=40)\n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = get_new_events_old_trigger_system2(orig_events, raw.info[\"sfreq\"])\n",
    "        filtered_event_codes, filtered_event_indices = filter_event_sequences(events)\n",
    "        filtered_events = events[filtered_event_indices]\n",
    "\n",
    "        # You can now create epochs with the filtered events\n",
    "        epochs = mne.Epochs(raw, events=filtered_events, event_id=event_id, baseline=None, reject=None, tmin=tmin, tmax=tmax, proj=True, preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        \n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        #ica.plot_components()\n",
    "        #ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "            \n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events) \n",
    "    if file_cond in conds_of_interest2:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        #raw.plot_psd(fmax=40)\n",
    "        raw.drop_channels(['T8']) ## drop noisy channel\n",
    "        ## get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = get_new_events_old_trigger_system2(orig_events, raw.info[\"sfreq\"])\n",
    "        filtered_event_codes, filtered_event_indices = filter_event_sequences(events)\n",
    "        filtered_events = events[filtered_event_indices]\n",
    "\n",
    "        # You can now create epochs with the filtered events\n",
    "        epochs = mne.Epochs(raw, events=filtered_events, event_id=event_id, baseline=None, reject=None, tmin=tmin, tmax=tmax, proj=True, preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        \n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        ica.plot_components()\n",
    "        ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "            \n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant KP #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data path to specific participant\n",
    "participant_path = Path(\"C:\\\\Users\\\\mtu10\\\\OneDrive\\\\Desktop\\\\EEG_code\\\\Data\\\\KP\")\n",
    "participant_id = participant_path.stem\n",
    "\n",
    "# conditions we are interested in as a list\n",
    "conds_of_interest = [\"AR\",\"UR\"]\n",
    "conds_of_interest2 = [\"US\",\"AS\"]\n",
    "# tmin and tmax of epochs\n",
    "tmin = -0.1\n",
    "tmax = 0.5\n",
    "all_event_codes_KP = []\n",
    "for file in participant_path.glob(\"*_KP_*.vhdr\"):\n",
    "    # Extract the condition and block from the file name \n",
    "    file_parts = file.stem.split('_')\n",
    "    file_cond = file_parts[0]  # Condition (e.g., \"AR\")\n",
    "    participant_id = file_parts[1]  # Participant ID \n",
    "    block_number = file_parts[2]  # Block number (e.g., \"01\")\n",
    "    if file_cond in conds_of_interest:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    " \n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = get_new_events_old_trigger_system2(orig_events, raw.info[\"sfreq\"])\n",
    "        filtered_event_codes, filtered_event_indices = filter_event_sequences(events)\n",
    "        filtered_events = events[filtered_event_indices]\n",
    "\n",
    "        # You can now create epochs with the filtered events\n",
    "        epochs = mne.Epochs(raw, events=filtered_events, event_id=event_id, baseline=None, reject=None, tmin=tmin, tmax=tmax, proj=True, preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        \n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "            \n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events)  \n",
    "    if file_cond in conds_of_interest2:\n",
    "        # event triggers as dict used file cond info\n",
    "        event_id_am = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_am\": 6}\n",
    "        event_id_unam = {f\"{file_cond}/checks_normal\": 2,\n",
    "                    f\"{file_cond}/checks_rev\": 4,\n",
    "                    f\"{file_cond}/lat_unam_l\": 8,\n",
    "                    f\"{file_cond}/lat_unam_r\": 10}\n",
    "        # get event_id corresponding with condition\n",
    "        if \"A\" in file_cond:\n",
    "            event_id = event_id_am\n",
    "        elif \"U\" in file_cond:\n",
    "            event_id = event_id_unam\n",
    "        # load raw data\n",
    "        raw = mne.io.read_raw_brainvision(file,preload=True)\n",
    "        # only pick eeg channels\n",
    "        raw.pick(\"eeg\")\n",
    "        \n",
    "        # raw.plot()\n",
    "        raw.set_montage('standard_1020')\n",
    "    \n",
    "        \n",
    "        # filter data\n",
    "        raw.filter(0.03,25)\n",
    "        # raw.plot_psd(fmax=40)\n",
    "        raw.pick([\"eeg\"]).load_data()\n",
    "        # raw.info\n",
    "        # raw.plot_sensors(show_names=True)\n",
    "        # fig = raw.plot_sensors(\"3d\")\n",
    "        # fig\n",
    "        \n",
    "        \n",
    "        # get triggers\n",
    "        orig_events, _ = mne.events_from_annotations(raw)\n",
    "        events = get_new_events_old_trigger_system2(orig_events, raw.info[\"sfreq\"])\n",
    "        # filtered_event_codes, filtered_event_indices = filter_event_sequences(events)\n",
    "        # filtered_events = events[filtered_event_indices] ## no need to filter\n",
    "\n",
    "        # You can now create epochs with the filtered events\n",
    "        epochs = mne.Epochs(raw, events=events, event_id=event_id, baseline=None, reject=None, tmin=tmin, tmax=tmax, proj=True, preload=True)\n",
    "\n",
    "        picks = mne.pick_types(epochs.info, meg=False, eeg=True,\n",
    "        stim=False, eog=False,\n",
    "        include=[], exclude=[])\n",
    "        ransac = Ransac(picks=picks, n_jobs=-1)\n",
    "        epochs = ransac.fit_transform(epochs)\n",
    "        print('\\n'.join(ransac.bad_chs_))\n",
    "        \n",
    "        # epochs.plot()\n",
    "        \n",
    "        # compute an ICA to remove eye blink components from signal\n",
    "        ica = mne.preprocessing.ICA(n_components=len(epochs.info['ch_names'])-1,random_state=55)\n",
    "        ica.fit(epochs)\n",
    "        ica.exclude = []\n",
    "        eog_idx, scores = ica.find_bads_eog(epochs,ch_name=['Fp1','Fp2'],measure='correlation',threshold=0.55)\n",
    "        ica.exclude = eog_idx\n",
    "        # ica.plot_scores(scores)\n",
    "        # ica.plot_components()\n",
    "        # ica.plot_sources(epochs)\n",
    "        epochs_new = epochs.copy()\n",
    "        ica.apply(epochs_new)\n",
    "        epochs = epochs_new\n",
    "        \n",
    "        # set offline reference at mastoid electrodes\n",
    "        epochs.set_eeg_reference(['TP9','TP10'], projection=False)\n",
    "        # apply baseline in ms\n",
    "        epochs.apply_baseline((-0.1,0))\n",
    "        # reject epochs that are above a certain threshold\n",
    "        # value needs to be in volts\n",
    "        epochs.drop_bad(reject={\"eeg\": 150*1e-6},flat=None)\n",
    "        # epochs.plot_drop_log()\n",
    "        # save epoch objects and events array\n",
    "        epoch_path = Path('saved_epochs')\n",
    "        folder_path = Path(epoch_path,participant_id)\n",
    "        # Check if saved_epochs folder already exists\n",
    "        if not epoch_path.exists():\n",
    "            # Create the folder\n",
    "            epoch_path.mkdir(parents=True)\n",
    "        # Check if participant folder already exists\n",
    "        if not folder_path.exists():\n",
    "            # Create the folder\n",
    "            folder_path.mkdir(parents=True)\n",
    "            \n",
    "        # Construct the filename with condition, participant ID, and block number\n",
    "        epochs_filename = f\"{file_cond}_{participant_id}_{block_number}-epo.fif\"\n",
    "        annotations_filename = f\"{file_cond}_{participant_id}_{block_number}-anno.npy\"\n",
    "            \n",
    "        # Save the epochs and annotations\n",
    "        epochs.save(folder_path / epochs_filename, overwrite=True)\n",
    "        np.save(folder_path / annotations_filename, events) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### READ EPOCHS DATA 2020 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs\\KM\\US_KM_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "400 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs\\KM\\AS_KM_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "400 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs\\KM\\UR_KM_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "319 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs\\KM\\AR_KM_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "374 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs\\KN\\US_KN_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "395 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs\\KN\\AS_KN_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "397 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs\\KN\\UR_KN_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "377 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs\\KN\\AR_KN_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "374 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs\\KO\\US_KO_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "400 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs\\KO\\AS_KO_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "400 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs\\KO\\UR_KO_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "381 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs\\KO\\AR_KO_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "343 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs\\KP\\US_KP_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "382 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs\\KP\\AS_KP_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "400 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs\\KP\\UR_KP_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "379 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading c:\\Users\\mtu10\\OneDrive\\Desktop\\EEG_code\\saved_epochs\\KP\\AR_KP_01-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =    -100.00 ...     500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "378 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# Function definitions\n",
    "def read_and_process_epochs(participant_path, condition, participant_id, block):\n",
    "    # Construct the file path based on participant ID, condition, and block\n",
    "    epochs_file = participant_path / f\"{condition}_{participant_id}_{block}-epo.fif\"\n",
    "    \n",
    "    if not epochs_file.is_file():\n",
    "        print(f\"File not found: {epochs_file}\")\n",
    "        return None\n",
    "    \n",
    "    epochs = mne.read_epochs(epochs_file, preload=True)\n",
    "\n",
    "    # Check for channel absence for specific blocks of specific participants and conditions\n",
    "    if participant_id == \"KM\" and condition == \"AS\" and block == \"01\":\n",
    "        channels_to_drop = ['T8'] if 'T8' in epochs.ch_names else []\n",
    "    elif participant_id == \"KN\" and block == \"01\":\n",
    "        if condition == \"UR\" and 'T8' in epochs.ch_names:\n",
    "            channels_to_drop = ['T8']\n",
    "        elif condition == \"AR\" and 'Fp2' in epochs.ch_names:\n",
    "            channels_to_drop = ['Fp2']\n",
    "        else:\n",
    "            channels_to_drop = []\n",
    "    else:\n",
    "        channels_to_drop = []\n",
    "\n",
    "    if channels_to_drop:\n",
    "        epochs.drop_channels(channels_to_drop)\n",
    "\n",
    "    # Select the appropriate event IDs based on condition\n",
    "    lat_cond = [f\"{condition}/lat_am\"] if \"A\" in condition else [f\"{condition}/lat_unam_r\", f\"{condition}/lat_unam_l\"]\n",
    "    evoked = epochs[lat_cond].average()\n",
    "    evoked.comment = f\"{condition}_{block}\"\n",
    "    \n",
    "    return evoked\n",
    "\n",
    "# Main processing\n",
    "conds_of_interest = [\"US\", \"AS\", \"UR\", \"AR\"]\n",
    "participants = [\"KM\", \"KN\", \"KO\", \"KP\"]  \n",
    "blocks = [\"01\"]  \n",
    "\n",
    "# Create a dictionary to store evoked data for each participant\n",
    "all_parts20 = {participant: [] for participant in participants}\n",
    "\n",
    "# Directory where epochs are stored\n",
    "data_path = Path(\"saved_epochs\")\n",
    "\n",
    "# Iterate over each participant, condition, and block\n",
    "for participant_id in participants:\n",
    "    participant_path = data_path / participant_id\n",
    "    for condition in conds_of_interest:\n",
    "        for block in blocks:\n",
    "            evoked = read_and_process_epochs(participant_path, condition, participant_id, block)\n",
    "            if evoked:\n",
    "                all_parts20[participant_id].append(evoked)\n",
    "\n",
    "\n",
    "    \n",
    "def simplify_condition(comment):\n",
    "    for cond in conds_of_interest:\n",
    "        if cond in comment:\n",
    "            return cond\n",
    "    return None\n",
    "\n",
    "def simplify_evoked_conditions(participant_evokeds):\n",
    "    simplified_evokeds = []\n",
    "    for evoked in participant_evokeds:\n",
    "        simplified_comment = simplify_condition(evoked.comment)\n",
    "        if simplified_comment:\n",
    "            evoked.comment = simplified_comment\n",
    "            simplified_evokeds.append(evoked)\n",
    "    return simplified_evokeds\n",
    "\n",
    "# Simplify the evoked conditions for all participants\n",
    "for participant in participants:\n",
    "    all_parts20[participant] = simplify_evoked_conditions(all_parts20[participant])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all datasets\n",
    "all_parts_combined = {}\n",
    "\n",
    "# Merge data\n",
    "for participant_id, data in all_parts23.items():\n",
    "    if participant_id not in all_parts_combined:\n",
    "        all_parts_combined[participant_id] = data\n",
    "    else:\n",
    "        all_parts_combined[participant_id].extend(data)\n",
    "\n",
    "# Merge data \n",
    "for participant_id, data in all_parts20.items():\n",
    "    if participant_id not in all_parts_combined:\n",
    "        all_parts_combined[participant_id] = data\n",
    "    else:\n",
    "        all_parts_combined[participant_id].extend(data)\n",
    "for participant_id, data in all_parts21.items():\n",
    "    if participant_id not in all_parts_combined:\n",
    "        all_parts_combined[participant_id] = data\n",
    "    else:\n",
    "        all_parts_combined[participant_id].extend(data)\n",
    "for participant_id, data in all_parts22.items():\n",
    "    if participant_id not in all_parts_combined:\n",
    "        all_parts_combined[participant_id] = data\n",
    "    else:\n",
    "        all_parts_combined[participant_id].extend(data)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all except dataset 2020\n",
    "all_parts_combined_M = {}\n",
    "\n",
    "\n",
    "# Merge data from all_parts3\n",
    "for participant_id, data in all_parts.items():\n",
    "    if participant_id not in all_parts_combined_M:\n",
    "        all_parts_combined_M[participant_id] = data\n",
    "    else:\n",
    "        all_parts_combined_M[participant_id].extend(data)\n",
    "for participant_id, data in all_parts21.items():\n",
    "    if participant_id not in all_parts_combined_M:\n",
    "        all_parts_combined_M[participant_id] = data\n",
    "    else:\n",
    "        all_parts_combined_M[participant_id].extend(data)\n",
    "for participant_id, data in all_parts22.items():\n",
    "    if participant_id not in all_parts_combined_M:\n",
    "        all_parts_combined_M[participant_id] = data\n",
    "    else:\n",
    "        all_parts_combined_M[participant_id].extend(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BA': [<Evoked | 'US' (average, N=151), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=145), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=130), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'BC': [<Evoked | 'US' (average, N=89), -0.1  0.5 s, baseline -0.1  0 s, 29 ch, ~178 kB>,\n",
       "  <Evoked | 'AS' (average, N=96), -0.1  0.5 s, baseline -0.1  0 s, 29 ch, ~178 kB>,\n",
       "  <Evoked | 'UR' (average, N=150), -0.1  0.5 s, baseline -0.1  0 s, 29 ch, ~178 kB>,\n",
       "  <Evoked | 'AR' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 29 ch, ~178 kB>],\n",
       " 'BD': [<Evoked | 'US' (average, N=151), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=149), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'KM': [<Evoked | 'US' (average, N=100), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=100), -0.1  0.5 s, baseline -0.1  0 s, 30 ch, ~183 kB>,\n",
       "  <Evoked | 'UR' (average, N=71), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=62), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'KN': [<Evoked | 'US' (average, N=98), -0.1  0.5 s, baseline -0.1  0 s, 30 ch, ~183 kB>,\n",
       "  <Evoked | 'AS' (average, N=100), -0.1  0.5 s, baseline -0.1  0 s, 30 ch, ~183 kB>,\n",
       "  <Evoked | 'UR' (average, N=78), -0.1  0.5 s, baseline -0.1  0 s, 30 ch, ~183 kB>,\n",
       "  <Evoked | 'AR' (average, N=67), -0.1  0.5 s, baseline -0.1  0 s, 30 ch, ~183 kB>],\n",
       " 'KO': [<Evoked | 'US' (average, N=100), -0.1  0.5 s, baseline -0.1  0 s, 30 ch, ~183 kB>,\n",
       "  <Evoked | 'AS' (average, N=100), -0.1  0.5 s, baseline -0.1  0 s, 30 ch, ~183 kB>,\n",
       "  <Evoked | 'UR' (average, N=79), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=76), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'KP': [<Evoked | 'US' (average, N=100), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=100), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=71), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=63), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AA': [<Evoked | 'US' (average, N=100), -0.1  0.5 s, baseline -0.1  0 s, 30 ch, ~183 kB>,\n",
       "  <Evoked | 'AS' (average, N=100), -0.1  0.5 s, baseline -0.1  0 s, 30 ch, ~183 kB>,\n",
       "  <Evoked | 'UR' (average, N=100), -0.1  0.5 s, baseline -0.1  0 s, 30 ch, ~183 kB>,\n",
       "  <Evoked | 'AR' (average, N=100), -0.1  0.5 s, baseline -0.1  0 s, 30 ch, ~183 kB>],\n",
       " 'AB': [<Evoked | 'US' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=150), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AC': [<Evoked | 'US' (average, N=151), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=151), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AD': [<Evoked | 'US' (average, N=76), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=143), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=150), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=146), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AF': [<Evoked | 'US' (average, N=151), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=151), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AG': [<Evoked | 'US' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=144), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=74), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=131), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AH': [<Evoked | 'US' (average, N=148), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=148), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=150), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AJ': [<Evoked | 'US' (average, N=136), -0.1  0.5 s, baseline -0.1  0 s, 30 ch, ~183 kB>,\n",
       "  <Evoked | 'AS' (average, N=151), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=142), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AK': [<Evoked | 'US' (average, N=146), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=150), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=151), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AL': [<Evoked | 'US' (average, N=150), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=124), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=142), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=73), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AO': [<Evoked | 'US' (average, N=72), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=110), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=92), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=99), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AP': [<Evoked | 'US' (average, N=150), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=74), -0.1  0.5 s, baseline -0.1  0 s, 30 ch, ~183 kB>,\n",
       "  <Evoked | 'UR' (average, N=141), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=123), -0.1  0.5 s, baseline -0.1  0 s, 29 ch, ~177 kB>],\n",
       " 'AQ': [<Evoked | 'US' (average, N=146), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=146), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=130), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=145), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AR': [<Evoked | 'US' (average, N=150), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=151), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=152), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AS': [<Evoked | 'US' (average, N=142), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AS' (average, N=145), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=76), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=142), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>],\n",
       " 'AT': [<Evoked | 'US' (average, N=143), -0.1  0.5 s, baseline -0.1  0 s, 29 ch, ~177 kB>,\n",
       "  <Evoked | 'AS' (average, N=147), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'UR' (average, N=143), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>,\n",
       "  <Evoked | 'AR' (average, N=148), -0.1  0.5 s, baseline -0.1  0 s, 31 ch, ~189 kB>]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_parts_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:27: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots()\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1965532854.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  ev.pick_channels(list(common_channels))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"ERP plots for all participants individually\"\"\"\n",
    "def plot_evokeds_for_participant(participant, evokeds, colors):\n",
    "    # Define styles for the lines\n",
    "    styles = {\n",
    "        'US': {'color': 'red', 'linestyle': '-'},   # Bold red for Unambiguous-Same\n",
    "        'UR': {'color': 'red', 'linestyle': '--'},  # Dashed red for Unambiguous-Random\n",
    "        'AS': {'color': 'blue', 'linestyle': '-'},  # Bold blue for Ambiguous-Same\n",
    "        'AR': {'color': 'blue', 'linestyle': '--'}  # Dashed blue for Ambiguous-Random\n",
    "    }\n",
    "    \n",
    "    # Determine the common channels among all evokeds for the participant\n",
    "    common_channels = set(evokeds[0].ch_names)\n",
    "    for evoked in evokeds[1:]:\n",
    "        common_channels.intersection_update(evoked.ch_names)\n",
    "    \n",
    "    # Pick only the common channels for plotting\n",
    "    evokeds_common_channels = []\n",
    "    for ev in evokeds:\n",
    "        ev.pick_channels(list(common_channels))\n",
    "        evokeds_common_channels.append(ev)\n",
    "\n",
    "    # Adjust colors and styles based on the evoked.comment\n",
    "    adjusted_styles = {ev.comment: styles[ev.comment] for ev in evokeds_common_channels if ev.comment in styles}\n",
    "    adjusted_colors = {ev.comment: colors[ev.comment] for ev in evokeds_common_channels if ev.comment in colors}\n",
    "\n",
    "    # Plotting using adjusted styles and colors\n",
    "    fig, ax = plt.subplots()\n",
    "    mne.viz.plot_compare_evokeds(\n",
    "        {ev.comment: ev for ev in evokeds_common_channels},\n",
    "        title=f\"Participant '{participant}' ERPs\",\n",
    "        picks=\"Cz\",\n",
    "        colors=adjusted_colors,\n",
    "        styles=adjusted_styles,\n",
    "        ci=True,\n",
    "        show=True,\n",
    "        truncate_yaxis=False,\n",
    "        truncate_xaxis=False,\n",
    "        axes=ax\n",
    "    )\n",
    "   \n",
    "\n",
    "    # Extending the x-axis to show time until 0.5 seconds\n",
    "    ax.set_xlim(left=ax.get_xlim()[0], right=0.5)  # Extends the right limit to 0.5 seconds\n",
    "\n",
    "    # Set explicit x-axis ticks to ensure 0.5 is included and labeled\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(0.1))  # Set major ticks interval\n",
    "    ax.xaxis.set_minor_locator(ticker.MultipleLocator(0.05))  # Set minor ticks interval\n",
    "    # Adjust font size of axis labels and tick labels\n",
    "    ax.set_xlabel('Time (s)', fontsize=14)  # Time in seconds with larger font\n",
    "    ax.set_ylabel('Amplitude (V)', fontsize=14)  # Amplitude in microvolts with larger font\n",
    "    ax.tick_params(axis='both', which='major', labelsize=12)  # Tick labels font size for major ticks\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=10)  # Tick labels font size for minor ticks\n",
    "    # Adjust the title font size\n",
    "    ax.set_title(f\"Participant '{participant}' ERPs\", fontsize=16)  \n",
    "    # Force a redraw of the figure to ensure the plot updates\n",
    "    plt.draw()\n",
    "\n",
    "    # Optionally, add grid for better readability\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Optionally, set labels for the axes to indicate units\n",
    "    ax.set_xlabel('Time (s)')  # Time in seconds\n",
    "    ax.set_ylabel('Amplitude (V)')  # Amplitude in microvolts\n",
    "    plt.show()\n",
    "\n",
    "colors = {'US': 'red', 'AS': 'blue', 'UR': 'red', 'AR': 'blue'}  \n",
    "\n",
    "for participant, evokeds in all_parts_combined.items():\n",
    "    if evokeds:  # Only plot if there are evoked data present\n",
    "        plot_evokeds_for_participant(participant, evokeds, colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:19: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3441582458.py:95: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "\"\"\"ERP of grand mean of all participants\"\"\"\n",
    "\n",
    "combined_evokeds_by_cond = {cond: [] for cond in conds_of_interest}\n",
    "participant_count_by_cond = {}  # Dictionary to hold participant counts for each condition\n",
    "\n",
    "for participant, evokeds in all_parts_combined.items():\n",
    "    for evoked in evokeds:\n",
    "        cond = simplify_condition(evoked.comment)\n",
    "        if cond:\n",
    "            combined_evokeds_by_cond[cond].append(evoked)\n",
    "            if cond not in participant_count_by_cond:\n",
    "                participant_count_by_cond[cond] = set()\n",
    "            participant_count_by_cond[cond].add(participant)\n",
    "\n",
    "# Adjusting each evoked data to only include common channels\n",
    "all_channels = set.intersection(*(set(evoked.ch_names) for evokeds in combined_evokeds_by_cond.values() for evoked in evokeds))\n",
    "for cond, evokeds in combined_evokeds_by_cond.items():\n",
    "    for evoked in evokeds:\n",
    "        evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
    "\n",
    "grand_averages_all = []\n",
    "legend_info = {}\n",
    "for cond, evokeds in combined_evokeds_by_cond.items():\n",
    "    if evokeds:\n",
    "        grand_avg = mne.grand_average(evokeds)\n",
    "        grand_avg.comment = cond\n",
    "        grand_averages_all.append(grand_avg)\n",
    "        # Prepare legend info with participant count\n",
    "        legend_info[cond] = f\"{cond} (n={len(participant_count_by_cond[cond])})\"\n",
    "\n",
    "# Dictionary for plot styling\n",
    "colors = {\n",
    "    'US': 'red',\n",
    "    'UR': 'red',\n",
    "    'AS': 'blue',\n",
    "    'AR': 'blue'\n",
    "}\n",
    "styles = {\n",
    "    'UR': {'linestyle': '--'},\n",
    "    'AR': {'linestyle': '--'}\n",
    "}\n",
    "\n",
    "# Update styles and colors to use the legend_info keys\n",
    "updated_colors = {legend_info[cond]: colors[cond] for cond in colors if cond in legend_info}\n",
    "updated_styles = {legend_info[cond]: styles[cond] for cond in styles if cond in legend_info}\n",
    "\n",
    "# Function to add shaded regions with labels\n",
    "def add_shaded_region_with_label(ax, start, end, label, y_max):\n",
    "    ax.axvspan(start, end, color='gray', alpha=0.3)\n",
    "    midpoint = (start + end) / 2\n",
    "    ax.text(midpoint, y_max * 0.9, label, horizontalalignment='center', fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "mne.viz.plot_compare_evokeds(\n",
    "    {legend_info[cond]: grand_averages_all[i] for i, cond in enumerate(conds_of_interest) if cond in legend_info},\n",
    "    picks=\"Cz\",\n",
    "    ci=0.95,\n",
    "    colors=updated_colors,\n",
    "    styles=updated_styles,\n",
    "    title=\"Grand Average Evoked Responses by Condition\",\n",
    "    axes=ax\n",
    ")\n",
    "\n",
    "# Get y-axis limits for label placement\n",
    "y_min, y_max = ax.get_ylim()\n",
    "\n",
    "# Add shaded regions and labels\n",
    "add_shaded_region_with_label(ax, 0.19, 0.3, 'P200', y_max)\n",
    "add_shaded_region_with_label(ax, 0.305, 0.5, 'P400', y_max)\n",
    "\n",
    "# Customizing the legend manually\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "new_labels = [legend_info[label.split()[0]] for label in labels]  # Remapping labels to include participant counts\n",
    "ax.legend(handles, new_labels, fontsize=15)\n",
    "\n",
    "# Extending the x-axis to show time until 0.5 seconds\n",
    "ax.set_xlim(left=ax.get_xlim()[0], right=0.5)  # Extends the right limit to 0.5 seconds\n",
    "\n",
    "# Set explicit x-axis ticks to ensure 0.5 is included and labeled\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(0.1))  # Set major ticks interval\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(0.05))  # Set minor ticks interval\n",
    "# Adjust font size of axis labels and tick labels\n",
    "ax.set_xlabel('Time (s)', fontsize=14)  # Time in seconds with larger font\n",
    "ax.set_ylabel('Amplitude (V)', fontsize=14)  # Amplitude in microvolts with larger font\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)  # Tick labels font size for major ticks\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)  # Tick labels font size for minor ticks\n",
    "# Force a redraw of the figure to ensure the plot updates\n",
    "plt.draw()\n",
    "\n",
    "# Optionally, add grid for better readability\n",
    "ax.grid(True)\n",
    "\n",
    "# Ensure everything fits in the plot area\n",
    "plt.tight_layout()\n",
    "# Add figure name below the x-axis label\n",
    "fig.text(0.5, 0.001, 'Plot A', ha='center', fontsize=14)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3106993419.py:24: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3106993419.py:24: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3106993419.py:24: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3106993419.py:24: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Voltage maps for P200 and P400\"\"\"\n",
    "\n",
    "# Define the time windows for P200 and P400\n",
    "p200_window = (0.19, 0.3)\n",
    "p400_window = (0.305, 0.5)\n",
    "\n",
    "# Create voltage maps for P200 and P400\n",
    "for grand_avg in grand_averages_all:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "    # P200 component\n",
    "    p200_data = grand_avg.copy().crop(tmin=p200_window[0], tmax=p200_window[1]).data.mean(axis=1)\n",
    "    mne.viz.plot_topomap(p200_data, grand_avg.info, axes=axes[0], show=False)\n",
    "    axes[0].set_title(f'{grand_avg.comment} - P200 (190-300 ms)')\n",
    "\n",
    "    # P400 component\n",
    "    p400_data = grand_avg.copy().crop(tmin=p400_window[0], tmax=p400_window[1]).data.mean(axis=1)\n",
    "    mne.viz.plot_topomap(p400_data, grand_avg.info, axes=axes[1], show=False)\n",
    "    axes[1].set_title(f'{grand_avg.comment} - P400 (305-500 ms)')\n",
    "\n",
    "    # Add a colorbar\n",
    "    plt.colorbar(axes[0].images[0], ax=axes, orientation='horizontal')\n",
    "    plt.suptitle(f'Voltage Maps for {grand_avg.comment}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Identifying common channels ...\n",
      "Identifying common channels ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:23: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  evoked.pick_channels(list(all_channels))  # Updated method to use pick_channels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying common channels ...\n",
      "Identifying common channels ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1079379902.py:100: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "\"\"\"ERP of grand mean of all participants with confidence interval\"\"\"\n",
    "\n",
    "combined_evokeds_by_cond = {cond: [] for cond in conds_of_interest}\n",
    "participant_count_by_cond = {}  # Dictionary to hold participant counts for each condition\n",
    "\n",
    "for participant, evokeds in all_parts_combined.items():\n",
    "    for evoked in evokeds:\n",
    "        cond = simplify_condition(evoked.comment)\n",
    "        if cond:\n",
    "            combined_evokeds_by_cond[cond].append(evoked)\n",
    "            if cond not in participant_count_by_cond:\n",
    "                participant_count_by_cond[cond] = set()\n",
    "            participant_count_by_cond[cond].add(participant)\n",
    "\n",
    "# Dictionary for plot styling\n",
    "colors = {\n",
    "    'US': 'red',\n",
    "    'UR': 'red',\n",
    "    'AS': 'blue',\n",
    "    'AR': 'blue'\n",
    "}\n",
    "styles = {\n",
    "    'UR': {'linestyle': '--'},\n",
    "    'AR': {'linestyle': '--'}\n",
    "}\n",
    "\n",
    "# Prepare the evoked data with participant counts for plotting\n",
    "plot_evokeds = {}\n",
    "for cond in combined_evokeds_by_cond:\n",
    "    if combined_evokeds_by_cond[cond]:\n",
    "        plot_evokeds[f\"{cond} (n={len(participant_count_by_cond[cond])})\"] = combined_evokeds_by_cond[cond]\n",
    "\n",
    "# Update colors and styles to use the condition names with participant counts\n",
    "updated_colors = {f\"{cond} (n={len(participant_count_by_cond[cond])})\": colors[cond] for cond in colors}\n",
    "updated_styles = {f\"{cond} (n={len(participant_count_by_cond[cond])})\": styles[cond] for cond in styles if cond in styles}\n",
    "\n",
    "# Plotting with CIs\n",
    "fig, ax = plt.subplots()\n",
    "mne.viz.plot_compare_evokeds(\n",
    "    plot_evokeds,\n",
    "    picks=\"Cz\",\n",
    "    ci=0.95,\n",
    "    colors=updated_colors,\n",
    "    styles=updated_styles,\n",
    "    title=\"Grand Average Evoked Responses by Condition\",\n",
    "    axes=ax\n",
    ")\n",
    "\n",
    "# Customizing the legend manually\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "new_labels = [legend_info[label.split()[0]] for label in labels]  # Remapping labels to include participant counts\n",
    "ax.legend(handles, new_labels, fontsize=14)\n",
    "\n",
    "# Extending the x-axis to show time until 0.5 seconds\n",
    "ax.set_xlim(left=ax.get_xlim()[0], right=0.5)  # Extends the right limit to 0.5 seconds\n",
    "\n",
    "# Set explicit x-axis ticks to ensure 0.5 is included and labeled\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(0.1))  # Set major ticks interval\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(0.05))  # Set minor ticks interval\n",
    "# Adjust font size of axis labels and tick labels\n",
    "ax.set_xlabel('Time (s)', fontsize=14)  # Time in seconds with larger font\n",
    "ax.set_ylabel('Amplitude (V)', fontsize=14)  # Amplitude in microvolts with larger font\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)  # Tick labels font size for major ticks\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)  # Tick labels font size for minor ticks\n",
    "\n",
    "# Adjust the title font size\n",
    "ax.set_title(\"Grand Average ERPs by Condition\", fontsize=16)  # Title with larger font\n",
    "\n",
    "# Adjust layout to make room for the figure name\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "# Add figure name below the x-axis label\n",
    "fig.text(0.5, 0.01, 'Figure A', ha='center', fontsize=14)\n",
    "\n",
    "# Force a redraw of the figure to ensure the plot updates\n",
    "plt.draw()\n",
    "\n",
    "# Optionally, add grid for better readability\n",
    "ax.grid(True)\n",
    "\n",
    "# Optionally, set labels for the axes to indicate units\n",
    "ax.set_xlabel('Time (s)')  # Time in seconds\n",
    "ax.set_ylabel('Amplitude (V)')  # Amplitude in microvolts\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\1644472798.py:116: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\1644472798.py:171: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"ERP of grand mean of all participants with confidence interval ambiguous and unambiguous conditions seperately\"\"\"\n",
    "# Separate conditions into ambiguous and unambiguous\n",
    "ambiguous_conds = ['AS', 'AR']\n",
    "unambiguous_conds = ['US', 'UR']\n",
    "\n",
    "# Create dictionaries to store combined evoked data for each set\n",
    "combined_evokeds_by_ambiguous = {cond: [] for cond in ambiguous_conds}\n",
    "combined_evokeds_by_unambiguous = {cond: [] for cond in unambiguous_conds}\n",
    "\n",
    "# Participant count dictionaries\n",
    "participant_count_by_ambiguous = {}\n",
    "participant_count_by_unambiguous = {}\n",
    "\n",
    "# Separate evoked data into ambiguous and unambiguous\n",
    "for participant, evokeds in all_parts_combined.items():\n",
    "    for evoked in evokeds:\n",
    "        cond = simplify_condition(evoked.comment)\n",
    "        if cond in ambiguous_conds:\n",
    "            combined_evokeds_by_ambiguous[cond].append(evoked)\n",
    "            if cond not in participant_count_by_ambiguous:\n",
    "                participant_count_by_ambiguous[cond] = set()\n",
    "            participant_count_by_ambiguous[cond].add(participant)\n",
    "        elif cond in unambiguous_conds:\n",
    "            combined_evokeds_by_unambiguous[cond].append(evoked)\n",
    "            if cond not in participant_count_by_unambiguous:\n",
    "                participant_count_by_unambiguous[cond] = set()\n",
    "            participant_count_by_unambiguous[cond].add(participant)\n",
    "\n",
    "# Prepare evoked data with participant counts for plotting ambiguous conditions\n",
    "plot_evokeds_ambiguous = {}\n",
    "for cond in combined_evokeds_by_ambiguous:\n",
    "    if combined_evokeds_by_ambiguous[cond]:\n",
    "        plot_evokeds_ambiguous[f\"{cond}\\n(n={len(participant_count_by_ambiguous[cond])})\"] = combined_evokeds_by_ambiguous[cond]\n",
    "\n",
    "# Prepare evoked data with participant counts for plotting unambiguous conditions\n",
    "plot_evokeds_unambiguous = {}\n",
    "for cond in combined_evokeds_by_unambiguous:\n",
    "    if combined_evokeds_by_unambiguous[cond]:\n",
    "        plot_evokeds_unambiguous[f\"{cond}\\n(n={len(participant_count_by_unambiguous[cond])})\"] = combined_evokeds_by_unambiguous[cond]\n",
    "\n",
    "# Update colors and styles\n",
    "colors = {\n",
    "    'US': 'darkred',\n",
    "    'UR': 'red',\n",
    "    'AS': 'darkblue',\n",
    "    'AR': 'blue'\n",
    "}\n",
    "styles = {\n",
    "    'UR': {'linestyle': '--'},\n",
    "    'AR': {'linestyle': '--'}\n",
    "}\n",
    "\n",
    "updated_colors_ambiguous = {f\"{cond}\\n(n={len(participant_count_by_ambiguous[cond])})\": colors[cond] for cond in ambiguous_conds}\n",
    "updated_styles_ambiguous = {f\"{cond}\\n(n={len(participant_count_by_ambiguous[cond])})\": styles[cond] for cond in styles if cond in ambiguous_conds}\n",
    "\n",
    "updated_colors_unambiguous = {f\"{cond}\\n(n={len(participant_count_by_unambiguous[cond])})\": colors[cond] for cond in unambiguous_conds}\n",
    "updated_styles_unambiguous = {f\"{cond}\\n(n={len(participant_count_by_unambiguous[cond])})\": styles[cond] for cond in styles if cond in unambiguous_conds}\n",
    "\n",
    "# Function to add shaded regions with labels\n",
    "def add_shaded_region_with_label(ax, start, end, label, y_max):\n",
    "    ax.axvspan(start, end, color='gray', alpha=0.3)\n",
    "    midpoint = (start + end) / 2\n",
    "    ax.text(midpoint, y_max * 0.9, label, horizontalalignment='center', fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "# Plotting ambiguous conditions\n",
    "fig, ax = plt.subplots()\n",
    "mne.viz.plot_compare_evokeds(\n",
    "    plot_evokeds_ambiguous,\n",
    "    picks=\"Cz\",\n",
    "    ci=0.95,\n",
    "    colors=updated_colors_ambiguous,\n",
    "    styles=updated_styles_ambiguous,\n",
    "    title=\"Grand Average ERPs - Ambiguos\",\n",
    "    axes=ax\n",
    ")\n",
    "\n",
    "# Get y-axis limits for label placement\n",
    "y_min, y_max = ax.get_ylim()\n",
    "\n",
    "# Add shaded regions and labels\n",
    "add_shaded_region_with_label(ax, 0.19, 0.3, 'P200', y_max)\n",
    "add_shaded_region_with_label(ax, 0.305, 0.5, 'P400', y_max)\n",
    "\n",
    "# Customizing the legend manually\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, fontsize=12, loc='upper left')  # Adjust legend font size here\n",
    "\n",
    "# Extending the x-axis to show time until 0.5 seconds\n",
    "ax.set_xlim(left=ax.get_xlim()[0], right=0.5)  # Extends the right limit to 0.5 seconds\n",
    "\n",
    "# Set explicit x-axis ticks to ensure 0.5 is included and labeled\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(0.1))  # Set major ticks interval\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(0.05))  # Set minor ticks interval\n",
    "\n",
    "# Adjust font size of axis labels and tick labels\n",
    "ax.set_xlabel('Time (s)', fontsize=14)  # Time in seconds with larger font\n",
    "ax.set_ylabel('Amplitude (V)', fontsize=14)  # Amplitude in microvolts with larger font\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)  # Tick labels font size for major ticks\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)  # Tick labels font size for minor ticks\n",
    "\n",
    "# Adjust the title font size\n",
    "ax.set_title(\"Grand Average ERPs - Ambiguous\", fontsize=16)  # Title with larger font\n",
    "\n",
    "# Set consistent Y-axis ticks\n",
    "ax.set_yticks([-10, -7.5, -5, -2.5, 0, 2.5, 5, 7.5, 10])\n",
    "# Add figure name\n",
    "fig.text(0.5, 0.01, 'Plot A', ha='center', fontsize=14)\n",
    "\n",
    "# Force a redraw of the figure to ensure the plot updates\n",
    "plt.draw()\n",
    "\n",
    "# Optionally, add grid for better readability\n",
    "ax.grid(True)\n",
    "\n",
    "# Ensure everything fits in the plot area\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plotting unambiguous conditions\n",
    "fig, ax = plt.subplots()\n",
    "mne.viz.plot_compare_evokeds(\n",
    "    plot_evokeds_unambiguous,\n",
    "    picks=\"Cz\",\n",
    "    ci=0.95,\n",
    "    colors=updated_colors_unambiguous,\n",
    "    styles=updated_styles_unambiguous,\n",
    "    title=\"Grand Average ERPs - Unambiguous\",\n",
    "    axes=ax\n",
    ")\n",
    "\n",
    "# Get y-axis limits for label placement\n",
    "y_min, y_max = ax.get_ylim()\n",
    "\n",
    "# Add shaded regions and labels\n",
    "add_shaded_region_with_label(ax, 0.19, 0.3, 'P200', y_max)\n",
    "add_shaded_region_with_label(ax, 0.305, 0.5, 'P400', y_max)\n",
    "\n",
    "# Customizing the legend manually\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, fontsize=12, loc='upper left')  # Adjust legend font size here\n",
    "\n",
    "# Extending the x-axis to show time until 0.5 seconds\n",
    "ax.set_xlim(left=ax.get_xlim()[0], right=0.5)  # Extends the right limit to 0.5 seconds\n",
    "\n",
    "# Set explicit x-axis ticks to ensure 0.5 is included and labeled\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(0.1))  # Set major ticks interval\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(0.05))  # Set minor ticks interval\n",
    "\n",
    "# Adjust font size of axis labels and tick labels\n",
    "ax.set_xlabel('Time (s)', fontsize=14)  # Time in seconds with larger font\n",
    "ax.set_ylabel('Amplitude (V)', fontsize=14)  # Amplitude in microvolts with larger font\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)  # Tick labels font size for major ticks\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)  # Tick labels font size for minor ticks\n",
    "\n",
    "# Adjust the title font size\n",
    "ax.set_title(\"Grand Average ERPs - Unambiguous\", fontsize=16)  # Title with larger font\n",
    "\n",
    "# Set consistent Y-axis ticks\n",
    "ax.set_yticks([-10, -7.5, -5, -2.5, 0, 2.5, 5, 7.5, 10])\n",
    "# Add figure name\n",
    "fig.text(0.5, 0.01, 'Plot B', ha='center', fontsize=14)\n",
    "\n",
    "# Force a redraw of the figure to ensure the plot updates\n",
    "plt.draw()\n",
    "\n",
    "# Optionally, add grid for better readability\n",
    "ax.grid(True)\n",
    "\n",
    "# Ensure everything fits in the plot area\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\1087814396.py:118: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\1087814396.py:174: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "\"\"\"ERP of grand mean of all participants with confidence interval steady state and random conditions seperately\"\"\"\n",
    "\n",
    "# Separate conditions into steady state and random\n",
    "steady_state_conds = ['US', 'AS']\n",
    "random_conds = ['UR', 'AR']\n",
    "\n",
    "# Create dictionaries to store combined evoked data for each set\n",
    "combined_evokeds_by_steady_state = {cond: [] for cond in steady_state_conds}\n",
    "combined_evokeds_by_random = {cond: [] for cond in random_conds}\n",
    "\n",
    "# Participant count dictionaries\n",
    "participant_count_by_steady_state = {}\n",
    "participant_count_by_random = {}\n",
    "\n",
    "# Separate evoked data into steady state and random\n",
    "for participant, evokeds in all_parts_combined.items():\n",
    "    for evoked in evokeds:\n",
    "        cond = simplify_condition(evoked.comment)\n",
    "        if cond in steady_state_conds:\n",
    "            combined_evokeds_by_steady_state[cond].append(evoked)\n",
    "            if cond not in participant_count_by_steady_state:\n",
    "                participant_count_by_steady_state[cond] = set()\n",
    "            participant_count_by_steady_state[cond].add(participant)\n",
    "        elif cond in random_conds:\n",
    "            combined_evokeds_by_random[cond].append(evoked)\n",
    "            if cond not in participant_count_by_random:\n",
    "                participant_count_by_random[cond] = set()\n",
    "            participant_count_by_random[cond].add(participant)\n",
    "\n",
    "# Prepare evoked data with participant counts for plotting steady state conditions\n",
    "plot_evokeds_steady_state = {}\n",
    "for cond in combined_evokeds_by_steady_state:\n",
    "    if combined_evokeds_by_steady_state[cond]:\n",
    "        plot_evokeds_steady_state[f\"{cond}\\n(n={len(participant_count_by_steady_state[cond])})\"] = combined_evokeds_by_steady_state[cond]\n",
    "\n",
    "# Prepare evoked data with participant counts for plotting random conditions\n",
    "plot_evokeds_random = {}\n",
    "for cond in combined_evokeds_by_random:\n",
    "    if combined_evokeds_by_random[cond]:\n",
    "        plot_evokeds_random[f\"{cond}\\n(n={len(participant_count_by_random[cond])})\"] = combined_evokeds_by_random[cond]\n",
    "\n",
    "# Update colors and styles\n",
    "colors = {\n",
    "    'US': 'darkred',\n",
    "    'UR': 'red',\n",
    "    'AS': 'darkblue',\n",
    "    'AR': 'blue'\n",
    "}\n",
    "styles = {\n",
    "    'UR': {'linestyle': '--'},\n",
    "    'AR': {'linestyle': '--'}\n",
    "}\n",
    "\n",
    "updated_colors_steady_state = {f\"{cond}\\n(n={len(participant_count_by_steady_state[cond])})\": colors[cond] for cond in steady_state_conds}\n",
    "updated_styles_steady_state = {f\"{cond}\\n(n={len(participant_count_by_steady_state[cond])})\": styles[cond] for cond in styles if cond in steady_state_conds}\n",
    "\n",
    "updated_colors_random = {f\"{cond}\\n(n={len(participant_count_by_random[cond])})\": colors[cond] for cond in random_conds}\n",
    "updated_styles_random = {f\"{cond}\\n(n={len(participant_count_by_random[cond])})\": styles[cond] for cond in styles if cond in random_conds}\n",
    "\n",
    "# Function to add shaded regions with labels\n",
    "def add_shaded_region_with_label(ax, start, end, label, y_max):\n",
    "    ax.axvspan(start, end, color='gray', alpha=0.3)\n",
    "    midpoint = (start + end) / 2\n",
    "    ax.text(midpoint, y_max * 0.9, label, horizontalalignment='center', fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "# Plotting steady state conditions\n",
    "fig, ax = plt.subplots()\n",
    "mne.viz.plot_compare_evokeds(\n",
    "    plot_evokeds_steady_state,\n",
    "    picks=\"Cz\",\n",
    "    ci=0.95,\n",
    "    colors=updated_colors_steady_state,\n",
    "    styles=updated_styles_steady_state,\n",
    "    title=\"Grand Average ERPs - Steady State\",\n",
    "    axes=ax\n",
    ")\n",
    "\n",
    "# Get y-axis limits for label placement\n",
    "y_min, y_max = ax.get_ylim()\n",
    "\n",
    "# Add shaded regions and labels\n",
    "add_shaded_region_with_label(ax, 0.19, 0.3, 'P200', y_max)\n",
    "add_shaded_region_with_label(ax, 0.305, 0.5, 'P400', y_max)\n",
    "\n",
    "# Customizing the legend manually\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, fontsize=12, loc='upper left')  # Adjust legend font size here\n",
    "\n",
    "# Extending the x-axis to show time until 0.5 seconds\n",
    "ax.set_xlim(left=ax.get_xlim()[0], right=0.5)  # Extends the right limit to 0.5 seconds\n",
    "\n",
    "# Set explicit x-axis ticks to ensure 0.5 is included and labeled\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(0.1))  # Set major ticks interval\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(0.05))  # Set minor ticks interval\n",
    "\n",
    "# Adjust font size of axis labels and tick labels\n",
    "ax.set_xlabel('Time (s)', fontsize=14)  # Time in seconds with larger font\n",
    "ax.set_ylabel('Amplitude (V)', fontsize=14)  # Amplitude in microvolts with larger font\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)  # Tick labels font size for major ticks\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)  # Tick labels font size for minor ticks\n",
    "\n",
    "# Adjust the title font size\n",
    "ax.set_title(\"Grand Average ERPs - Steady State\", fontsize=16)  # Title with larger font\n",
    "\n",
    "# Set consistent Y-axis ticks\n",
    "ax.set_yticks([-10, -7.5, -5, -2.5, 0, 2.5, 5, 7.5, 10])\n",
    "\n",
    "# Add figure name\n",
    "fig.text(0.5, 0.01, 'Plot B', ha='center', fontsize=14)\n",
    "\n",
    "# Force a redraw of the figure to ensure the plot updates\n",
    "plt.draw()\n",
    "\n",
    "# Optionally, add grid for better readability\n",
    "ax.grid(True)\n",
    "\n",
    "# Ensure everything fits in the plot area\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plotting random conditions\n",
    "fig, ax = plt.subplots()\n",
    "mne.viz.plot_compare_evokeds(\n",
    "    plot_evokeds_random,\n",
    "    picks=\"Cz\",\n",
    "    ci=0.95,\n",
    "    colors=updated_colors_random,\n",
    "    styles=updated_styles_random,\n",
    "    title=\"Grand Average ERPs - Random\",\n",
    "    axes=ax\n",
    ")\n",
    "\n",
    "# Get y-axis limits for label placement\n",
    "y_min, y_max = ax.get_ylim()\n",
    "\n",
    "# Add shaded regions and labels\n",
    "add_shaded_region_with_label(ax, 0.19, 0.3, 'P200', y_max)\n",
    "add_shaded_region_with_label(ax, 0.305, 0.5, 'P400', y_max)\n",
    "\n",
    "# Customizing the legend manually\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, fontsize=12, loc='upper left')  # Adjust legend font size here\n",
    "\n",
    "# Extending the x-axis to show time until 0.5 seconds\n",
    "ax.set_xlim(left=ax.get_xlim()[0], right=0.5)  # Extends the right limit to 0.5 seconds\n",
    "\n",
    "# Set explicit x-axis ticks to ensure 0.5 is included and labeled\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(0.1))  # Set major ticks interval\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(0.05))  # Set minor ticks interval\n",
    "\n",
    "# Adjust font size of axis labels and tick labels\n",
    "ax.set_xlabel('Time (s)', fontsize=14)  # Time in seconds with larger font\n",
    "ax.set_ylabel('Amplitude (V)', fontsize=14)  # Amplitude in microvolts with larger font\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)  # Tick labels font size for major ticks\n",
    "ax.tick_params(axis='both', which='minor', labelsize=10)  # Tick labels font size for minor ticks\n",
    "\n",
    "# Adjust the title font size\n",
    "ax.set_title(\"Grand Average ERPs - Random\", fontsize=16)  # Title with larger font\n",
    "\n",
    "# Set consistent Y-axis ticks\n",
    "ax.set_yticks([-10, -7.5, -5, -2.5, 0, 2.5, 5, 7.5, 10])\n",
    "\n",
    "# Add figure name\n",
    "fig.text(0.5, 0.01, 'Plot C', ha='center', fontsize=14)\n",
    "\n",
    "# Force a redraw of the figure to ensure the plot updates\n",
    "plt.draw()\n",
    "\n",
    "# Optionally, add grid for better readability\n",
    "ax.grid(True)\n",
    "\n",
    "# Ensure everything fits in the plot area\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Condition</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BA</td>\n",
       "      <td>US</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BA</td>\n",
       "      <td>AS</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BA</td>\n",
       "      <td>UR</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BA</td>\n",
       "      <td>AR</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BC</td>\n",
       "      <td>US</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BC</td>\n",
       "      <td>AS</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BC</td>\n",
       "      <td>UR</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BC</td>\n",
       "      <td>AR</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BD</td>\n",
       "      <td>US</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BD</td>\n",
       "      <td>AS</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BD</td>\n",
       "      <td>UR</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BD</td>\n",
       "      <td>AR</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KM</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KM</td>\n",
       "      <td>AS</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KM</td>\n",
       "      <td>UR</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KM</td>\n",
       "      <td>AR</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KN</td>\n",
       "      <td>US</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KN</td>\n",
       "      <td>AS</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KN</td>\n",
       "      <td>UR</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>KN</td>\n",
       "      <td>AR</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KO</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>KO</td>\n",
       "      <td>AS</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>KO</td>\n",
       "      <td>UR</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>KO</td>\n",
       "      <td>AR</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KP</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KP</td>\n",
       "      <td>AS</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KP</td>\n",
       "      <td>UR</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>KP</td>\n",
       "      <td>AR</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AA</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AA</td>\n",
       "      <td>AS</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>AA</td>\n",
       "      <td>UR</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>AA</td>\n",
       "      <td>AR</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>AB</td>\n",
       "      <td>US</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>AB</td>\n",
       "      <td>AS</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>AB</td>\n",
       "      <td>UR</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>AB</td>\n",
       "      <td>AR</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>AC</td>\n",
       "      <td>US</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>AC</td>\n",
       "      <td>AS</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>AC</td>\n",
       "      <td>UR</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>AC</td>\n",
       "      <td>AR</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>AD</td>\n",
       "      <td>US</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>AD</td>\n",
       "      <td>AS</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>AD</td>\n",
       "      <td>UR</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>AD</td>\n",
       "      <td>AR</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>AF</td>\n",
       "      <td>US</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>AF</td>\n",
       "      <td>AS</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>AF</td>\n",
       "      <td>UR</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>AF</td>\n",
       "      <td>AR</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>AG</td>\n",
       "      <td>US</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>AG</td>\n",
       "      <td>AS</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>AG</td>\n",
       "      <td>UR</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>AG</td>\n",
       "      <td>AR</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>AH</td>\n",
       "      <td>US</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>AH</td>\n",
       "      <td>AS</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>AH</td>\n",
       "      <td>UR</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>AH</td>\n",
       "      <td>AR</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>AJ</td>\n",
       "      <td>US</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>AJ</td>\n",
       "      <td>AS</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>AJ</td>\n",
       "      <td>UR</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>AJ</td>\n",
       "      <td>AR</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>AK</td>\n",
       "      <td>US</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>AK</td>\n",
       "      <td>AS</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>AK</td>\n",
       "      <td>UR</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>AK</td>\n",
       "      <td>AR</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>AL</td>\n",
       "      <td>US</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>AL</td>\n",
       "      <td>AS</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>AL</td>\n",
       "      <td>UR</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>AL</td>\n",
       "      <td>AR</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>AO</td>\n",
       "      <td>US</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>AO</td>\n",
       "      <td>AS</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>AO</td>\n",
       "      <td>UR</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>AO</td>\n",
       "      <td>AR</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>AP</td>\n",
       "      <td>US</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>AP</td>\n",
       "      <td>AS</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>AP</td>\n",
       "      <td>UR</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>AP</td>\n",
       "      <td>AR</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>AQ</td>\n",
       "      <td>US</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>AQ</td>\n",
       "      <td>AS</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>AQ</td>\n",
       "      <td>UR</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>AQ</td>\n",
       "      <td>AR</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>AR</td>\n",
       "      <td>US</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>AR</td>\n",
       "      <td>AS</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>AR</td>\n",
       "      <td>UR</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>AR</td>\n",
       "      <td>AR</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>AS</td>\n",
       "      <td>US</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>AS</td>\n",
       "      <td>AS</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>AS</td>\n",
       "      <td>UR</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>AS</td>\n",
       "      <td>AR</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>AT</td>\n",
       "      <td>US</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>AT</td>\n",
       "      <td>AS</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>AT</td>\n",
       "      <td>UR</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>AT</td>\n",
       "      <td>AR</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participant Condition    N\n",
       "0           BA        US  151\n",
       "1           BA        AS  145\n",
       "2           BA        UR  130\n",
       "3           BA        AR  152\n",
       "4           BC        US   89\n",
       "5           BC        AS   96\n",
       "6           BC        UR  150\n",
       "7           BC        AR  152\n",
       "8           BD        US  151\n",
       "9           BD        AS  152\n",
       "10          BD        UR  152\n",
       "11          BD        AR  149\n",
       "12          KM        US  100\n",
       "13          KM        AS  100\n",
       "14          KM        UR   71\n",
       "15          KM        AR   62\n",
       "16          KN        US   98\n",
       "17          KN        AS  100\n",
       "18          KN        UR   78\n",
       "19          KN        AR   67\n",
       "20          KO        US  100\n",
       "21          KO        AS  100\n",
       "22          KO        UR   79\n",
       "23          KO        AR   76\n",
       "24          KP        US  100\n",
       "25          KP        AS  100\n",
       "26          KP        UR   71\n",
       "27          KP        AR   63\n",
       "28          AA        US  100\n",
       "29          AA        AS  100\n",
       "30          AA        UR  100\n",
       "31          AA        AR  100\n",
       "32          AB        US  152\n",
       "33          AB        AS  150\n",
       "34          AB        UR  152\n",
       "35          AB        AR  152\n",
       "36          AC        US  151\n",
       "37          AC        AS  151\n",
       "38          AC        UR  152\n",
       "39          AC        AR  152\n",
       "40          AD        US   76\n",
       "41          AD        AS  143\n",
       "42          AD        UR  150\n",
       "43          AD        AR  146\n",
       "44          AF        US  151\n",
       "45          AF        AS  152\n",
       "46          AF        UR  152\n",
       "47          AF        AR  151\n",
       "48          AG        US  152\n",
       "49          AG        AS  144\n",
       "50          AG        UR   74\n",
       "51          AG        AR  131\n",
       "52          AH        US  148\n",
       "53          AH        AS  152\n",
       "54          AH        UR  148\n",
       "55          AH        AR  150\n",
       "56          AJ        US  136\n",
       "57          AJ        AS  151\n",
       "58          AJ        UR  152\n",
       "59          AJ        AR  142\n",
       "60          AK        US  146\n",
       "61          AK        AS  150\n",
       "62          AK        UR  152\n",
       "63          AK        AR  151\n",
       "64          AL        US  150\n",
       "65          AL        AS  124\n",
       "66          AL        UR  142\n",
       "67          AL        AR   73\n",
       "68          AO        US   72\n",
       "69          AO        AS  110\n",
       "70          AO        UR   92\n",
       "71          AO        AR   99\n",
       "72          AP        US  150\n",
       "73          AP        AS   74\n",
       "74          AP        UR  141\n",
       "75          AP        AR  123\n",
       "76          AQ        US  146\n",
       "77          AQ        AS  146\n",
       "78          AQ        UR  130\n",
       "79          AQ        AR  145\n",
       "80          AR        US  150\n",
       "81          AR        AS  151\n",
       "82          AR        UR  152\n",
       "83          AR        AR  152\n",
       "84          AS        US  142\n",
       "85          AS        AS  145\n",
       "86          AS        UR   76\n",
       "87          AS        AR  142\n",
       "88          AT        US  143\n",
       "89          AT        AS  147\n",
       "90          AT        UR  143\n",
       "91          AT        AR  148"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Increase the maximum number of rows to display the entire DataFrame\n",
    "pd.set_option('display.max_rows', None)\n",
    "data = []\n",
    "for participant, evokeds in all_parts_combined.items():\n",
    "    for evoked in evokeds:\n",
    "        data.append({\n",
    "            \"Participant\": participant,\n",
    "            \"Condition\": evoked.comment.split('/')[0],  \n",
    "            \"N\": evoked.nave\n",
    "        })\n",
    "\n",
    "df_evokeds = pd.DataFrame(data)\n",
    "# print(df_evokeds)\n",
    "\n",
    "# Display the DataFrame of all participants after preprocessing\n",
    "display(df_evokeds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Finding peak function for P200 and P400\"\"\"\n",
    "\n",
    "# Function to detect peaks in the evoked response\n",
    "def detect_peaks(evoked, ch_name='Cz'):\n",
    "    sfreq = evoked.info['sfreq']  # Sample frequency\n",
    "\n",
    "    # Time ranges for P200 and P400 in seconds\n",
    "    P200_range = (0.29, 0.4)\n",
    "    P400_range = (0.4, 0.6)\n",
    "    # Convert time ranges to sample indices\n",
    "    idx_range_P2 = (int(P200_range[0] * sfreq), int(P200_range[1] * sfreq))\n",
    "    idx_range_P4 = (int(P400_range[0] * sfreq), int(P400_range[1] * sfreq))\n",
    "    \n",
    "    # Select data for 'Cz' electrode\n",
    "    ch_idx = mne.pick_channels(evoked.ch_names, include=[ch_name])\n",
    "    data_P2 = evoked.data[ch_idx, idx_range_P2[0]:idx_range_P2[1]][0]\n",
    "    data_P4 = evoked.data[ch_idx, idx_range_P4[0]:idx_range_P4[1]][0]\n",
    "\n",
    "    # Detect peaks in the specified ranges\n",
    "    peaks_P2 = find_peaks(data_P2, distance=sfreq*P200_range[0])[0]  # enforcing minimum distance\n",
    "    peaks_P4 = find_peaks(data_P4, distance=sfreq*P400_range[0])[0]\n",
    "\n",
    "    # Find peak with the maximum amplitude in each range\n",
    "    if len(peaks_P2) > 0:\n",
    "        peak_amp_P2 = data_P2[peaks_P2[np.argmax(data_P2[peaks_P2])]]\n",
    "        peak_time_P2 = evoked.times[idx_range_P2[0] + peaks_P2[np.argmax(data_P2[peaks_P2])]]\n",
    "    else:\n",
    "        peak_amp_P2 = None\n",
    "        peak_time_P2 = None\n",
    "\n",
    "    if len(peaks_P4) > 0:\n",
    "        peak_amp_P4 = data_P4[peaks_P4[np.argmax(data_P4[peaks_P4])]]\n",
    "        peak_time_P4 = evoked.times[idx_range_P4[0] + peaks_P4[np.argmax(data_P4[peaks_P4])]]\n",
    "    else:\n",
    "        peak_amp_P4 = None\n",
    "        peak_time_P4 = None\n",
    "\n",
    "    return {\n",
    "        'P200_amplitude': peak_amp_P2,\n",
    "        'P200_time': peak_time_P2,\n",
    "        'P400_amplitude': peak_amp_P4,\n",
    "        'P400_time': peak_time_P4\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detect_peaks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m participant, evokeds \u001b[39min\u001b[39;00m all_parts_combined\u001b[39m.\u001b[39mitems():\n\u001b[0;32m      4\u001b[0m     \u001b[39mfor\u001b[39;00m evoked \u001b[39min\u001b[39;00m evokeds:\n\u001b[0;32m      5\u001b[0m         \u001b[39m# Detect peaks (you should have this function from previous snippets)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m         peaks \u001b[39m=\u001b[39m detect_peaks(evoked)\n\u001b[0;32m      7\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCondition \u001b[39m\u001b[39m{\u001b[39;00mevoked\u001b[39m.\u001b[39mcomment\u001b[39m}\u001b[39;00m\u001b[39m - P200 Time: \u001b[39m\u001b[39m{\u001b[39;00mpeaks[\u001b[39m'\u001b[39m\u001b[39mP200_time\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m, Amplitude: \u001b[39m\u001b[39m{\u001b[39;00mpeaks[\u001b[39m'\u001b[39m\u001b[39mP200_amplitude\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-----------------------------------------------------------------------------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'detect_peaks' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"Plot all peaks from participants and save it\"\"\"\n",
    "## Find peaks for all participants\n",
    "for participant, evokeds in all_parts_combined.items():\n",
    "    for evoked in evokeds:\n",
    "        # Detect peaks (you should have this function from previous snippets)\n",
    "        peaks = detect_peaks(evoked)\n",
    "        print(f\"Condition {evoked.comment} - P200 Time: {peaks['P200_time']}, Amplitude: {peaks['P200_amplitude']}\")\n",
    "        print(\"-----------------------------------------------------------------------------------------------------\")\n",
    "        print(f\"Condition {evoked.comment} - P400 Time: {peaks['P400_time']}, Amplitude: {peaks['P400_amplitude']}\")\n",
    "        if peaks['P400_time'] is not None:\n",
    "            print(f\"Detected P400 peak at {peaks['P400_time']} s\")\n",
    "        \n",
    "        lat_P2 = peaks.get('P200_time', None)\n",
    "        lat_P4 = peaks.get('P400_time', None)\n",
    "        # Prepare the figure\n",
    "        fig = plt.figure(figsize=(8, 10))\n",
    "        ax1 = fig.add_subplot(2, 1, 1)\n",
    "        ax2 = fig.add_subplot(2, 2, 3)\n",
    "        ax3 = fig.add_subplot(2, 2, 4)\n",
    "\n",
    "        # Plot the compare evokeds for 'Cz' with vertical lines at the peak latencies\n",
    "        mne.viz.plot_compare_evokeds(\n",
    "            evoked.copy().pick(['Cz']), \n",
    "            vlines=[lat_P2, lat_P4] if None not in [lat_P2, lat_P4] else None,\n",
    "            legend=False, \n",
    "            title=f'Participant {participant} - Condition {evoked.comment}', \n",
    "            axes=ax1\n",
    "        )\n",
    "\n",
    "        # Plot topomaps at the detected peak times\n",
    "        if lat_P2 is not None:\n",
    "            evoked.plot_topomap(times=[lat_P2], ch_type=\"eeg\", colorbar=False, axes=ax2)\n",
    "        if lat_P4 is not None:\n",
    "            evoked.plot_topomap(times=[lat_P4], ch_type=\"eeg\", colorbar=False, axes=ax3)\n",
    "\n",
    "        # Adjust layout and save the figure\n",
    "        fig.tight_layout()\n",
    "        filename = f'Participant_{participant}_{evoked.comment}_peaks'\n",
    "        # fig.savefig(f'{filename}.png') ## save the file in the directory\n",
    "        plt.show()\n",
    "# if 'AO' in all_parts:\n",
    "#     evokeds = all_parts['AO']\n",
    "    # for evoked in evokeds:\n",
    "    #         # Detect peaks (you should have this function from previous snippets)\n",
    "    #         peaks = detect_peaks(evoked)\n",
    "    #         print(f\"Condition {evoked.comment} - P200 Time: {peaks['P200_time']}, Amplitude: {peaks['P200_amplitude']}\")\n",
    "    #         print(f\"Condition {evoked.comment} - P400 Time: {peaks['P400_time']}, Amplitude: {peaks['P400_amplitude']}\")\n",
    "    #         if peaks['P400_time'] is not None:\n",
    "    #             print(f\"Detected P400 peak at {peaks['P400_time']} s\")\n",
    "            \n",
    "    #         lat_P2 = peaks.get('P200_time', None)\n",
    "    #         lat_P4 = peaks.get('P400_time', None)\n",
    "    #         # Prepare the figure\n",
    "    #         fig = plt.figure(figsize=(8, 10))\n",
    "    #         ax1 = fig.add_subplot(2, 1, 1)\n",
    "    #         ax2 = fig.add_subplot(2, 2, 3)\n",
    "    #         ax3 = fig.add_subplot(2, 2, 4)\n",
    "\n",
    "    #         # Plot the compare evokeds for 'Cz' with vertical lines at the peak latencies\n",
    "    #         mne.viz.plot_compare_evokeds(\n",
    "    #             evoked.copy().pick(['Cz']), \n",
    "    #             vlines=[lat_P2, lat_P4] if None not in [lat_P2, lat_P4] else None,\n",
    "    #             legend=False, \n",
    "    #             title=f'Participant {participant} - Condition {evoked.comment}', \n",
    "    #             axes=ax1\n",
    "    #         )\n",
    "\n",
    "    #         # Plot topomaps at the detected peak times\n",
    "    #         if lat_P2 is not None:\n",
    "    #             evoked.plot_topomap(times=[lat_P2], ch_type=\"eeg\", colorbar=False, axes=ax2)\n",
    "    #         if lat_P4 is not None:\n",
    "    #             evoked.plot_topomap(times=[lat_P4], ch_type=\"eeg\", colorbar=False, axes=ax3)\n",
    "\n",
    "    #         # Adjust layout and save the figure\n",
    "    #         fig.tight_layout()\n",
    "    #         # filename = f'Participant_{participant}_{evoked.comment}_peaks'\n",
    "    #         # fig.savefig(f'{filename}.png')\n",
    "    #         plt.show()\n",
    "else:\n",
    "    print(\"Participant {participant} not found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P200 Amplitude ANOVA\n",
      "                      Anova\n",
      "==================================================\n",
      "                     F Value Num DF  Den DF Pr > F\n",
      "--------------------------------------------------\n",
      "Ambiguity             1.3298 1.0000 22.0000 0.2612\n",
      "Randomness            1.3794 1.0000 22.0000 0.2528\n",
      "Ambiguity:Randomness  0.6274 1.0000 22.0000 0.4368\n",
      "==================================================\n",
      "\n",
      "P400 Amplitude ANOVA\n",
      "                      Anova\n",
      "==================================================\n",
      "                     F Value Num DF  Den DF Pr > F\n",
      "--------------------------------------------------\n",
      "Ambiguity            40.2018 1.0000 22.0000 0.0000\n",
      "Randomness            5.3990 1.0000 22.0000 0.0298\n",
      "Ambiguity:Randomness  0.7003 1.0000 22.0000 0.4117\n",
      "==================================================\n",
      "\n",
      "P200 Latency ANOVA\n",
      "                      Anova\n",
      "==================================================\n",
      "                     F Value Num DF  Den DF Pr > F\n",
      "--------------------------------------------------\n",
      "Ambiguity             2.0781 1.0000 22.0000 0.1635\n",
      "Randomness           12.8186 1.0000 22.0000 0.0017\n",
      "Ambiguity:Randomness  0.3489 1.0000 22.0000 0.5608\n",
      "==================================================\n",
      "\n",
      "P400 Latency ANOVA\n",
      "                      Anova\n",
      "==================================================\n",
      "                     F Value Num DF  Den DF Pr > F\n",
      "--------------------------------------------------\n",
      "Ambiguity             4.0211 1.0000 22.0000 0.0574\n",
      "Randomness            0.9528 1.0000 22.0000 0.3396\n",
      "Ambiguity:Randomness  0.0181 1.0000 22.0000 0.8942\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\875302821.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df2122 = pd.concat([df2122, entry], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"UNCORRECTED ANOVA TEST FOR ALL PARTICIPANTS\"\"\"\n",
    "# Create an empty DataFrame\n",
    "df2122 = pd.DataFrame(columns=['Participant', 'Condition', 'Ambiguity', 'Randomness', 'P200_Amplitude', 'P400_Amplitude'])\n",
    "\n",
    "# Populate the DataFrame with the peak detection results\n",
    "for participant, evokeds in all_parts_combined.items():\n",
    "    for evoked in evokeds:\n",
    "        peaks = detect_peaks(evoked)\n",
    "        entry = pd.DataFrame({\n",
    "            'Participant': [participant],\n",
    "            'Condition': [evoked.comment],\n",
    "            'Ambiguity': ['Ambiguous' if 'A' in evoked.comment else 'Unambiguous'],\n",
    "            'Randomness': ['Random' if 'R' in evoked.comment else 'Steady State'],\n",
    "            'P200_Amplitude': [peaks.get('P200_amplitude', np.nan)],  # use np.nan for missing data\n",
    "            'P200_Latency': peaks.get('P200_time', np.nan),\n",
    "            'P400_Amplitude': [peaks.get('P400_amplitude', np.nan)],\n",
    "            'P400_Latency': [peaks.get('P400_time', np.nan)]\n",
    "        })\n",
    "        \n",
    "        df2122 = pd.concat([df2122, entry], ignore_index=True)\n",
    "# print(df2122)\n",
    "df2122['P200_Amplitude'] = df2122['P200_Amplitude'] * 1e6 ### convert to microvolt\n",
    "df2122['P400_Amplitude'] = df2122['P400_Amplitude'] * 1e6\n",
    "# Running ANOVA for P200 amplitude\n",
    "model_p200_amp = AnovaRM(df2122.dropna(subset=['P200_Amplitude']), 'P200_Amplitude', 'Participant', within=['Ambiguity', 'Randomness'])\n",
    "res_p200_amp = model_p200_amp.fit()\n",
    "print(\"P200 Amplitude ANOVA\")\n",
    "print(res_p200_amp)\n",
    "\n",
    "# Running ANOVA for P400 amplitude\n",
    "model_p400_amp = AnovaRM(df2122.dropna(subset=['P400_Amplitude']), 'P400_Amplitude', 'Participant', within=['Ambiguity', 'Randomness'])\n",
    "res_p400_amp = model_p400_amp.fit()\n",
    "print(\"P400 Amplitude ANOVA\")\n",
    "print(res_p400_amp)\n",
    "\n",
    "# Running ANOVA for P200 latency\n",
    "model_p200_lat = AnovaRM(df2122.dropna(subset=['P200_Latency']), 'P200_Latency', 'Participant', within=['Ambiguity', 'Randomness'])\n",
    "res_p200_lat = model_p200_lat.fit()\n",
    "print(\"P200 Latency ANOVA\")\n",
    "print(res_p200_lat)\n",
    "\n",
    "# Running ANOVA for P400 latency\n",
    "model_p400_lat = AnovaRM(df2122.dropna(subset=['P400_Latency']), 'P400_Latency', 'Participant', within=['Ambiguity', 'Randomness'])\n",
    "res_p400_lat = model_p400_lat.fit()\n",
    "print(\"P400 Latency ANOVA\")\n",
    "print(res_p400_lat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P200 Amplitude ANOVA\n",
      "                      Anova\n",
      "==================================================\n",
      "                     F Value Num DF  Den DF Pr > F\n",
      "--------------------------------------------------\n",
      "Ambiguity             1.3298 1.0000 22.0000 0.2612\n",
      "Randomness            1.3794 1.0000 22.0000 0.2528\n",
      "Ambiguity:Randomness  0.6274 1.0000 22.0000 0.4368\n",
      "==================================================\n",
      "\n",
      "\n",
      "Bonferroni Corrected P200 Amplitude ANOVA p-values:\n",
      "Ambiguity               1\n",
      "Randomness              1\n",
      "Ambiguity:Randomness    1\n",
      "Name: Pr > F, dtype: int64\n",
      "\n",
      "P400 Amplitude ANOVA\n",
      "                      Anova\n",
      "==================================================\n",
      "                     F Value Num DF  Den DF Pr > F\n",
      "--------------------------------------------------\n",
      "Ambiguity            40.2018 1.0000 22.0000 0.0000\n",
      "Randomness            5.3990 1.0000 22.0000 0.0298\n",
      "Ambiguity:Randomness  0.7003 1.0000 22.0000 0.4117\n",
      "==================================================\n",
      "\n",
      "\n",
      "Bonferroni Corrected P400 Amplitude ANOVA p-values:\n",
      "Ambiguity               0.000009\n",
      "Randomness              0.119135\n",
      "Ambiguity:Randomness    1.000000\n",
      "Name: Pr > F, dtype: float64\n",
      "\n",
      "P200 Latency ANOVA\n",
      "                      Anova\n",
      "==================================================\n",
      "                     F Value Num DF  Den DF Pr > F\n",
      "--------------------------------------------------\n",
      "Ambiguity             2.0781 1.0000 22.0000 0.1635\n",
      "Randomness           12.8186 1.0000 22.0000 0.0017\n",
      "Ambiguity:Randomness  0.3489 1.0000 22.0000 0.5608\n",
      "==================================================\n",
      "\n",
      "\n",
      "Bonferroni Corrected P200 Latency ANOVA p-values:\n",
      "Ambiguity               0.654028\n",
      "Randomness              0.006675\n",
      "Ambiguity:Randomness    1.000000\n",
      "Name: Pr > F, dtype: float64\n",
      "\n",
      "P400 Latency ANOVA\n",
      "                      Anova\n",
      "==================================================\n",
      "                     F Value Num DF  Den DF Pr > F\n",
      "--------------------------------------------------\n",
      "Ambiguity             4.0211 1.0000 22.0000 0.0574\n",
      "Randomness            0.9528 1.0000 22.0000 0.3396\n",
      "Ambiguity:Randomness  0.0181 1.0000 22.0000 0.8942\n",
      "==================================================\n",
      "\n",
      "\n",
      "Bonferroni Corrected P400 Latency ANOVA p-values:\n",
      "Ambiguity               0.229565\n",
      "Randomness              1.000000\n",
      "Ambiguity:Randomness    1.000000\n",
      "Name: Pr > F, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Corrected Anova test\"\"\"\n",
    "\n",
    "num_tests = 4\n",
    "# Run ANOVA for P200 Amplitude, P400 Amplitude, P200 Latency, and P400 Latency\n",
    "res_p200_amp = AnovaRM(df2122.dropna(subset=['P200_Amplitude']), 'P200_Amplitude', 'Participant', within=['Ambiguity', 'Randomness']).fit()\n",
    "res_p400_amp = AnovaRM(df2122.dropna(subset=['P400_Amplitude']), 'P400_Amplitude', 'Participant', within=['Ambiguity', 'Randomness']).fit()\n",
    "res_p200_lat = AnovaRM(df2122.dropna(subset=['P200_Latency']), 'P200_Latency', 'Participant', within=['Ambiguity', 'Randomness']).fit()\n",
    "res_p400_lat = AnovaRM(df2122.dropna(subset=['P400_Latency']), 'P400_Latency', 'Participant', within=['Ambiguity', 'Randomness']).fit()\n",
    "\n",
    "# Apply Bonferroni correction\n",
    "corrected_p200_amp = res_p200_amp.anova_table['Pr > F'] * num_tests\n",
    "corrected_p400_amp = res_p400_amp.anova_table['Pr > F'] * num_tests\n",
    "corrected_p200_lat = res_p200_lat.anova_table['Pr > F'] * num_tests\n",
    "corrected_p400_lat = res_p400_lat.anova_table['Pr > F'] * num_tests\n",
    "\n",
    "# Ensure p-values do not exceed 1 after correction\n",
    "corrected_p200_amp = corrected_p200_amp.apply(lambda x: min(x, 1))\n",
    "corrected_p400_amp = corrected_p400_amp.apply(lambda x: min(x, 1))\n",
    "corrected_p200_lat = corrected_p200_lat.apply(lambda x: min(x, 1))\n",
    "corrected_p400_lat = corrected_p400_lat.apply(lambda x: min(x, 1))\n",
    "\n",
    "# Printing results\n",
    "print(\"P200 Amplitude ANOVA\")\n",
    "print(res_p200_amp)\n",
    "print(\"\\nBonferroni Corrected P200 Amplitude ANOVA p-values:\")\n",
    "print(corrected_p200_amp)\n",
    "\n",
    "print(\"\\nP400 Amplitude ANOVA\")\n",
    "print(res_p400_amp)\n",
    "print(\"\\nBonferroni Corrected P400 Amplitude ANOVA p-values:\")\n",
    "print(corrected_p400_amp)\n",
    "\n",
    "print(\"\\nP200 Latency ANOVA\")\n",
    "print(res_p200_lat)\n",
    "print(\"\\nBonferroni Corrected P200 Latency ANOVA p-values:\")\n",
    "print(corrected_p200_lat)\n",
    "\n",
    "print(\"\\nP400 Latency ANOVA\")\n",
    "print(res_p400_lat)\n",
    "print(\"\\nBonferroni Corrected P400 Latency ANOVA p-values:\")\n",
    "print(corrected_p400_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P200 Amplitude ANOVA\n",
      "Ambiguity - F Value: 1.3298226669454392, p-value: 0.2612124317259424, Partial Eta Squared: 0.057000976215287796\n",
      "Randomness - F Value: 1.3793929049505596, p-value: 0.25276133531249273, Partial Eta Squared: 0.059000373130239606\n",
      "Ambiguity:Randomness - F Value: 0.6273875695083952, p-value: 0.4367732227250336, Partial Eta Squared: 0.02772691136266359\n",
      "P400 Amplitude ANOVA\n",
      "Ambiguity - F Value: 40.201757695029166, p-value: 2.2179968774043187e-06, Partial Eta Squared: 0.6463122455821192\n",
      "Randomness - F Value: 5.398963344931899, p-value: 0.02978383401305363, Partial Eta Squared: 0.19704991305558164\n",
      "Ambiguity:Randomness - F Value: 0.7002700609131252, p-value: 0.41169111313140827, Partial Eta Squared: 0.03084853435813955\n",
      "P200 Latency ANOVA\n",
      "Ambiguity - F Value: 2.07813284987221, p-value: 0.16350704846934133, Partial Eta Squared: 0.08630789035135833\n",
      "Randomness - F Value: 12.818597249989821, p-value: 0.0016687967614118081, Partial Eta Squared: 0.36815375294860764\n",
      "Ambiguity:Randomness - F Value: 0.3488859764089205, p-value: 0.5607639919383169, Partial Eta Squared: 0.015610888917559391\n",
      "P400 Latency ANOVA\n",
      "Ambiguity - F Value: 4.021052194017888, p-value: 0.057391305107082916, Partial Eta Squared: 0.1545307301194495\n",
      "Randomness - F Value: 0.9528163680095366, p-value: 0.3396155148066713, Partial Eta Squared: 0.04151195882599939\n",
      "Ambiguity:Randomness - F Value: 0.01810973670470798, p-value: 0.8941735283616048, Partial Eta Squared: 0.0008224927989398937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\2222521068.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dfAll = pd.concat([dfAll, entry], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Uncorrected Anova test with details for all participants\"\"\"\n",
    "\n",
    "# Create an empty DataFrame\n",
    "dfAll = pd.DataFrame(columns=['Participant', 'Condition', 'Ambiguity', 'Randomness', 'P200_Amplitude', 'P200_Latency', 'P400_Amplitude', 'P400_Latency'])\n",
    "\n",
    "# Populate the DataFrame with the peak detection results\n",
    "for participant, evokeds in all_parts_combined.items():\n",
    "    for evoked in evokeds:\n",
    "        peaks = detect_peaks(evoked)\n",
    "        entry = pd.DataFrame({\n",
    "            'Participant': [participant],\n",
    "            'Condition': [evoked.comment],\n",
    "            'Ambiguity': ['Ambiguous' if 'A' in evoked.comment else 'Unambiguous'],\n",
    "            'Randomness': ['Random' if 'R' in evoked.comment else 'Steady State'],\n",
    "            'P200_Amplitude': [peaks.get('P200_amplitude', np.nan)],  # use np.nan for missing data\n",
    "            'P200_Latency': [peaks.get('P200_time', np.nan)],\n",
    "            'P400_Amplitude': [peaks.get('P400_amplitude', np.nan)],\n",
    "            'P400_Latency': [peaks.get('P400_time', np.nan)] \n",
    "        })\n",
    "        \n",
    "        dfAll = pd.concat([dfAll, entry], ignore_index=True)\n",
    "\n",
    "dfAll['P200_Amplitude'] = dfAll['P200_Amplitude'] * 1e6\n",
    "dfAll['P400_Amplitude'] = dfAll['P400_Amplitude'] * 1e6\n",
    "\n",
    "def calculate_partial_eta_squared(f_value, df_effect, df_error):\n",
    "    return (f_value * df_effect) / (f_value * df_effect + df_error)\n",
    "\n",
    "# Function to print ANOVA results with effect sizes\n",
    "def print_anova_with_effect_sizes(res):\n",
    "    anova_table = res.anova_table\n",
    "    for effect in anova_table.index:\n",
    "        f_value = anova_table.loc[effect, 'F Value']\n",
    "        df_effect = anova_table.loc[effect, 'Num DF']\n",
    "        df_error = anova_table.loc[effect, 'Den DF']\n",
    "        partial_eta_squared = calculate_partial_eta_squared(f_value, df_effect, df_error)\n",
    "        print(f\"{effect} - F Value: {f_value}, p-value: {anova_table.loc[effect, 'Pr > F']}, Partial Eta Squared: {partial_eta_squared}\")\n",
    "\n",
    "# Running ANOVA for P200 amplitude\n",
    "model_p200_amp = AnovaRM(dfAll.dropna(subset=['P200_Amplitude']), 'P200_Amplitude', 'Participant', within=['Ambiguity', 'Randomness'])\n",
    "res_p200_amp = model_p200_amp.fit()\n",
    "print(\"P200 Amplitude ANOVA\")\n",
    "print_anova_with_effect_sizes(res_p200_amp)\n",
    "\n",
    "# Running ANOVA for P400 amplitude\n",
    "model_p400_amp = AnovaRM(dfAll.dropna(subset=['P400_Amplitude']), 'P400_Amplitude', 'Participant', within=['Ambiguity', 'Randomness'])\n",
    "res_p400_amp = model_p400_amp.fit()\n",
    "print(\"P400 Amplitude ANOVA\")\n",
    "print_anova_with_effect_sizes(res_p400_amp)\n",
    "\n",
    "# Running ANOVA for P200 latency\n",
    "model_p200_lat = AnovaRM(dfAll.dropna(subset=['P200_Latency']), 'P200_Latency', 'Participant', within=['Ambiguity', 'Randomness'])\n",
    "res_p200_lat = model_p200_lat.fit()\n",
    "print(\"P200 Latency ANOVA\")\n",
    "print_anova_with_effect_sizes(res_p200_lat)\n",
    "\n",
    "# Running ANOVA for P400 latency\n",
    "model_p400_lat = AnovaRM(dfAll.dropna(subset=['P400_Latency']), 'P400_Latency', 'Participant', within=['Ambiguity', 'Randomness'])\n",
    "res_p400_lat = model_p400_lat.fit()\n",
    "print(\"P400 Latency ANOVA\")\n",
    "print_anova_with_effect_sizes(res_p400_lat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P200 Amplitude ANOVA\n",
      "Ambiguity - F Value: 1.3298226669454392, p-value: 0.2612124317259424, Partial Eta Squared: 0.057000976215287796\n",
      "Randomness - F Value: 1.3793929049505596, p-value: 0.25276133531249273, Partial Eta Squared: 0.059000373130239606\n",
      "Ambiguity:Randomness - F Value: 0.6273875695083952, p-value: 0.4367732227250336, Partial Eta Squared: 0.02772691136266359\n",
      "P400 Amplitude ANOVA\n",
      "Ambiguity - F Value: 40.201757695029166, p-value: 2.2179968774043187e-06, Partial Eta Squared: 0.6463122455821192\n",
      "Randomness - F Value: 5.398963344931899, p-value: 0.02978383401305363, Partial Eta Squared: 0.19704991305558164\n",
      "Ambiguity:Randomness - F Value: 0.7002700609131252, p-value: 0.41169111313140827, Partial Eta Squared: 0.03084853435813955\n",
      "P200 Latency ANOVA\n",
      "Ambiguity - F Value: 2.07813284987221, p-value: 0.16350704846934133, Partial Eta Squared: 0.08630789035135833\n",
      "Randomness - F Value: 12.818597249989821, p-value: 0.0016687967614118081, Partial Eta Squared: 0.36815375294860764\n",
      "Ambiguity:Randomness - F Value: 0.3488859764089205, p-value: 0.5607639919383169, Partial Eta Squared: 0.015610888917559391\n",
      "P400 Latency ANOVA\n",
      "Ambiguity - F Value: 4.021052194017888, p-value: 0.057391305107082916, Partial Eta Squared: 0.1545307301194495\n",
      "Randomness - F Value: 0.9528163680095366, p-value: 0.3396155148066713, Partial Eta Squared: 0.04151195882599939\n",
      "Ambiguity:Randomness - F Value: 0.01810973670470798, p-value: 0.8941735283616048, Partial Eta Squared: 0.0008224927989398937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2923938866.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df2122 = pd.concat([df2122, entry], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Uncorrected Anova test with details for all participants\"\"\"\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df2122 = pd.DataFrame(columns=['Participant', 'Condition', 'Ambiguity', 'Randomness', 'P200_Amplitude', 'P200_Latency', 'P400_Amplitude', 'P400_Latency'])\n",
    "\n",
    "# Populate the DataFrame with the peak detection results\n",
    "for participant, evokeds in all_parts_combined.items():\n",
    "    for evoked in evokeds:\n",
    "        peaks = detect_peaks(evoked)\n",
    "        entry = pd.DataFrame({\n",
    "            'Participant': [participant],\n",
    "            'Condition': [evoked.comment],\n",
    "            'Ambiguity': ['Ambiguous' if 'A' in evoked.comment else 'Unambiguous'],\n",
    "            'Randomness': ['Random' if 'R' in evoked.comment else 'Steady State'],\n",
    "            'P200_Amplitude': [peaks.get('P200_amplitude', np.nan)],  # use np.nan for missing data\n",
    "            'P200_Latency': [peaks.get('P200_time', np.nan)],\n",
    "            'P400_Amplitude': [peaks.get('P400_amplitude', np.nan)],\n",
    "            'P400_Latency': [peaks.get('P400_time', np.nan)] \n",
    "        })\n",
    "        \n",
    "        df2122 = pd.concat([df2122, entry], ignore_index=True)\n",
    "\n",
    "df2122['P200_Amplitude'] = df2122['P200_Amplitude'] * 1e6\n",
    "df2122['P400_Amplitude'] = df2122['P400_Amplitude'] * 1e6\n",
    "\n",
    "def calculate_partial_eta_squared(f_value, df_effect, df_error):\n",
    "    return (f_value * df_effect) / (f_value * df_effect + df_error)\n",
    "\n",
    "# Function to print ANOVA results with effect sizes\n",
    "def print_anova_with_effect_sizes(res):\n",
    "    anova_table = res.anova_table\n",
    "    for effect in anova_table.index:\n",
    "        f_value = anova_table.loc[effect, 'F Value']\n",
    "        df_effect = anova_table.loc[effect, 'Num DF']\n",
    "        df_error = anova_table.loc[effect, 'Den DF']\n",
    "        partial_eta_squared = calculate_partial_eta_squared(f_value, df_effect, df_error)\n",
    "        print(f\"{effect} - F Value: {f_value}, p-value: {anova_table.loc[effect, 'Pr > F']}, Partial Eta Squared: {partial_eta_squared}\")\n",
    "\n",
    "# Running ANOVA for P200 amplitude\n",
    "model_p200_amp = AnovaRM(df2122.dropna(subset=['P200_Amplitude']), 'P200_Amplitude', 'Participant', within=['Ambiguity', 'Randomness'])\n",
    "res_p200_amp = model_p200_amp.fit()\n",
    "print(\"P200 Amplitude ANOVA\")\n",
    "print_anova_with_effect_sizes(res_p200_amp)\n",
    "\n",
    "# Running ANOVA for P400 amplitude\n",
    "model_p400_amp = AnovaRM(df2122.dropna(subset=['P400_Amplitude']), 'P400_Amplitude', 'Participant', within=['Ambiguity', 'Randomness'])\n",
    "res_p400_amp = model_p400_amp.fit()\n",
    "print(\"P400 Amplitude ANOVA\")\n",
    "print_anova_with_effect_sizes(res_p400_amp)\n",
    "\n",
    "# Running ANOVA for P200 latency\n",
    "model_p200_lat = AnovaRM(df2122.dropna(subset=['P200_Latency']), 'P200_Latency', 'Participant', within=['Ambiguity', 'Randomness'])\n",
    "res_p200_lat = model_p200_lat.fit()\n",
    "print(\"P200 Latency ANOVA\")\n",
    "print_anova_with_effect_sizes(res_p200_lat)\n",
    "\n",
    "# Running ANOVA for P400 latency\n",
    "model_p400_lat = AnovaRM(df2122.dropna(subset=['P400_Latency']), 'P400_Latency', 'Participant', within=['Ambiguity', 'Randomness'])\n",
    "res_p400_lat = model_p400_lat.fit()\n",
    "print(\"P400 Latency ANOVA\")\n",
    "print_anova_with_effect_sizes(res_p400_lat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3574163733.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df2122 = pd.concat([df2122, entry], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P200 Amplitude-Ambiguity ANOVA\n",
      "        Source          SS  DF1  DF2         MS         F     p-unc       np2  \\\n",
      "0        Group  245.075556    3   19  81.691852  2.380436  0.101634  0.273181   \n",
      "1    Ambiguity    4.743967    1   19   4.743967  1.460726  0.241642  0.071392   \n",
      "2  Interaction   16.776232    3   19   5.592077  1.721870  0.196403  0.213759   \n",
      "\n",
      "   eps  \n",
      "0  NaN  \n",
      "1  1.0  \n",
      "2  NaN  \n",
      "P400 Amplitude-Ambiguity ANOVA\n",
      "        Source          SS  DF1  DF2          MS          F     p-unc  \\\n",
      "0        Group  287.722908    3   19   95.907636   3.231081  0.045459   \n",
      "1    Ambiguity  165.977592    1   19  165.977592  36.856992  0.000008   \n",
      "2  Interaction    5.267095    3   19    1.755698   0.389870  0.761625   \n",
      "\n",
      "        np2  eps  \n",
      "0  0.337823  NaN  \n",
      "1  0.659846  1.0  \n",
      "2  0.057989  NaN  \n",
      "P200 Latency-Ambiguity ANOVA\n",
      "        Source        SS  DF1  DF2        MS         F     p-unc       np2  \\\n",
      "0        Group  0.004698    3   19  0.001566  3.990485  0.023192  0.386532   \n",
      "1    Ambiguity  0.000047    1   19  0.000047  2.883433  0.105813  0.131763   \n",
      "2  Interaction  0.000188    3   19  0.000063  3.841749  0.026374  0.377564   \n",
      "\n",
      "   eps  \n",
      "0  NaN  \n",
      "1  1.0  \n",
      "2  NaN  \n",
      "P400 Latency-Ambiguity ANOVA\n",
      "        Source        SS  DF1  DF2        MS         F     p-unc       np2  \\\n",
      "0        Group  0.006431    3   19  0.002144  0.988252  0.419388  0.134978   \n",
      "1    Ambiguity  0.005544    1   19  0.005544  5.089256  0.036055  0.211267   \n",
      "2  Interaction  0.009635    3   19  0.003212  2.948120  0.059052  0.317636   \n",
      "\n",
      "   eps  \n",
      "0  NaN  \n",
      "1  1.0  \n",
      "2  NaN  \n",
      "P200 Amplitude-Randomness ANOVA\n",
      "        Source          SS  DF1  DF2         MS         F     p-unc       np2  \\\n",
      "0        Group  245.075556    3   19  81.691852  2.380436  0.101634  0.273181   \n",
      "1   Randomness    3.757532    1   19   3.757532  1.313834  0.265933  0.064677   \n",
      "2  Interaction    5.589512    3   19   1.863171  0.651464  0.591765  0.093269   \n",
      "\n",
      "   eps  \n",
      "0  NaN  \n",
      "1  1.0  \n",
      "2  NaN  \n",
      "P400 Amplitude-Randomness ANOVA\n",
      "        Source          SS  DF1  DF2         MS         F     p-unc       np2  \\\n",
      "0        Group  287.722908    3   19  95.907636  3.231081  0.045459  0.337823   \n",
      "1   Randomness   31.774189    1   19  31.774189  5.673331  0.027833  0.229938   \n",
      "2  Interaction   23.063413    3   19   7.687804  1.372669  0.281375  0.178130   \n",
      "\n",
      "   eps  \n",
      "0  NaN  \n",
      "1  1.0  \n",
      "2  NaN  \n",
      "P200 Latency-Randomness ANOVA\n",
      "        Source        SS  DF1  DF2        MS          F     p-unc       np2  \\\n",
      "0        Group  0.004698    3   19  0.001566   3.990485  0.023192  0.386532   \n",
      "1   Randomness  0.000155    1   19  0.000155  12.572966  0.002159  0.398219   \n",
      "2  Interaction  0.000032    3   19  0.000011   0.859478  0.479017  0.119491   \n",
      "\n",
      "   eps  \n",
      "0  NaN  \n",
      "1  1.0  \n",
      "2  NaN  \n",
      "P400 Latency-Randomness ANOVA\n",
      "        Source        SS  DF1  DF2        MS         F     p-unc       np2  \\\n",
      "0        Group  0.006431    3   19  0.002144  0.988252  0.419388  0.134978   \n",
      "1   Randomness  0.000793    1   19  0.000793  0.881021  0.359702  0.044315   \n",
      "2  Interaction  0.001208    3   19  0.000403  0.447429  0.721974  0.065985   \n",
      "\n",
      "   eps  \n",
      "0  NaN  \n",
      "1  1.0  \n",
      "2  NaN  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"Anova test with pingouin and group test only for dataset 2021-2022-2023\"\"\"\n",
    "\n",
    "# Define participant groups\n",
    "groups = {\n",
    "    'Group1': ['KM', 'KN', 'KO', 'KP'],\n",
    "    'Group2': ['BA', 'BC', 'BD'],\n",
    "    'Group3': ['AA', 'AB', 'AC', 'AD', 'AF', 'AG', 'AH'],\n",
    "    'Group4': ['AJ', 'AK', 'AL', 'AO', 'AP', 'AQ', 'AR', 'AS', 'AT']\n",
    "}\n",
    "\n",
    "# Create a reverse lookup dictionary for participant groups\n",
    "participant_to_group = {}\n",
    "for group_name, participants in groups.items():\n",
    "    for participant in participants:\n",
    "        participant_to_group[participant] = group_name\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df2122 = pd.DataFrame(columns=['Participant', 'Group', 'Condition', 'Ambiguity', 'Randomness', 'P200_Amplitude', 'P200_Latency', 'P400_Amplitude', 'P400_Latency'])\n",
    "\n",
    "# Populate the DataFrame with the peak detection results\n",
    "for participant, evokeds in all_parts_combined.items():\n",
    "    group = participant_to_group.get(participant, 'Unknown')  # Get group, default to 'Unknown'\n",
    "    for evoked in evokeds:\n",
    "        peaks = detect_peaks(evoked)\n",
    "        entry = pd.DataFrame({\n",
    "            'Participant': [participant],\n",
    "            'Group': [group],\n",
    "            'Condition': [evoked.comment],\n",
    "            'Ambiguity': ['Ambiguous' if 'A' in evoked.comment else 'Unambiguous'],\n",
    "            'Randomness': ['Random' if 'R' in evoked.comment else 'Steady State'],\n",
    "            'P200_Amplitude': [peaks.get('P200_amplitude', np.nan)],\n",
    "            'P200_Latency': [peaks.get('P200_time', np.nan)],\n",
    "            'P400_Amplitude': [peaks.get('P400_amplitude', np.nan)],\n",
    "            'P400_Latency': [peaks.get('P400_time', np.nan)]\n",
    "        })\n",
    "        df2122 = pd.concat([df2122, entry], ignore_index=True)\n",
    "\n",
    "# print(dfAll.head())  # Print first few rows to check\n",
    "df2122['P200_Amplitude'] = df2122['P200_Amplitude'] * 1e6\n",
    "df2122['P400_Amplitude'] = df2122['P400_Amplitude'] * 1e6\n",
    "# Run mixed ANOVA for P200 amplitude\n",
    "aov_p200_amp = pg.mixed_anova(data=df2122.dropna(subset=['P200_Amplitude']), dv='P200_Amplitude', between='Group', within='Ambiguity', subject='Participant')\n",
    "print(\"P200 Amplitude-Ambiguity ANOVA\")\n",
    "print(aov_p200_amp)\n",
    "\n",
    "# Run mixed ANOVA for P400 amplitude\n",
    "aov_p400_amp = pg.mixed_anova(data=df2122.dropna(subset=['P400_Amplitude']), dv='P400_Amplitude', between='Group', within='Ambiguity', subject='Participant')\n",
    "print(\"P400 Amplitude-Ambiguity ANOVA\")\n",
    "print(aov_p400_amp)\n",
    "\n",
    "# Run mixed ANOVA for P200 latency\n",
    "aov_p200_lat = pg.mixed_anova(data=df2122.dropna(subset=['P200_Latency']), dv='P200_Latency', between='Group', within='Ambiguity', subject='Participant')\n",
    "print(\"P200 Latency-Ambiguity ANOVA\")\n",
    "print(aov_p200_lat)\n",
    "\n",
    "# Run mixed ANOVA for P400 latency\n",
    "aov_p400_lat = pg.mixed_anova(data=df2122.dropna(subset=['P400_Latency']), dv='P400_Latency', between='Group', within='Ambiguity', subject='Participant')\n",
    "print(\"P400 Latency-Ambiguity ANOVA\")\n",
    "print(aov_p400_lat)\n",
    "\n",
    "\n",
    "\n",
    "# Run mixed ANOVA for P200 amplitude\n",
    "aov_p200_amp = pg.mixed_anova(data=df2122.dropna(subset=['P200_Amplitude']), dv='P200_Amplitude', between='Group', within='Randomness', subject='Participant')\n",
    "print(\"P200 Amplitude-Randomness ANOVA\")\n",
    "print(aov_p200_amp)\n",
    "\n",
    "# Run mixed ANOVA for P400 amplitude\n",
    "aov_p400_amp = pg.mixed_anova(data=df2122.dropna(subset=['P400_Amplitude']), dv='P400_Amplitude', between='Group', within='Randomness', subject='Participant')\n",
    "print(\"P400 Amplitude-Randomness ANOVA\")\n",
    "print(aov_p400_amp)\n",
    "\n",
    "# Run mixed ANOVA for P200 latency\n",
    "aov_p200_lat = pg.mixed_anova(data=df2122.dropna(subset=['P200_Latency']), dv='P200_Latency', between='Group', within='Randomness', subject='Participant')\n",
    "print(\"P200 Latency-Randomness ANOVA\")\n",
    "print(aov_p200_lat)\n",
    "\n",
    "# Run mixed ANOVA for P400 latency\n",
    "aov_p400_lat = pg.mixed_anova(data=df2122.dropna(subset=['P400_Latency']), dv='P400_Latency', between='Group', within='Randomness', subject='Participant')\n",
    "print(\"P400 Latency-Randomness ANOVA\")\n",
    "print(aov_p400_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2260176270.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dfAll = pd.concat([dfAll, entry], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P200 Amplitude-Ambiguity ANOVA\n",
      "        Source          SS  DF1  DF2         MS         F     p-unc       np2  \\\n",
      "0        Group  245.075556    3   19  81.691852  2.380436  0.101634  0.273181   \n",
      "1    Ambiguity    4.743967    1   19   4.743967  1.460726  0.241642  0.071392   \n",
      "2  Interaction   16.776232    3   19   5.592077  1.721870  0.196403  0.213759   \n",
      "\n",
      "   eps  \n",
      "0  NaN  \n",
      "1  1.0  \n",
      "2  NaN  \n",
      "P400 Amplitude-Ambiguity ANOVA\n",
      "        Source          SS  DF1  DF2          MS          F     p-unc  \\\n",
      "0        Group  287.722908    3   19   95.907636   3.231081  0.045459   \n",
      "1    Ambiguity  165.977592    1   19  165.977592  36.856992  0.000008   \n",
      "2  Interaction    5.267095    3   19    1.755698   0.389870  0.761625   \n",
      "\n",
      "        np2  eps  \n",
      "0  0.337823  NaN  \n",
      "1  0.659846  1.0  \n",
      "2  0.057989  NaN  \n",
      "P200 Latency-Ambiguity ANOVA\n",
      "        Source        SS  DF1  DF2        MS         F     p-unc       np2  \\\n",
      "0        Group  0.004698    3   19  0.001566  3.990485  0.023192  0.386532   \n",
      "1    Ambiguity  0.000047    1   19  0.000047  2.883433  0.105813  0.131763   \n",
      "2  Interaction  0.000188    3   19  0.000063  3.841749  0.026374  0.377564   \n",
      "\n",
      "   eps  \n",
      "0  NaN  \n",
      "1  1.0  \n",
      "2  NaN  \n",
      "P400 Latency-Ambiguity ANOVA\n",
      "        Source        SS  DF1  DF2        MS         F     p-unc       np2  \\\n",
      "0        Group  0.006431    3   19  0.002144  0.988252  0.419388  0.134978   \n",
      "1    Ambiguity  0.005544    1   19  0.005544  5.089256  0.036055  0.211267   \n",
      "2  Interaction  0.009635    3   19  0.003212  2.948120  0.059052  0.317636   \n",
      "\n",
      "   eps  \n",
      "0  NaN  \n",
      "1  1.0  \n",
      "2  NaN  \n",
      "P200 Amplitude-Randomness ANOVA\n",
      "        Source          SS  DF1  DF2         MS         F     p-unc       np2  \\\n",
      "0        Group  245.075556    3   19  81.691852  2.380436  0.101634  0.273181   \n",
      "1   Randomness    3.757532    1   19   3.757532  1.313834  0.265933  0.064677   \n",
      "2  Interaction    5.589512    3   19   1.863171  0.651464  0.591765  0.093269   \n",
      "\n",
      "   eps  \n",
      "0  NaN  \n",
      "1  1.0  \n",
      "2  NaN  \n",
      "P400 Amplitude-Randomness ANOVA\n",
      "        Source          SS  DF1  DF2         MS         F     p-unc       np2  \\\n",
      "0        Group  287.722908    3   19  95.907636  3.231081  0.045459  0.337823   \n",
      "1   Randomness   31.774189    1   19  31.774189  5.673331  0.027833  0.229938   \n",
      "2  Interaction   23.063413    3   19   7.687804  1.372669  0.281375  0.178130   \n",
      "\n",
      "   eps  \n",
      "0  NaN  \n",
      "1  1.0  \n",
      "2  NaN  \n",
      "P200 Latency-Randomness ANOVA\n",
      "        Source        SS  DF1  DF2        MS          F     p-unc       np2  \\\n",
      "0        Group  0.004698    3   19  0.001566   3.990485  0.023192  0.386532   \n",
      "1   Randomness  0.000155    1   19  0.000155  12.572966  0.002159  0.398219   \n",
      "2  Interaction  0.000032    3   19  0.000011   0.859478  0.479017  0.119491   \n",
      "\n",
      "   eps  \n",
      "0  NaN  \n",
      "1  1.0  \n",
      "2  NaN  \n",
      "P400 Latency-Randomness ANOVA\n",
      "        Source        SS  DF1  DF2        MS         F     p-unc       np2  \\\n",
      "0        Group  0.006431    3   19  0.002144  0.988252  0.419388  0.134978   \n",
      "1   Randomness  0.000793    1   19  0.000793  0.881021  0.359702  0.044315   \n",
      "2  Interaction  0.001208    3   19  0.000403  0.447429  0.721974  0.065985   \n",
      "\n",
      "   eps  \n",
      "0  NaN  \n",
      "1  1.0  \n",
      "2  NaN  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"Anova test with pingouin and group test only for all participants\"\"\"\n",
    "\n",
    "# Define participant groups\n",
    "groups = {\n",
    "    'Group1': ['KM', 'KN', 'KO', 'KP'],\n",
    "    'Group2': ['BA', 'BC', 'BD'],\n",
    "    'Group3': ['AA', 'AB', 'AC', 'AD', 'AF', 'AG', 'AH'],\n",
    "    'Group4': ['AJ', 'AK', 'AL', 'AO', 'AP', 'AQ', 'AR', 'AS', 'AT']\n",
    "}\n",
    "\n",
    "# Create a reverse lookup dictionary for participant groups\n",
    "participant_to_group = {}\n",
    "for group_name, participants in groups.items():\n",
    "    for participant in participants:\n",
    "        participant_to_group[participant] = group_name\n",
    "\n",
    "# Create an empty DataFrame\n",
    "dfAll = pd.DataFrame(columns=['Participant', 'Group', 'Condition', 'Ambiguity', 'Randomness', 'P200_Amplitude', 'P200_Latency', 'P400_Amplitude', 'P400_Latency'])\n",
    "\n",
    "# Populate the DataFrame with the peak detection results\n",
    "for participant, evokeds in all_parts_combined.items():\n",
    "    group = participant_to_group.get(participant, 'Unknown')  # Get group, default to 'Unknown'\n",
    "    for evoked in evokeds:\n",
    "        peaks = detect_peaks(evoked)\n",
    "        entry = pd.DataFrame({\n",
    "            'Participant': [participant],\n",
    "            'Group': [group],\n",
    "            'Condition': [evoked.comment],\n",
    "            'Ambiguity': ['Ambiguous' if 'A' in evoked.comment else 'Unambiguous'],\n",
    "            'Randomness': ['Random' if 'R' in evoked.comment else 'Steady State'],\n",
    "            'P200_Amplitude': [peaks.get('P200_amplitude', np.nan)],\n",
    "            'P200_Latency': [peaks.get('P200_time', np.nan)],\n",
    "            'P400_Amplitude': [peaks.get('P400_amplitude', np.nan)],\n",
    "            'P400_Latency': [peaks.get('P400_time', np.nan)]\n",
    "        })\n",
    "        dfAll = pd.concat([dfAll, entry], ignore_index=True)\n",
    "        \n",
    "\n",
    "# print(dfAll.head())  # Print first few rows to check\n",
    "dfAll['P200_Amplitude'] = dfAll['P200_Amplitude'] * 1e6\n",
    "dfAll['P400_Amplitude'] = dfAll['P400_Amplitude'] * 1e6\n",
    "# Run mixed ANOVA for P200 amplitude\n",
    "aov_p200_amp = pg.mixed_anova(data=dfAll.dropna(subset=['P200_Amplitude']), dv='P200_Amplitude', between='Group', within='Ambiguity', subject='Participant')\n",
    "print(\"P200 Amplitude-Ambiguity ANOVA\")\n",
    "print(aov_p200_amp)\n",
    "\n",
    "# Run mixed ANOVA for P400 amplitude\n",
    "aov_p400_amp = pg.mixed_anova(data=dfAll.dropna(subset=['P400_Amplitude']), dv='P400_Amplitude', between='Group', within='Ambiguity', subject='Participant')\n",
    "print(\"P400 Amplitude-Ambiguity ANOVA\")\n",
    "print(aov_p400_amp)\n",
    "\n",
    "# Run mixed ANOVA for P200 latency\n",
    "aov_p200_lat = pg.mixed_anova(data=dfAll.dropna(subset=['P200_Latency']), dv='P200_Latency', between='Group', within='Ambiguity', subject='Participant')\n",
    "print(\"P200 Latency-Ambiguity ANOVA\")\n",
    "print(aov_p200_lat)\n",
    "\n",
    "# Run mixed ANOVA for P400 latency\n",
    "aov_p400_lat = pg.mixed_anova(data=dfAll.dropna(subset=['P400_Latency']), dv='P400_Latency', between='Group', within='Ambiguity', subject='Participant')\n",
    "print(\"P400 Latency-Ambiguity ANOVA\")\n",
    "print(aov_p400_lat)\n",
    "\n",
    "\n",
    "\n",
    "# Run mixed ANOVA for P200 amplitude\n",
    "aov_p200_amp = pg.mixed_anova(data=dfAll.dropna(subset=['P200_Amplitude']), dv='P200_Amplitude', between='Group', within='Randomness', subject='Participant')\n",
    "print(\"P200 Amplitude-Randomness ANOVA\")\n",
    "print(aov_p200_amp)\n",
    "\n",
    "# Run mixed ANOVA for P400 amplitude\n",
    "aov_p400_amp = pg.mixed_anova(data=dfAll.dropna(subset=['P400_Amplitude']), dv='P400_Amplitude', between='Group', within='Randomness', subject='Participant')\n",
    "print(\"P400 Amplitude-Randomness ANOVA\")\n",
    "print(aov_p400_amp)\n",
    "\n",
    "# Run mixed ANOVA for P200 latency\n",
    "aov_p200_lat = pg.mixed_anova(data=dfAll.dropna(subset=['P200_Latency']), dv='P200_Latency', between='Group', within='Randomness', subject='Participant')\n",
    "print(\"P200 Latency-Randomness ANOVA\")\n",
    "print(aov_p200_lat)\n",
    "\n",
    "# Run mixed ANOVA for P400 latency\n",
    "aov_p400_lat = pg.mixed_anova(data=dfAll.dropna(subset=['P400_Latency']), dv='P400_Latency', between='Group', within='Randomness', subject='Participant')\n",
    "print(\"P400 Latency-Randomness ANOVA\")\n",
    "print(aov_p400_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3514180731.py:7: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='Condition', y='P200_Amplitude', data=dfAll, palette={'US': 'darkred', 'AS': 'darkblue', 'UR': 'red', 'AR': 'blue'}, showfliers=False)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3514180731.py:18: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='Condition', y='P400_Amplitude', data=dfAll, palette={'US': 'darkred', 'AS': 'darkblue', 'UR': 'red', 'AR': 'blue'}, showfliers=False)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3514180731.py:29: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='Condition', y='P200_Latency', data=dfAll, palette={'US': 'darkred', 'AS': 'darkblue', 'UR': 'red', 'AR': 'blue'}, showfliers=False)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3514180731.py:40: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='Condition', y='P400_Latency', data=dfAll, palette={'US': 'darkred', 'AS': 'darkblue', 'UR': 'red', 'AR': 'blue'}, showfliers=False)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Create boxplot for amplitude and latency values\"\"\"\n",
    "\n",
    "# Create boxplots for P200 Amplitude\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Condition', y='P200_Amplitude', data=dfAll, palette={'US': 'darkred', 'AS': 'darkblue', 'UR': 'red', 'AR': 'blue'}, showfliers=False)\n",
    "sns.stripplot(x='Condition', y='P200_Amplitude', data=dfAll, color='green', jitter=0.2, size=5)  # Increased size\n",
    "plt.title('P200 Amplitude by Condition', fontsize=16)\n",
    "plt.xlabel('Condition', fontsize=14)\n",
    "plt.ylabel('P200 Amplitude (V)', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Create boxplots for P400 Amplitude\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Condition', y='P400_Amplitude', data=dfAll, palette={'US': 'darkred', 'AS': 'darkblue', 'UR': 'red', 'AR': 'blue'}, showfliers=False)\n",
    "sns.stripplot(x='Condition', y='P400_Amplitude', data=dfAll, color='green', jitter=0.2, size=5)  # Increased size\n",
    "plt.title('P400 Amplitude by Condition', fontsize=16)\n",
    "plt.xlabel('Condition', fontsize=14)\n",
    "plt.ylabel('P400 Amplitude (V)', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Create boxplots for P200 Latency\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Condition', y='P200_Latency', data=dfAll, palette={'US': 'darkred', 'AS': 'darkblue', 'UR': 'red', 'AR': 'blue'}, showfliers=False)\n",
    "sns.stripplot(x='Condition', y='P200_Latency', data=dfAll, color='green', jitter=0.2, size=5)  # Increased size\n",
    "plt.title('P200 Latency by Condition', fontsize=16)\n",
    "plt.xlabel('Condition', fontsize=14)\n",
    "plt.ylabel('P200 Latency (ms)', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Create boxplots for P400 Latency\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='Condition', y='P400_Latency', data=dfAll, palette={'US': 'darkred', 'AS': 'darkblue', 'UR': 'red', 'AR': 'blue'}, showfliers=False)\n",
    "sns.stripplot(x='Condition', y='P400_Latency', data=dfAll, color='green', jitter=0.2, size=5)  # Increased size\n",
    "plt.title('P400 Latency by Condition', fontsize=16)\n",
    "plt.xlabel('Condition', fontsize=14)\n",
    "plt.ylabel('P400 Latency (ms)', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3590523954.py:16: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.boxplot(x='Ambiguity', y='P200_Amplitude', data=dfAll, palette=color_palette_ambiguity, showfliers=False)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3590523954.py:28: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.boxplot(x='Ambiguity', y='P400_Amplitude', data=dfAll, palette=color_palette_ambiguity, showfliers=False)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3590523954.py:40: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.boxplot(x='Randomness', y='P200_Amplitude', data=dfAll, palette=color_palette_randomness, showfliers=False)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3590523954.py:52: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.boxplot(x='Randomness', y='P400_Amplitude', data=dfAll, palette=color_palette_randomness, showfliers=False)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3590523954.py:64: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.boxplot(x='Ambiguity', y='P200_Latency', data=dfAll, palette=color_palette_ambiguity, showfliers=False)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3590523954.py:76: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.boxplot(x='Ambiguity', y='P400_Latency', data=dfAll, palette=color_palette_ambiguity, showfliers=False)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3590523954.py:88: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.boxplot(x='Randomness', y='P200_Latency', data=dfAll, palette=color_palette_randomness, showfliers=False)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3590523954.py:100: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  ax = sns.boxplot(x='Randomness', y='P400_Latency', data=dfAll, palette=color_palette_randomness, showfliers=False)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\categorical.py:632: FutureWarning: SeriesGroupBy.grouper is deprecated and will be removed in a future version of pandas.\n",
      "  positions = grouped.grouper.result_index.to_numpy(dtype=float)\n",
      "c:\\Python311\\Lib\\site-packages\\seaborn\\_base.py:948: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Boxplots with p-values\"\"\"\n",
    "\n",
    "# Define a color palette\n",
    "color_palette_ambiguity = {'Ambiguous': 'blue', 'Unambiguous': 'red'}\n",
    "color_palette_randomness = {'Random': 'green', 'Steady State': 'orange'}\n",
    "\n",
    "# Function to add p-values in the middle of the plot\n",
    "def add_p_value(text, ax):\n",
    "    # Get the y-limit of the current plot\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    # Calculate the vertical position (middle of the plot)\n",
    "    y_pos = (y_max + y_min) / 2\n",
    "    # Add text annotation\n",
    "    ax.text(0.5, y_pos, text, ha='center', va='center', fontsize=12, color='black', bbox=dict(facecolor='white', alpha=0.6))\n",
    "\n",
    "# Create boxplots for P200 Amplitude grouped by Ambiguity\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.boxplot(x='Ambiguity', y='P200_Amplitude', data=dfAll, palette=color_palette_ambiguity, showfliers=False)\n",
    "sns.stripplot(x='Ambiguity', y='P200_Amplitude', data=dfAll, color='black', jitter=0.2, size=5)\n",
    "plt.title('P200 Amplitude by Ambiguity', fontsize=16)\n",
    "plt.xlabel('Ambiguity', fontsize=14)\n",
    "plt.ylabel('P200 Amplitude (V)', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "add_p_value('p-value: 0.26', ax)\n",
    "plt.show()\n",
    "\n",
    "# Create boxplots for P400 Amplitude grouped by Ambiguity\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.boxplot(x='Ambiguity', y='P400_Amplitude', data=dfAll, palette=color_palette_ambiguity, showfliers=False)\n",
    "sns.stripplot(x='Ambiguity', y='P400_Amplitude', data=dfAll, color='black', jitter=0.2, size=5)\n",
    "plt.title('P400 Amplitude by Ambiguity', fontsize=16)\n",
    "plt.xlabel('Ambiguity', fontsize=14)\n",
    "plt.ylabel('P400 Amplitude (V)', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "add_p_value('p-value: 0.000008, corrected p-value: 0.000009', ax)\n",
    "plt.show()\n",
    "\n",
    "# Create boxplots for P200 Amplitude grouped by Randomness\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.boxplot(x='Randomness', y='P200_Amplitude', data=dfAll, palette=color_palette_randomness, showfliers=False)\n",
    "sns.stripplot(x='Randomness', y='P200_Amplitude', data=dfAll, color='black', jitter=0.2, size=5)\n",
    "plt.title('P200 Amplitude by Randomness', fontsize=16)\n",
    "plt.xlabel('Randomness', fontsize=14)\n",
    "plt.ylabel('P200 Amplitude (V)', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "add_p_value('p-value: 0.25', ax)\n",
    "plt.show()\n",
    "\n",
    "# Create boxplots for P400 Amplitude grouped by Randomness\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.boxplot(x='Randomness', y='P400_Amplitude', data=dfAll, palette=color_palette_randomness, showfliers=False)\n",
    "sns.stripplot(x='Randomness', y='P400_Amplitude', data=dfAll, color='black', jitter=0.2, size=5)\n",
    "plt.title('P400 Amplitude by Randomness', fontsize=16)\n",
    "plt.xlabel('Randomness', fontsize=14)\n",
    "plt.ylabel('P400 Amplitude (V)', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "add_p_value('p-value: 0.02, corrected p-value: 0.1', ax)\n",
    "plt.show()\n",
    "\n",
    "# Create boxplots for P200 Latency grouped by Ambiguity\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.boxplot(x='Ambiguity', y='P200_Latency', data=dfAll, palette=color_palette_ambiguity, showfliers=False)\n",
    "sns.stripplot(x='Ambiguity', y='P200_Latency', data=dfAll, color='black', jitter=0.2, size=5)\n",
    "plt.title('P200 Latency by Ambiguity', fontsize=16)\n",
    "plt.xlabel('Ambiguity', fontsize=14)\n",
    "plt.ylabel('P200 Latency (ms)', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "add_p_value('p-value: 0.16', ax)\n",
    "plt.show()\n",
    "\n",
    "# Create boxplots for P400 Latency grouped by Ambiguity\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.boxplot(x='Ambiguity', y='P400_Latency', data=dfAll, palette=color_palette_ambiguity, showfliers=False)\n",
    "sns.stripplot(x='Ambiguity', y='P400_Latency', data=dfAll, color='black', jitter=0.2, size=5)\n",
    "plt.title('P400 Latency by Ambiguity', fontsize=16)\n",
    "plt.xlabel('Ambiguity', fontsize=14)\n",
    "plt.ylabel('P400 Latency (ms)', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "add_p_value('p-value: 0.004, corrected p-value: 0.2', ax)\n",
    "plt.show()\n",
    "\n",
    "# Create boxplots for P200 Latency grouped by Randomness\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.boxplot(x='Randomness', y='P200_Latency', data=dfAll, palette=color_palette_randomness, showfliers=False)\n",
    "sns.stripplot(x='Randomness', y='P200_Latency', data=dfAll, color='black', jitter=0.2, size=5)\n",
    "plt.title('P200 Latency by Randomness', fontsize=16)\n",
    "plt.xlabel('Randomness', fontsize=14)\n",
    "plt.ylabel('P200 Latency (ms)', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "add_p_value('p-value: 0.002, corrected p-value: 0.006', ax)\n",
    "plt.show()\n",
    "\n",
    "# Create boxplots for P400 Latency grouped by Randomness\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.boxplot(x='Randomness', y='P400_Latency', data=dfAll, palette=color_palette_randomness, showfliers=False)\n",
    "sns.stripplot(x='Randomness', y='P400_Latency', data=dfAll, color='black', jitter=0.2, size=5)\n",
    "plt.title('P400 Latency by Randomness', fontsize=16)\n",
    "plt.xlabel('Randomness', fontsize=14)\n",
    "plt.ylabel('P400 Latency (ms)', fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "add_p_value('p-value: 0.35', ax)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Group</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Ambiguity</th>\n",
       "      <th>Randomness</th>\n",
       "      <th>P200_Amplitude</th>\n",
       "      <th>P200_Latency</th>\n",
       "      <th>P400_Amplitude</th>\n",
       "      <th>P400_Latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BA</td>\n",
       "      <td>Group2</td>\n",
       "      <td>US</td>\n",
       "      <td>Unambiguous</td>\n",
       "      <td>Study State</td>\n",
       "      <td>3.369963</td>\n",
       "      <td>0.241</td>\n",
       "      <td>4.178744</td>\n",
       "      <td>0.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BA</td>\n",
       "      <td>Group2</td>\n",
       "      <td>AS</td>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Study State</td>\n",
       "      <td>2.213954</td>\n",
       "      <td>0.231</td>\n",
       "      <td>1.350312</td>\n",
       "      <td>0.306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BA</td>\n",
       "      <td>Group2</td>\n",
       "      <td>UR</td>\n",
       "      <td>Unambiguous</td>\n",
       "      <td>Random</td>\n",
       "      <td>4.139553</td>\n",
       "      <td>0.232</td>\n",
       "      <td>5.437677</td>\n",
       "      <td>0.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BA</td>\n",
       "      <td>Group2</td>\n",
       "      <td>AR</td>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Random</td>\n",
       "      <td>3.356740</td>\n",
       "      <td>0.236</td>\n",
       "      <td>3.017965</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BC</td>\n",
       "      <td>Group2</td>\n",
       "      <td>US</td>\n",
       "      <td>Unambiguous</td>\n",
       "      <td>Study State</td>\n",
       "      <td>12.390849</td>\n",
       "      <td>0.222</td>\n",
       "      <td>3.106674</td>\n",
       "      <td>0.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>AS</td>\n",
       "      <td>Group4</td>\n",
       "      <td>AR</td>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Random</td>\n",
       "      <td>12.565052</td>\n",
       "      <td>0.229</td>\n",
       "      <td>5.598564</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>AT</td>\n",
       "      <td>Group4</td>\n",
       "      <td>US</td>\n",
       "      <td>Unambiguous</td>\n",
       "      <td>Study State</td>\n",
       "      <td>13.063968</td>\n",
       "      <td>0.246</td>\n",
       "      <td>8.247790</td>\n",
       "      <td>0.423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>AT</td>\n",
       "      <td>Group4</td>\n",
       "      <td>AS</td>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Study State</td>\n",
       "      <td>9.903590</td>\n",
       "      <td>0.240</td>\n",
       "      <td>7.837134</td>\n",
       "      <td>0.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>AT</td>\n",
       "      <td>Group4</td>\n",
       "      <td>UR</td>\n",
       "      <td>Unambiguous</td>\n",
       "      <td>Random</td>\n",
       "      <td>8.314536</td>\n",
       "      <td>0.247</td>\n",
       "      <td>5.482178</td>\n",
       "      <td>0.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>AT</td>\n",
       "      <td>Group4</td>\n",
       "      <td>AR</td>\n",
       "      <td>Ambiguous</td>\n",
       "      <td>Random</td>\n",
       "      <td>6.197472</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.694251</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participant   Group Condition    Ambiguity   Randomness  P200_Amplitude  \\\n",
       "0           BA  Group2        US  Unambiguous  Study State        3.369963   \n",
       "1           BA  Group2        AS    Ambiguous  Study State        2.213954   \n",
       "2           BA  Group2        UR  Unambiguous       Random        4.139553   \n",
       "3           BA  Group2        AR    Ambiguous       Random        3.356740   \n",
       "4           BC  Group2        US  Unambiguous  Study State       12.390849   \n",
       "..         ...     ...       ...          ...          ...             ...   \n",
       "87          AS  Group4        AR    Ambiguous       Random       12.565052   \n",
       "88          AT  Group4        US  Unambiguous  Study State       13.063968   \n",
       "89          AT  Group4        AS    Ambiguous  Study State        9.903590   \n",
       "90          AT  Group4        UR  Unambiguous       Random        8.314536   \n",
       "91          AT  Group4        AR    Ambiguous       Random        6.197472   \n",
       "\n",
       "    P200_Latency  P400_Amplitude  P400_Latency  \n",
       "0          0.241        4.178744         0.322  \n",
       "1          0.231        1.350312         0.306  \n",
       "2          0.232        5.437677         0.420  \n",
       "3          0.236        3.017965         0.326  \n",
       "4          0.222        3.106674         0.418  \n",
       "..           ...             ...           ...  \n",
       "87         0.229        5.598564         0.333  \n",
       "88         0.246        8.247790         0.423  \n",
       "89         0.240        7.837134         0.447  \n",
       "90         0.247        5.482178         0.448  \n",
       "91         0.245        0.694251         0.435  \n",
       "\n",
       "[92 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Participant Condition    Ambiguity    Randomness  P200_Amplitude  \\\n",
      "0           BA        US  Unambiguous  Steady State        3.369963   \n",
      "1           BA        AS    Ambiguous  Steady State        2.213954   \n",
      "2           BA        UR  Unambiguous        Random        4.139553   \n",
      "3           BA        AR    Ambiguous        Random        3.356740   \n",
      "4           BC        US  Unambiguous  Steady State       12.390849   \n",
      "..         ...       ...          ...           ...             ...   \n",
      "87          AS        AR    Ambiguous        Random       12.565052   \n",
      "88          AT        US  Unambiguous  Steady State       13.063968   \n",
      "89          AT        AS    Ambiguous  Steady State        9.903590   \n",
      "90          AT        UR  Unambiguous        Random        8.314536   \n",
      "91          AT        AR    Ambiguous        Random        6.197472   \n",
      "\n",
      "    P200_Latency  P400_Amplitude  P400_Latency  \n",
      "0          0.241        4.178744         0.322  \n",
      "1          0.231        1.350312         0.306  \n",
      "2          0.232        5.437677         0.420  \n",
      "3          0.236        3.017965         0.326  \n",
      "4          0.222        3.106674         0.418  \n",
      "..           ...             ...           ...  \n",
      "87         0.229        5.598564         0.333  \n",
      "88         0.246        8.247790         0.423  \n",
      "89         0.240        7.837134         0.447  \n",
      "90         0.247        5.482178         0.448  \n",
      "91         0.245        0.694251         0.435  \n",
      "\n",
      "[92 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df2122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\740432192.py:4: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  color_map = plt.cm.get_cmap('tab20', len(participants))  # 'tab20' has 20 distinct colors, adjust if needed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Scatter plot for P200 amplitude\"\"\"\n",
    "# Create a color map for participants\n",
    "participants = df2122['Participant'].unique()  # Extract participants\n",
    "color_map = plt.cm.get_cmap('tab20', len(participants))  # 'tab20' has 20 distinct colors, adjust if needed\n",
    "\n",
    "# Create a dictionary to map each participant to a color\n",
    "participant_colors = {participant: color_map(i) for i, participant in enumerate(participants)}\n",
    "\n",
    "# Filter data for plotting\n",
    "unambiguous_study_state_data = df2122[(df2122['Ambiguity'] == 'Unambiguous') & (df2122['Randomness'] == 'Steady State')]\n",
    "ambiguous_study_state_data = df2122[(df2122['Ambiguity'] == 'Ambiguous') & (df2122['Randomness'] == 'Steady State')]\n",
    "unambiguous_random_data = df2122[(df2122['Ambiguity'] == 'Unambiguous') & (df2122['Randomness'] == 'Random')]\n",
    "ambiguous_random_data = df2122[(df2122['Ambiguity'] == 'Ambiguous') & (df2122['Randomness'] == 'Random')]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(5, 5))\n",
    "marker_size = 100  # Increased marker size\n",
    "for participant in participants:\n",
    "    # Filter by participant\n",
    "    part_unamb_study = unambiguous_study_state_data[unambiguous_study_state_data['Participant'] == participant]['P200_Amplitude']\n",
    "    part_amb_study = ambiguous_study_state_data[ambiguous_study_state_data['Participant'] == participant]['P200_Amplitude']\n",
    "    part_unamb_random = unambiguous_random_data[unambiguous_random_data['Participant'] == participant]['P200_Amplitude']\n",
    "    part_amb_random = ambiguous_random_data[ambiguous_random_data['Participant'] == participant]['P200_Amplitude']\n",
    "    \n",
    "    # Ensure there are data points to plot\n",
    "    min_study = min(len(part_unamb_study), len(part_amb_study))\n",
    "    min_random = min(len(part_unamb_random), len(part_amb_random))\n",
    "    \n",
    "    # Plotting each participant's data with specific color\n",
    "    plt.scatter(part_amb_study[:min_study], part_unamb_study[:min_study], color=participant_colors[participant], marker='o', s=marker_size)\n",
    "    plt.scatter(part_amb_random[:min_random], part_unamb_random[:min_random], color=participant_colors[participant], marker='x', s=marker_size)\n",
    "\n",
    "# Calculate limits based on data\n",
    "buffer = 0.25\n",
    "all_ambiguity = df2122['P200_Amplitude'].dropna()\n",
    "all_unambiguity = df2122['P200_Amplitude'].dropna()\n",
    "xlim_min = min(all_ambiguity.min(), all_unambiguity.min()) - buffer\n",
    "xlim_max = max(all_ambiguity.max(), all_unambiguity.max()) + buffer\n",
    "ylim_min = xlim_min  # Assuming symmetry for simplicity\n",
    "ylim_max = xlim_max \n",
    "# Plot diagonal line\n",
    "plt.plot([xlim_min, xlim_max], [ylim_min, ylim_max], color='brown', linestyle='--')\n",
    "plt.xlim(xlim_min, xlim_max)\n",
    "plt.ylim(ylim_min, ylim_max)\n",
    "\n",
    "# Enhance the legend to show unique entries only\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))  # This removes duplicate labels\n",
    "\n",
    "# Custom legend entries for 'o' and 'x' markers\n",
    "custom_legend_entries = [plt.Line2D([0], [0], marker='o', color='r', markerfacecolor='k', markersize=10, label='Steady State'),\n",
    "                         plt.Line2D([0], [0], marker='x', color='b', markerfacecolor='k', markersize=10, label='Random')]\n",
    "\n",
    "# Combine custom legend entries with unique participant entries\n",
    "combined_legend = custom_legend_entries + list(by_label.values())\n",
    "\n",
    "# Create combined legend\n",
    "legend_labels = [entry.get_label() for entry in custom_legend_entries] + list(by_label.keys())\n",
    "legend = plt.legend(combined_legend, legend_labels, loc='upper left', bbox_to_anchor=(1, 1), borderaxespad=0., markerscale=0.7, title_fontsize='small')\n",
    "plt.setp(legend.get_texts(), fontsize='x-small')\n",
    "\n",
    "plt.xlabel('Ambiguous Amplitude (V)', fontsize=16)\n",
    "plt.ylabel('Unambiguous Amplitude (V)', fontsize=16)\n",
    "plt.title('P200 Peak Amplitudes', fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()  # Adjust the layout to make room for the legend\n",
    "# Add Figure name under the X axis label\n",
    "plt.text((xlim_min + xlim_max) / 2, ylim_min - (ylim_max - ylim_min) * 0.15, 'Plot D', ha='center', fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1835408799.py:4: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  color_map = plt.cm.get_cmap('tab20', len(participants))  # 'tab20' has 20 distinct colors, adjust if needed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Scatter plot for P400 amplitude, Ambiguous vs Unambiguous\"\"\"\n",
    "# Create a color map for participants\n",
    "participants = df2122['Participant'].unique()  # Extract participants\n",
    "color_map = plt.cm.get_cmap('tab20', len(participants))  # 'tab20' has 20 distinct colors, adjust if needed\n",
    "\n",
    "# Create a dictionary to map each participant to a color\n",
    "participant_colors = {participant: color_map(i) for i, participant in enumerate(participants)}\n",
    "\n",
    "# Filter data for plotting\n",
    "unambiguous_study_state_data = df2122[(df2122['Ambiguity'] == 'Unambiguous') & (df2122['Randomness'] == 'Steady State')]\n",
    "ambiguous_study_state_data = df2122[(df2122['Ambiguity'] == 'Ambiguous') & (df2122['Randomness'] == 'Steady State')]\n",
    "unambiguous_random_data = df2122[(df2122['Ambiguity'] == 'Unambiguous') & (df2122['Randomness'] == 'Random')]\n",
    "ambiguous_random_data = df2122[(df2122['Ambiguity'] == 'Ambiguous') & (df2122['Randomness'] == 'Random')]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(5, 5))\n",
    "marker_size = 75  # Increased marker size\n",
    "for participant in participants:\n",
    "    # Filter by participant\n",
    "    part_unamb_study = unambiguous_study_state_data[unambiguous_study_state_data['Participant'] == participant]['P400_Amplitude']\n",
    "    part_amb_study = ambiguous_study_state_data[ambiguous_study_state_data['Participant'] == participant]['P400_Amplitude']\n",
    "    part_unamb_random = unambiguous_random_data[unambiguous_random_data['Participant'] == participant]['P400_Amplitude']\n",
    "    part_amb_random = ambiguous_random_data[ambiguous_random_data['Participant'] == participant]['P400_Amplitude']\n",
    "    \n",
    "    # Ensure there are data points to plot\n",
    "    min_study = min(len(part_unamb_study), len(part_amb_study))\n",
    "    min_random = min(len(part_unamb_random), len(part_amb_random))\n",
    "    \n",
    "    # Plotting each participant's data with specific color\n",
    "    plt.scatter(part_amb_study[:min_study], part_unamb_study[:min_study], color=participant_colors[participant], marker='o', s=marker_size)\n",
    "    plt.scatter(part_amb_random[:min_random], part_unamb_random[:min_random], color=participant_colors[participant], marker='x', s=marker_size)\n",
    "\n",
    "# Calculate limits based on data\n",
    "buffer = 0.5\n",
    "all_ambiguity = df2122['P400_Amplitude'].dropna()\n",
    "all_unambiguity = df2122['P400_Amplitude'].dropna()\n",
    "xlim_min = min(all_ambiguity.min(), all_unambiguity.min()) - buffer\n",
    "xlim_max = max(all_ambiguity.max(), all_unambiguity.max()) + buffer\n",
    "ylim_min = xlim_min  # Assuming symmetry for simplicity\n",
    "ylim_max = xlim_max \n",
    "# Plot diagonal line\n",
    "plt.plot([xlim_min, xlim_max], [ylim_min, ylim_max], color='brown', linestyle='--')\n",
    "plt.xlim(xlim_min, xlim_max)\n",
    "plt.ylim(ylim_min, ylim_max)\n",
    "\n",
    "# Enhance the legend to show unique entries only\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))  # This removes duplicate labels\n",
    "\n",
    "# Custom legend entries for 'o' and 'x' markers\n",
    "custom_legend_entries = [plt.Line2D([0], [0], marker='o', color='r', markerfacecolor='k', markersize=10, label='Steady State'),\n",
    "                         plt.Line2D([0], [0], marker='x', color='b', markerfacecolor='k', markersize=10, label='Random')]\n",
    "\n",
    "# Combine custom legend entries with unique participant entries\n",
    "combined_legend = custom_legend_entries + list(by_label.values())\n",
    "\n",
    "# Create combined legend\n",
    "legend_labels = [entry.get_label() for entry in custom_legend_entries] + list(by_label.keys())\n",
    "\n",
    "legend = plt.legend(combined_legend, legend_labels, loc='upper left', bbox_to_anchor=(1, 1), borderaxespad=0., markerscale=0.7, title_fontsize='small')\n",
    "plt.setp(legend.get_texts(), fontsize='x-small')\n",
    "\n",
    "plt.xlabel('Ambiguous Amplitude (V)', fontsize=16)\n",
    "plt.ylabel('Unambiguous Amplitude (V)', fontsize=16)\n",
    "plt.title('P400 Peak Amplitudes', fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()  # Adjust the layout to make room for the legend\n",
    "# Add Figure name under the X axis label\n",
    "plt.text((xlim_min + xlim_max) / 2, ylim_min - (ylim_max - ylim_min) * 0.15, 'Plot E', ha='center', fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\1238685167.py:5: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  color_map = plt.cm.get_cmap('tab20', len(participants))  # 'tab20' has 20 distinct colors, adjust if needed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Scatter plot for P400 amplitude, Steady state vs Random\"\"\"\n",
    "\n",
    "# Create a color map for participants\n",
    "participants = df2122['Participant'].unique()  # Extract participants\n",
    "color_map = plt.cm.get_cmap('tab20', len(participants))  # 'tab20' has 20 distinct colors, adjust if needed\n",
    "\n",
    "# Create a dictionary to map each participant to a color\n",
    "participant_colors = {participant: color_map(i) for i, participant in enumerate(participants)}\n",
    "\n",
    "# Filter data for plotting\n",
    "steady_state_data = df2122[df2122['Randomness'] == 'Steady State']\n",
    "random_data = df2122[df2122['Randomness'] == 'Random']\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(5, 5))\n",
    "marker_size = 100  # Increased marker size\n",
    "for participant in participants:\n",
    "    # Filter by participant and ambiguity\n",
    "    part_steady_unamb = steady_state_data[(steady_state_data['Participant'] == participant) & (steady_state_data['Ambiguity'] == 'Unambiguous')]['P400_Amplitude']\n",
    "    part_steady_amb = steady_state_data[(steady_state_data['Participant'] == participant) & (steady_state_data['Ambiguity'] == 'Ambiguous')]['P400_Amplitude']\n",
    "    part_random_unamb = random_data[(random_data['Participant'] == participant) & (random_data['Ambiguity'] == 'Unambiguous')]['P400_Amplitude']\n",
    "    part_random_amb = random_data[(random_data['Participant'] == participant) & (random_data['Ambiguity'] == 'Ambiguous')]['P400_Amplitude']\n",
    "    \n",
    "    # Ensure there are data points to plot\n",
    "    min_steady_unamb = min(len(part_steady_unamb), len(part_random_unamb))\n",
    "    min_steady_amb = min(len(part_steady_amb), len(part_random_amb))\n",
    "    \n",
    "    # Plotting each participant's data with specific color and marker\n",
    "    plt.scatter(part_steady_unamb[:min_steady_unamb], part_random_unamb[:min_steady_unamb], color=participant_colors[participant], marker='+', s=marker_size, label=participant if 'Unambiguous' in participant else \"\")\n",
    "    plt.scatter(part_steady_amb[:min_steady_amb], part_random_amb[:min_steady_amb], color=participant_colors[participant], marker='^', s=marker_size, label=participant if 'Ambiguous' in participant else \"\")\n",
    "\n",
    "# Calculate limits based on data\n",
    "buffer = 0.5\n",
    "all_steady = steady_state_data['P400_Amplitude'].dropna()\n",
    "all_random = random_data['P400_Amplitude'].dropna()\n",
    "xlim_min = min(all_steady.min(), all_random.min()) - buffer\n",
    "xlim_max = max(all_steady.max(), all_random.max()) + buffer\n",
    "ylim_min = xlim_min  # Assuming symmetry for simplicity\n",
    "ylim_max = xlim_max \n",
    "\n",
    "# Plot diagonal line\n",
    "plt.plot([xlim_min, xlim_max], [ylim_min, ylim_max], color='brown', linestyle='--')\n",
    "plt.xlim(xlim_min, xlim_max)\n",
    "plt.ylim(ylim_min, ylim_max)\n",
    "\n",
    "# Enhance the legend to show unique entries only\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))  # This removes duplicate labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Custom legend entries for 'o' and 'x' markers\n",
    "custom_legend_entries = [plt.Line2D([0], [0], marker='+', linestyle='None', color='g', markerfacecolor='k', markersize=10, label='Unambiguous'),\n",
    "                         plt.Line2D([0], [0], marker='^', linestyle='None', color='m', markerfacecolor='k', markersize=10, label='Ambiguous')]\n",
    "\n",
    "# Combine custom legend entries with unique participant entries\n",
    "combined_legend = custom_legend_entries + list(by_label.values())\n",
    "\n",
    "# Create combined legend\n",
    "legend_labels = [entry.get_label() for entry in custom_legend_entries] + list(by_label.keys())\n",
    "\n",
    "legend = plt.legend(combined_legend, legend_labels, loc='upper left', bbox_to_anchor=(1, 1), borderaxespad=0., markerscale=0.7, title_fontsize='small')\n",
    "plt.setp(legend.get_texts(), fontsize='x-small')\n",
    "\n",
    "plt.xlabel('Steady State Amplitude (V)', fontsize=16)\n",
    "plt.ylabel('Random Amplitude (V)', fontsize=16)\n",
    "plt.title('P400 Peak Amplitudes', fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()  # Adjust the layout to make room for the legend\n",
    "\n",
    "# Add Figure name under the X axis label\n",
    "plt.text((xlim_min + xlim_max) / 2, ylim_min - (ylim_max - ylim_min) * 0.15, 'Plot F', ha='center', fontsize=12)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\2665826161.py:4: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  color_map = plt.cm.get_cmap('tab20', len(participants))  # 'tab20' has 20 distinct colors, adjust if needed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Scatter plot for P400 latency, Steady state vs Random\"\"\"\n",
    "# Create a color map for participants\n",
    "participants = df2122['Participant'].unique()  # Extract participants\n",
    "color_map = plt.cm.get_cmap('tab20', len(participants))  # 'tab20' has 20 distinct colors, adjust if needed\n",
    "\n",
    "# Create a dictionary to map each participant to a color\n",
    "participant_colors = {participant: color_map(i) for i, participant in enumerate(participants)}\n",
    "\n",
    "# Filter data for plotting\n",
    "steady_state_data = df2122[df2122['Randomness'] == 'Steady State']\n",
    "random_data = df2122[df2122['Randomness'] == 'Random']\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(5, 5))\n",
    "marker_size = 100  # Increased marker size\n",
    "for participant in participants:\n",
    "    # Filter by participant and ambiguity\n",
    "    part_steady_unamb = steady_state_data[(steady_state_data['Participant'] == participant) & (steady_state_data['Ambiguity'] == 'Unambiguous')]['P400_Latency']\n",
    "    part_steady_amb = steady_state_data[(steady_state_data['Participant'] == participant) & (steady_state_data['Ambiguity'] == 'Ambiguous')]['P400_Latency']\n",
    "    part_random_unamb = random_data[(random_data['Participant'] == participant) & (random_data['Ambiguity'] == 'Unambiguous')]['P400_Latency']\n",
    "    part_random_amb = random_data[(random_data['Participant'] == participant) & (random_data['Ambiguity'] == 'Ambiguous')]['P400_Latency']\n",
    "    \n",
    "    # Ensure there are data points to plot\n",
    "    min_steady_unamb = min(len(part_steady_unamb), len(part_random_unamb))\n",
    "    min_steady_amb = min(len(part_steady_amb), len(part_random_amb))\n",
    "    \n",
    "    # Plotting each participant's data with specific color and marker\n",
    "    plt.scatter(part_steady_unamb[:min_steady_unamb], part_random_unamb[:min_steady_unamb], color=participant_colors[participant], marker='+', s=marker_size, label=participant if 'Unambiguous' in participant else \"\")\n",
    "    plt.scatter(part_steady_amb[:min_steady_amb], part_random_amb[:min_steady_amb], color=participant_colors[participant], marker='^', s=marker_size, label=participant if 'Ambiguous' in participant else \"\")\n",
    "\n",
    "# Calculate limits based on data\n",
    "buffer = 0.01\n",
    "all_steady = steady_state_data['P400_Latency'].dropna()\n",
    "all_random = random_data['P400_Latency'].dropna()\n",
    "xlim_min = min(all_steady.min(), all_random.min()) - buffer\n",
    "xlim_max = max(all_steady.max(), all_random.max()) + buffer\n",
    "ylim_min = xlim_min  # Assuming symmetry for simplicity\n",
    "ylim_max = xlim_max \n",
    "\n",
    "# Plot diagonal line\n",
    "plt.plot([xlim_min, xlim_max], [ylim_min, ylim_max], color='brown', linestyle='--')\n",
    "plt.xlim(xlim_min, xlim_max)\n",
    "plt.ylim(ylim_min, ylim_max)\n",
    "\n",
    "# Enhance the legend to show unique entries only\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))  # This removes duplicate labels\n",
    "\n",
    "\n",
    "\n",
    "# Custom legend entries for 'o' and 'x' markers\n",
    "custom_legend_entries = [plt.Line2D([0], [0], marker='+', linestyle='None', color='g', markerfacecolor='k', markersize=10, label='Unambiguous'),\n",
    "                         plt.Line2D([0], [0], marker='^', linestyle='None', color='m', markerfacecolor='k', markersize=10, label='Ambiguous')]\n",
    "\n",
    "# Combine custom legend entries with unique participant entries\n",
    "combined_legend = custom_legend_entries + list(by_label.values())\n",
    "\n",
    "# Create combined legend\n",
    "legend_labels = [entry.get_label() for entry in custom_legend_entries] + list(by_label.keys())\n",
    "\n",
    "legend = plt.legend(combined_legend, legend_labels, loc='upper left', bbox_to_anchor=(1, 1), borderaxespad=0., markerscale=0.7, title_fontsize='small')\n",
    "plt.setp(legend.get_texts(), fontsize='x-small')\n",
    "\n",
    "plt.xlabel('Steady State Latencies (ms)', fontsize=16)\n",
    "plt.ylabel('Random Latencies (ms)', fontsize=16)\n",
    "plt.title('P400 Peak Latencies', fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()  # Adjust the layout to make room for the legend\n",
    "\n",
    "# Add Figure name under the X axis label\n",
    "plt.text((xlim_min + xlim_max) / 2, ylim_min - (ylim_max - ylim_min) * 0.15, 'Plot D', ha='center', fontsize=12)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_25248\\3786465566.py:4: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  color_map = plt.cm.get_cmap('tab20', len(participants))  # 'tab20' has 20 distinct colors, adjust if needed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Scatter plot for P200 latency, Steady state vs Random\"\"\"\n",
    "# Create a color map for participants\n",
    "participants = df2122['Participant'].unique()  # Extract participants\n",
    "color_map = plt.cm.get_cmap('tab20', len(participants))  # 'tab20' has 20 distinct colors, adjust if needed\n",
    "\n",
    "# Create a dictionary to map each participant to a color\n",
    "participant_colors = {participant: color_map(i) for i, participant in enumerate(participants)}\n",
    "\n",
    "# Filter data for plotting\n",
    "steady_state_data = df2122[df2122['Randomness'] == 'Steady State']\n",
    "random_data = df2122[df2122['Randomness'] == 'Random']\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(5, 5))\n",
    "marker_size = 100  # Increased marker size\n",
    "for participant in participants:\n",
    "    # Filter by participant and ambiguity\n",
    "    part_steady_unamb = steady_state_data[(steady_state_data['Participant'] == participant) & (steady_state_data['Ambiguity'] == 'Unambiguous')]['P200_Latency']\n",
    "    part_steady_amb = steady_state_data[(steady_state_data['Participant'] == participant) & (steady_state_data['Ambiguity'] == 'Ambiguous')]['P200_Latency']\n",
    "    part_random_unamb = random_data[(random_data['Participant'] == participant) & (random_data['Ambiguity'] == 'Unambiguous')]['P200_Latency']\n",
    "    part_random_amb = random_data[(random_data['Participant'] == participant) & (random_data['Ambiguity'] == 'Ambiguous')]['P200_Latency']\n",
    "    \n",
    "    # Ensure there are data points to plot\n",
    "    min_steady_unamb = min(len(part_steady_unamb), len(part_random_unamb))\n",
    "    min_steady_amb = min(len(part_steady_amb), len(part_random_amb))\n",
    "    \n",
    "    # Plotting each participant's data with specific color and marker\n",
    "    plt.scatter(part_steady_unamb[:min_steady_unamb], part_random_unamb[:min_steady_unamb], color=participant_colors[participant], marker='+', s=marker_size, label=participant if 'Unambiguous' in participant else \"\")\n",
    "    plt.scatter(part_steady_amb[:min_steady_amb], part_random_amb[:min_steady_amb], color=participant_colors[participant], marker='^', s=marker_size, label=participant if 'Ambiguous' in participant else \"\")\n",
    "\n",
    "# Calculate limits based on data\n",
    "buffer = 0.001\n",
    "all_steady = steady_state_data['P200_Latency'].dropna()\n",
    "all_random = random_data['P200_Latency'].dropna()\n",
    "xlim_min = min(all_steady.min(), all_random.min()) - buffer\n",
    "xlim_max = max(all_steady.max(), all_random.max()) + buffer\n",
    "ylim_min = xlim_min  # Assuming symmetry for simplicity\n",
    "ylim_max = xlim_max \n",
    "\n",
    "# Plot diagonal line\n",
    "plt.plot([xlim_min, xlim_max], [ylim_min, ylim_max], color='brown', linestyle='--')\n",
    "plt.xlim(xlim_min, xlim_max)\n",
    "plt.ylim(ylim_min, ylim_max)\n",
    "\n",
    "# Enhance the legend to show unique entries only\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))  # This removes duplicate labels\n",
    "\n",
    "\n",
    "# Custom legend entries for 'o' and 'x' markers\n",
    "custom_legend_entries = [plt.Line2D([0], [0], marker='+', linestyle='None', color='g', markerfacecolor='k', markersize=10, label='Unambiguous'),\n",
    "                         plt.Line2D([0], [0], marker='^', linestyle='None', color='m', markerfacecolor='k', markersize=10, label='Ambiguous')]\n",
    "\n",
    "# Combine custom legend entries with unique participant entries\n",
    "combined_legend = custom_legend_entries + list(by_label.values())\n",
    "\n",
    "# Create combined legend\n",
    "legend_labels = [entry.get_label() for entry in custom_legend_entries] + list(by_label.keys())\n",
    "\n",
    "legend = plt.legend(combined_legend, legend_labels, loc='upper left', bbox_to_anchor=(1, 1), borderaxespad=0., markerscale=0.7, title_fontsize='small')\n",
    "plt.setp(legend.get_texts(), fontsize='x-small')\n",
    "\n",
    "plt.xlabel('Steady State Latencies (ms)', fontsize=16)\n",
    "plt.ylabel('Random Latencies (ms)', fontsize=16)\n",
    "plt.title('P200 Peak Latencies', fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()  # Adjust the layout to make room for the legend\n",
    "\n",
    "# Add Figure name under the X axis label\n",
    "plt.text((xlim_min + xlim_max) / 2, ylim_min - (ylim_max - ylim_min) * 0.15, 'Plot C', ha='center', fontsize=12)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\2084213329.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  color_map = plt.cm.get_cmap('tab20', len(participants))  # 'tab20' has 20 distinct colors, adjust if needed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Value differences\"\"\"\n",
    "\n",
    "# Create a color map for participants\n",
    "participants = df2122['Participant'].unique()  # Extract unique participants\n",
    "color_map = plt.cm.get_cmap('tab20', len(participants))  # 'tab20' has 20 distinct colors, adjust if needed\n",
    "\n",
    "# Create a dictionary to map each participant to a color\n",
    "participant_colors = {participant: color_map(i) for i, participant in enumerate(participants)}\n",
    "\n",
    "# Initializing lists to store amplitude differences\n",
    "study_state_latency_diff = []\n",
    "random_latency_diff = []\n",
    "\n",
    "# Calculating differences\n",
    "for participant in participants:\n",
    "    # Filter by participant\n",
    "    unamb_study_amplitude = df2122[(df2122['Participant'] == participant) & (df2122['Ambiguity'] == 'Unambiguous') & (df2122['Randomness'] == 'Steady State')]['P200_Latency'].mean()\n",
    "    amb_study_amplitude = df2122[(df2122['Participant'] == participant) & (df2122['Ambiguity'] == 'Ambiguous') & (df2122['Randomness'] == 'Steady State')]['P200_Latency'].mean()\n",
    "    unamb_random_amplitude = df2122[(df2122['Participant'] == participant) & (df2122['Ambiguity'] == 'Unambiguous') & (df2122['Randomness'] == 'Random')]['P200_Latency'].mean()\n",
    "    amb_random_amplitude = df2122[(df2122['Participant'] == participant) & (df2122['Ambiguity'] == 'Ambiguous') & (df2122['Randomness'] == 'Random')]['P200_Latency'].mean()\n",
    "    \n",
    "    # Calculate differences and append to lists\n",
    "    study_state_latency_diff.append(unamb_study_amplitude - amb_study_amplitude)\n",
    "    random_latency_diff.append(unamb_random_amplitude - amb_random_amplitude)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, participant in enumerate(participants):\n",
    "    plt.scatter(study_state_latency_diff[i], random_latency_diff[i], color=participant_colors[participant], label=f' {participant}')\n",
    "# Calculate limits based on data\n",
    "buffer = 0.001\n",
    "xlim_min = min(study_state_latency_diff) - buffer\n",
    "xlim_max = max(study_state_latency_diff) + buffer\n",
    "ylim_min = min(random_latency_diff) - buffer\n",
    "ylim_max = max(random_latency_diff) + buffer\n",
    "\n",
    "# Ensure the plot is square by setting the same limits for both axes\n",
    "combined_min = min(xlim_min, ylim_min)\n",
    "combined_max = max(xlim_max, ylim_max)\n",
    "plt.plot([combined_min, combined_max], [combined_min, combined_max], color='brown', linestyle='--')\n",
    "plt.xlim(combined_min, combined_max)\n",
    "plt.ylim(combined_min, combined_max)\n",
    "# Enhance the legend to show unique entries only\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))  # This removes duplicate labels\n",
    "plt.legend(by_label.values(), by_label.keys(), loc='upper left', bbox_to_anchor=(1, 1), borderaxespad=0.)\n",
    "\n",
    "plt.xlabel('Steady State Latency Difference (Unambiguous - Ambiguous)')\n",
    "plt.ylabel('Random State Latency Difference (Unambiguous - Ambiguous)')\n",
    "plt.title('Scatter Plot of Latency Differences at P200 by Participant')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()  # Adjust the layout to make room for the legend\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\1617307158.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  color_map = plt.cm.get_cmap('tab20', len(participants))  # 'tab20' has 20 distinct colors, adjust if needed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"Value differences\"\"\"\n",
    "# Create a color map for participants\n",
    "participants = df2122['Participant'].unique()  # Extract unique participants\n",
    "color_map = plt.cm.get_cmap('tab20', len(participants))  # 'tab20' has 20 distinct colors, adjust if needed\n",
    "\n",
    "# Create a dictionary to map each participant to a color\n",
    "participant_colors = {participant: color_map(i) for i, participant in enumerate(participants)}\n",
    "\n",
    "# Initializing lists to store amplitude differences\n",
    "study_state_amplitude_diff = []\n",
    "random_amplitude_diff = []\n",
    "\n",
    "# Calculating differences\n",
    "for participant in participants:\n",
    "    # Filter by participant\n",
    "    unamb_study_amplitude = df2122[(df2122['Participant'] == participant) & (df2122['Ambiguity'] == 'Unambiguous') & (df2122['Randomness'] == 'Steady State')]['P400_Amplitude'].mean()\n",
    "    amb_study_amplitude = df2122[(df2122['Participant'] == participant) & (df2122['Ambiguity'] == 'Ambiguous') & (df2122['Randomness'] == 'Steady State')]['P400_Amplitude'].mean()\n",
    "    unamb_random_amplitude = df2122[(df2122['Participant'] == participant) & (df2122['Ambiguity'] == 'Unambiguous') & (df2122['Randomness'] == 'Random')]['P400_Amplitude'].mean()\n",
    "    amb_random_amplitude = df2122[(df2122['Participant'] == participant) & (df2122['Ambiguity'] == 'Ambiguous') & (df2122['Randomness'] == 'Random')]['P400_Amplitude'].mean()\n",
    "    \n",
    "    # Calculate differences and append to lists\n",
    "    study_state_amplitude_diff.append(unamb_study_amplitude - amb_study_amplitude)\n",
    "    random_amplitude_diff.append(unamb_random_amplitude - amb_random_amplitude)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, participant in enumerate(participants):\n",
    "    plt.scatter(study_state_amplitude_diff[i], random_amplitude_diff[i], color=participant_colors[participant], label=f' {participant}')\n",
    "# Calculate limits based on data\n",
    "buffer = 0.1\n",
    "xlim_min = min(study_state_amplitude_diff)\n",
    "xlim_max = max(study_state_amplitude_diff)\n",
    "ylim_min = min(random_amplitude_diff)\n",
    "ylim_max = max(random_amplitude_diff) + buffer\n",
    "\n",
    "# Ensure the plot is square by setting the same limits for both axes\n",
    "combined_min = min(xlim_min, ylim_min)\n",
    "combined_max = max(xlim_max, ylim_max)\n",
    "plt.plot([combined_min, combined_max], [combined_min, combined_max], color='brown', linestyle='--')\n",
    "plt.xlim(combined_min, combined_max)\n",
    "plt.ylim(combined_min, combined_max)\n",
    "# Enhance the legend to show unique entries only\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))  # This removes duplicate labels\n",
    "plt.legend(by_label.values(), by_label.keys(), loc='upper left', bbox_to_anchor=(1, 1), borderaxespad=0.)\n",
    "\n",
    "plt.xlabel('Steady State Amplitude Difference (Unambiguous - Ambiguous)')\n",
    "plt.ylabel('Random State Amplitude Difference (Unambiguous - Ambiguous)')\n",
    "plt.title('Scatter Plot of Amplitude Differences at P400 by Participant')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()  # Adjust the layout to make room for the legend\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mtu10\\AppData\\Local\\Temp\\ipykernel_9076\\3495064017.py:5: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  color_map = plt.cm.get_cmap('tab20', len(participants))  # 'tab20' has 20 distinct colors, adjust if needed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Value differences\"\"\"\n",
    "\n",
    "# Create a color map for participants\n",
    "participants = df2122['Participant'].unique()  # Extract unique participants\n",
    "color_map = plt.cm.get_cmap('tab20', len(participants))  # 'tab20' has 20 distinct colors, adjust if needed\n",
    "\n",
    "# Create a dictionary to map each participant to a color\n",
    "participant_colors = {participant: color_map(i) for i, participant in enumerate(participants)}\n",
    "\n",
    "# Initializing lists to store amplitude differences\n",
    "study_state_amplitude_diff = []\n",
    "random_amplitude_diff = []\n",
    "\n",
    "# Calculating differences\n",
    "for participant in participants:\n",
    "    # Filter by participant\n",
    "    unamb_study_amplitude = df2122[(df2122['Participant'] == participant) & (df2122['Ambiguity'] == 'Unambiguous') & (df2122['Randomness'] == 'Steady State')]['P400_Latency'].mean()\n",
    "    amb_study_amplitude = df2122[(df2122['Participant'] == participant) & (df2122['Ambiguity'] == 'Ambiguous') & (df2122['Randomness'] == 'Steady State')]['P400_Latency'].mean()\n",
    "    unamb_random_amplitude = df2122[(df2122['Participant'] == participant) & (df2122['Ambiguity'] == 'Unambiguous') & (df2122['Randomness'] == 'Random')]['P400_Latency'].mean()\n",
    "    amb_random_amplitude = df2122[(df2122['Participant'] == participant) & (df2122['Ambiguity'] == 'Ambiguous') & (df2122['Randomness'] == 'Random')]['P400_Latency'].mean()\n",
    "    \n",
    "    # Calculate differences and append to lists\n",
    "    study_state_amplitude_diff.append(unamb_study_amplitude - amb_study_amplitude)\n",
    "    random_amplitude_diff.append(unamb_random_amplitude - amb_random_amplitude)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, participant in enumerate(participants):\n",
    "    plt.scatter(study_state_amplitude_diff[i], random_amplitude_diff[i], color=participant_colors[participant], label=f' {participant}')\n",
    "# make axis same range\n",
    "buffer = 0.0018\n",
    "xlim_min = min(study_state_amplitude_diff) - buffer\n",
    "xlim_max = max(study_state_amplitude_diff)\n",
    "ylim_min = min(random_amplitude_diff)\n",
    "ylim_max = max(random_amplitude_diff) \n",
    "\n",
    "# Ensure the plot is square by setting the same limits for both axes\n",
    "combined_min = min(xlim_min, ylim_min)\n",
    "combined_max = max(xlim_max, ylim_max)\n",
    "plt.plot([combined_min, combined_max], [combined_min, combined_max], color='brown', linestyle='--')\n",
    "plt.xlim(combined_min, combined_max)\n",
    "plt.ylim(combined_min, combined_max)\n",
    "\n",
    "# Enhance the legend to show unique entries only\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))  # This removes duplicate labels\n",
    "plt.legend(by_label.values(), by_label.keys(), loc='upper left', bbox_to_anchor=(1, 1), borderaxespad=0.)\n",
    "\n",
    "plt.xlabel('Steady State Latency Difference (Unambiguous - Ambiguous)')\n",
    "plt.ylabel('Random State Latency Difference (Unambiguous - Ambiguous)')\n",
    "plt.title('Scatter Plot of Latency Differences at P400 by Participant')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()  # Adjust the layout to make room for the legend\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27.0, 26.0, 3.1622776601683795),\n",
       " (25.0, 25.0, 1.7320508075688772),\n",
       " (24.181818181818183, 23.0, 2.5619594773603196),\n",
       " (25.25, 25.5, 2.0615528128088303),\n",
       " (25.06896551724138, 25.0, 2.4630270934470424))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Calculate group mean, median, and standart deviation\"\"\"\n",
    "\n",
    "# Define the ages in each group\n",
    "group1 = np.array([28, 25, 26, 24, 32])\n",
    "group2 = np.array([24, 25, 27, 26, 22, 25, 27, 26, 23])\n",
    "group3 = np.array([26, 25, 21, 22, 23, 28, 24, 22, 23, 23, 29])\n",
    "group4 = np.array([27, 23, 24, 27])\n",
    "\n",
    "# Define a function to calculate mean, median, and standard deviation\n",
    "def calculate_stats(data):\n",
    "    mean = np.mean(data)\n",
    "    median = np.median(data)\n",
    "    std_dev = np.std(data, ddof=1)  # Using sample standard deviation (N-1)\n",
    "    return mean, median, std_dev\n",
    "\n",
    "# Calculate stats for each group\n",
    "stats_group1 = calculate_stats(group1)\n",
    "stats_group2 = calculate_stats(group2)\n",
    "stats_group3 = calculate_stats(group3)\n",
    "stats_group4 = calculate_stats(group4)\n",
    "\n",
    "# Combine all groups into one for overall statistics\n",
    "all_groups = np.concatenate((group1, group2, group3, group4))\n",
    "stats_all_groups = calculate_stats(all_groups)\n",
    "stats_group1, stats_group2, stats_group3, stats_group4, stats_all_groups"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
